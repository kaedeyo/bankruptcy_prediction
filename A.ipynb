{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT TEXT FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET\n",
    "#Bankrupt_files\n",
    "bankrupted_risk_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/bankrupted/trainB')\n",
    "bankrupted_risk_reports = [file for file in bankrupted_risk_reports]\n",
    "\n",
    "bankrupted_file = []\n",
    "for report in range(0, len(bankrupted_risk_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/bankrupted/trainB/{bankrupted_risk_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        filesB = file.read()\n",
    "        bankrupted_file.append(filesB)\n",
    "\n",
    "df_bankrupted = pd.DataFrame(bankrupted_file)\n",
    "df_bankrupted.columns = ['text_file']\n",
    "df_bankrupted['Y'] = 0 #Y=0 means bankrupted\n",
    "# print(df_bankrupted)\n",
    "\n",
    "#Nonbankrupt_files\n",
    "nonbankrupted_risk_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/nonbankrupted/trainNB')\n",
    "nonbankrupted_risk_reports = [file for file in nonbankrupted_risk_reports]\n",
    "\n",
    "nonbankrupted_file = []\n",
    "for report in range(0, len(nonbankrupted_risk_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/nonbankrupted/trainNB/{nonbankrupted_risk_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        filesNB = file.read()\n",
    "        nonbankrupted_file.append(filesNB)\n",
    "\n",
    "df_nonbankrupted = pd.DataFrame(nonbankrupted_file)\n",
    "df_nonbankrupted.columns = ['text_file']\n",
    "df_nonbankrupted['Y'] = 1 #Y=1 means non-bankrupted\n",
    "# print(df_nonbankrupted)\n",
    "\n",
    "concatenated_train = [df_bankrupted, df_nonbankrupted]\n",
    "df_train = pd.concat(concatenated_train, ignore_index= True)\n",
    "# print(df_train)\n",
    "\n",
    "# VALIDATION SET\n",
    "#Bankrupt_files\n",
    "bankrupted_risk_reports_val = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/bankrupted/valB')\n",
    "bankrupted_risk_reports_val = [file for file in bankrupted_risk_reports_val]\n",
    "\n",
    "bankrupted_file_val = []\n",
    "for report in range(0, len(bankrupted_risk_reports_val)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/bankrupted/valB/{bankrupted_risk_reports_val[report]}\", encoding=\"utf8\") as file:\n",
    "        filesB_val = file.read()\n",
    "        bankrupted_file_val.append(filesB_val)\n",
    "\n",
    "df_bankrupted_val = pd.DataFrame(bankrupted_file_val)\n",
    "df_bankrupted_val.columns = ['text_file']\n",
    "df_bankrupted_val['Y'] = 0 #Y=0 means bankrupted\n",
    "# print(df_bankrupted_val)\n",
    "\n",
    "#Nonbankrupt_files\n",
    "nonbankrupted_risk_reports_val = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/nonbankrupted/valNB')\n",
    "nonbankrupted_risk_reports_val = [file for file in nonbankrupted_risk_reports_val]\n",
    "\n",
    "nonbankrupted_file_val = []\n",
    "for report in range(0, len(nonbankrupted_risk_reports_val)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/nonbankrupted/valNB/{nonbankrupted_risk_reports_val[report]}\", encoding=\"utf8\") as file:\n",
    "        filesNB_val = file.read()\n",
    "        nonbankrupted_file_val.append(filesNB_val)\n",
    "\n",
    "df_nonbankrupted_val = pd.DataFrame(nonbankrupted_file_val)\n",
    "df_nonbankrupted_val.columns = ['text_file']\n",
    "df_nonbankrupted_val['Y'] = 1 #Y=1 means non-bankrupted\n",
    "# print(df_nonbankrupted_val)\n",
    "\n",
    "concatenated_val = [df_bankrupted_val, df_nonbankrupted_val]\n",
    "df_val = pd.concat(concatenated_val, ignore_index=True)\n",
    "# print(df_val)\n",
    "\n",
    "# TEST SET\n",
    "\n",
    "#Bankrupt_files (test data)\n",
    "testbankrupted_risk_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/bankrupted/testB')\n",
    "\n",
    "testbankrupted_file = []\n",
    "for report in range(0, len(testbankrupted_risk_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/bankrupted/testB/{testbankrupted_risk_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        testfilesB = file.read()\n",
    "        testbankrupted_file.append(testfilesB)\n",
    "\n",
    "df_bankrupted_test = pd.DataFrame(testbankrupted_file)\n",
    "df_bankrupted_test.columns = ['text_file']\n",
    "df_bankrupted_test['Y'] = 0\n",
    "\n",
    "#Nonbankrupt_files (test data)\n",
    "testnonbankrupted_risk_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/nonbankrupted/testNB')\n",
    "\n",
    "testnonbankrupted_file = []\n",
    "for report in range(0, len(testnonbankrupted_risk_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/risk_info/nonbankrupted/testNB/{testnonbankrupted_risk_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        testfilesNB = file.read()\n",
    "        testnonbankrupted_file.append(testfilesNB)\n",
    "\n",
    "df_nonbankrupted_test = pd.DataFrame(testnonbankrupted_file)\n",
    "df_nonbankrupted_test.columns = ['text_file']\n",
    "df_nonbankrupted_test['Y'] = 1\n",
    "\n",
    "concatenated_test = [df_bankrupted_test, df_nonbankrupted_test]\n",
    "df_test = pd.concat(concatenated_test, ignore_index=True)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            text_file  Y\n",
      "0   　有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、当社グループの経営成績...  0\n",
      "1   以下において、当社グループの事業展開上、リスク要因となる可能性があると考えられる主な事項を記...  0\n",
      "2   当社グループの経営成績及び財政状態等に関して、投資者の判断に重要な影響を及ぼす可能性のある事...  0\n",
      "3   当社グループの経営成績、株価および財務状況等に影響を及ぼす可能性のあるリスク要因については以...  0\n",
      "4   有価証券報告書に記載した事業の状況、経理の状況に関する事項のうち、投資者の判断に重要な影響を...  0\n",
      "5   当グループの経営成績、株価および財務状況等に影響を及ぼす可能性のある事項には以下のようなもの...  0\n",
      "6   当社グループのリスク管理に関しては、「リスク管理規程」を制定し、「リスク管理委員会」を設置し...  0\n",
      "7   当連結グループの経営成績等に影響を及ぼす可能性のあるリスクには以下のようなものがあります。 ...  0\n",
      "8   当社グループは、物流施設のサブリース事業で培ったノウハウ・信用を、ＰＭ領域での業容拡大、ＡＭ...  0\n",
      "9   当社グループの経営成績、株価及び財務状況等に影響を及ぼす可能性のあるリスクには、以下のような...  0\n",
      "10  　有価証券報告書に記載した事業の状況、経理の状況等に関する事のうち、投資者の判断に重要な影響...  0\n",
      "11  有価証券報告書に記載した事業の状況、経理の状況等に関連する事項のうち、投資者の投資判断に重要...  0\n",
      "12  当グループの経営成績、財務状況等に影響を及ぼす可能性のあるリスクには以下のようなものがありま...  1\n",
      "13  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  1\n",
      "14  (1) 住宅市場の動向\\n当社グループの業績は、とりわけ住宅市場の動向に大きく依存しておりま...  1\n",
      "15  以下において、当社グループの事業の展開上、投資家の判断に重要な影響を及ぼす可能性があると考え...  1\n",
      "16  有価証券報告書に記載した事業の内容、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  1\n",
      "17  有価証券報告書に記載した事業の状況、経理の状況に関する事項のうち、投資者の判断に重要な影響を...  1\n",
      "18  以下において、当社グループの事業展開上のリスク要因となる可能性があると考えられる主な事項を記...  1\n",
      "19  当社グループの経営成績および財政状態に影響を及ぼす可能性があるリスクには、次のようなものがあ...  1\n",
      "20  当社及び当社の関係会社（以下「当社グループ」といいます）の経営成績、株価及び財務状況等に影響...  1\n",
      "21  以下において、当社グループの事業展開上、リスク要因となる可能性があると考えられる主な事項を記...  1\n",
      "22  当社グループの経営成績及び財政状態などに重要な影響を及ぼす可能性がある事項には、以下のような...  1\n",
      "23  本書に記載した事業の状況、経理に関する事項のうち、投資家の判断に重要な影響を及ぼす可能性のあ...  1\n",
      "24  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  1\n"
     ]
    }
   ],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT RATIO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET\n",
    "\n",
    "traindata = pd.read_csv('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/ratios/train_ratio.csv')\n",
    "# print('TRAINING DATASET \\n:', traindata.describe().transpose())\n",
    "X_train_ratio = traindata.drop('Y', axis=1)\n",
    "y_train_ratio = traindata['Y']\n",
    "# print(sns.countplot(x = 'Y', data=traindata))\n",
    "\n",
    "# VALIDATION SET\n",
    "\n",
    "valdata = pd.read_csv('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/ratios/val_ratio.csv')\n",
    "# print('VALIDATION DATASET \\n:', valdata.describe().transpose())\n",
    "X_val_ratio = valdata.drop('Y', axis=1)\n",
    "y_val_ratio = valdata['Y']\n",
    "\n",
    "# TEST SET\n",
    "\n",
    "testdata = pd.read_csv('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/ratios/test_ratio.csv')\n",
    "# print('TEST DATASET \\n:', testdata.describe().transpose())\n",
    "# print('TEST DATASET \\n:', testdata)\n",
    "X_test_ratio = testdata.drop('Y', axis=1)\n",
    "y_test_ratio = testdata['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINE BOTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD THE A NEW COLUMN FOR TEXT FILE\n",
    "\n",
    "X_train_ratio['text'] = df_train['text_file']\n",
    "X_val_ratio['text'] = df_val['text_file']\n",
    "X_test_ratio['text'] = df_test.drop('Y', axis=1)\n",
    "\n",
    "# CREATE NEW DATAFRAME FOR COMBINED DATA\n",
    "\n",
    "X_train_both = X_train_ratio\n",
    "X_val_both = X_val_ratio\n",
    "X_test_both = X_test_ratio\n",
    "\n",
    "y_train_both = y_train_ratio\n",
    "y_val_both = y_val_ratio\n",
    "y_test_both = y_test_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X29</th>\n",
       "      <th>X47</th>\n",
       "      <th>X51</th>\n",
       "      <th>X54</th>\n",
       "      <th>X59</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>...</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X79</th>\n",
       "      <th>X80</th>\n",
       "      <th>X84</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-56.50</td>\n",
       "      <td>-12.14</td>\n",
       "      <td>4.35</td>\n",
       "      <td>-143.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.17</td>\n",
       "      <td>217.91</td>\n",
       "      <td>48.72</td>\n",
       "      <td>173.50</td>\n",
       "      <td>36.20</td>\n",
       "      <td>...</td>\n",
       "      <td>-1102.48</td>\n",
       "      <td>333.84</td>\n",
       "      <td>257.75</td>\n",
       "      <td>228.53</td>\n",
       "      <td>-26.80</td>\n",
       "      <td>-44.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>308.94</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>当社グループの経営成績、株価及び財務状況等に重要な影響を及ぼす可能性のある事業等のリスクには...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.33</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.72</td>\n",
       "      <td>51.61</td>\n",
       "      <td>123.96</td>\n",
       "      <td>1288.35</td>\n",
       "      <td>7.12</td>\n",
       "      <td>...</td>\n",
       "      <td>111.11</td>\n",
       "      <td>203.17</td>\n",
       "      <td>570.71</td>\n",
       "      <td>-103.33</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>-838.37</td>\n",
       "      <td>-12.80</td>\n",
       "      <td>-1495.54</td>\n",
       "      <td>3.03</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-220.42</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-23.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.36</td>\n",
       "      <td>56.14</td>\n",
       "      <td>206.41</td>\n",
       "      <td>844.44</td>\n",
       "      <td>10.64</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.03</td>\n",
       "      <td>-50.36</td>\n",
       "      <td>-36.22</td>\n",
       "      <td>914.70</td>\n",
       "      <td>-24.20</td>\n",
       "      <td>12.38</td>\n",
       "      <td>-21.79</td>\n",
       "      <td>-2198.07</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>当グループの経営成績、財務状況等に影響を及ぼす可能性のあるリスクには次のようなものがある。た...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.13</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.37</td>\n",
       "      <td>132.09</td>\n",
       "      <td>30.43</td>\n",
       "      <td>204.28</td>\n",
       "      <td>32.86</td>\n",
       "      <td>...</td>\n",
       "      <td>9.69</td>\n",
       "      <td>33.15</td>\n",
       "      <td>295.54</td>\n",
       "      <td>-111.94</td>\n",
       "      <td>-8.85</td>\n",
       "      <td>10.06</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-114.86</td>\n",
       "      <td>-10.88</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.44</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1.91</td>\n",
       "      <td>18.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.39</td>\n",
       "      <td>39.96</td>\n",
       "      <td>14.71</td>\n",
       "      <td>283.68</td>\n",
       "      <td>26.06</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>42.59</td>\n",
       "      <td>44.35</td>\n",
       "      <td>61.80</td>\n",
       "      <td>77.84</td>\n",
       "      <td>76.70</td>\n",
       "      <td>2.81</td>\n",
       "      <td>64.88</td>\n",
       "      <td>-44.19</td>\n",
       "      <td>（１）法的規制のリスク\\n　当社グループの属する建設、不動産業界は、建設業法、建築基準法、都...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.42</td>\n",
       "      <td>20.61</td>\n",
       "      <td>23.69</td>\n",
       "      <td>46.37</td>\n",
       "      <td>104.47</td>\n",
       "      <td>445.89</td>\n",
       "      <td>18.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.34</td>\n",
       "      <td>-91.01</td>\n",
       "      <td>-99.84</td>\n",
       "      <td>-106.65</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-28.94</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-71.98</td>\n",
       "      <td>-7.91</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.82</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>192.25</td>\n",
       "      <td>53.71</td>\n",
       "      <td>49.12</td>\n",
       "      <td>67.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.03</td>\n",
       "      <td>-34.88</td>\n",
       "      <td>-34.81</td>\n",
       "      <td>-48.63</td>\n",
       "      <td>-14.17</td>\n",
       "      <td>4.40</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-21.04</td>\n",
       "      <td>-28.06</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>25.94</td>\n",
       "      <td>30.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>309.99</td>\n",
       "      <td>15.18</td>\n",
       "      <td>42.85</td>\n",
       "      <td>69.84</td>\n",
       "      <td>...</td>\n",
       "      <td>4.96</td>\n",
       "      <td>6.39</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.13</td>\n",
       "      <td>13.99</td>\n",
       "      <td>16.96</td>\n",
       "      <td>11.30</td>\n",
       "      <td>8.37</td>\n",
       "      <td>55.29</td>\n",
       "      <td>以下において、当社グループの事業展開上のリスク要因となる可能性があると考えられる主な事項を記...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.15</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.79</td>\n",
       "      <td>30.26</td>\n",
       "      <td>36.38</td>\n",
       "      <td>2.63</td>\n",
       "      <td>95.92</td>\n",
       "      <td>96.99</td>\n",
       "      <td>66.94</td>\n",
       "      <td>58.92</td>\n",
       "      <td>...</td>\n",
       "      <td>3.44</td>\n",
       "      <td>40.28</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1.70</td>\n",
       "      <td>67.83</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>14.57</td>\n",
       "      <td>8.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>16.63</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.68</td>\n",
       "      <td>122.27</td>\n",
       "      <td>79.58</td>\n",
       "      <td>241.40</td>\n",
       "      <td>27.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-13.74</td>\n",
       "      <td>-15.80</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>1.56</td>\n",
       "      <td>21.28</td>\n",
       "      <td>6.03</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.75</td>\n",
       "      <td>当社グループの経営成績及び財政状態は、今後起こりうる様々な要因により影響を受ける可能性があり...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X19    X20   X29     X47    X51    X54     X59     X62      X63    X64  \\\n",
       "0   -56.50 -12.14  4.35 -143.28   0.00  -3.17  217.91   48.72   173.50  36.20   \n",
       "1     4.33   1.34  1.36    1.67   0.00  81.72   51.61  123.96  1288.35   7.12   \n",
       "2  -220.42   0.81  1.81  -23.60   0.00  -7.36   56.14  206.41   844.44  10.64   \n",
       "3     9.13   2.01  0.18    2.24   0.00   8.37  132.09   30.43   204.28  32.86   \n",
       "4    19.44   8.63  1.91   18.37   0.00  10.39   39.96   14.71   283.68  26.06   \n",
       "..     ...    ...   ...     ...    ...    ...     ...     ...      ...    ...   \n",
       "87   -1.10   0.00  1.06    4.42  20.61  23.69   46.37  104.47   445.89  18.27   \n",
       "88    5.82   7.83  0.00   13.00   0.84   0.00  192.25   53.71    49.12  67.05   \n",
       "89   25.94  30.94  0.00    7.39   0.00   0.07  309.99   15.18    42.85  69.84   \n",
       "90    2.15   3.50  0.79   30.26  36.38   2.63   95.92   96.99    66.94  58.92   \n",
       "91   14.57   8.28  0.23   16.63   3.25   5.68  122.27   79.58   241.40  27.25   \n",
       "\n",
       "    ...      X71     X72     X73     X74    X76     X77    X79      X80  \\\n",
       "0   ... -1102.48  333.84  257.75  228.53 -26.80  -44.75   0.00   308.94   \n",
       "1   ...   111.11  203.17  570.71 -103.33  -4.49 -838.37 -12.80 -1495.54   \n",
       "2   ...   -29.03  -50.36  -36.22  914.70 -24.20   12.38 -21.79 -2198.07   \n",
       "3   ...     9.69   33.15  295.54 -111.94  -8.85   10.06  -0.34  -114.86   \n",
       "4   ...    32.01   42.59   44.35   61.80  77.84   76.70   2.81    64.88   \n",
       "..  ...      ...     ...     ...     ...    ...     ...    ...      ...   \n",
       "87  ...   -28.34  -91.01  -99.84 -106.65  -1.26  -28.94   5.42   -71.98   \n",
       "88  ...   -23.03  -34.88  -34.81  -48.63 -14.17    4.40  -6.25   -21.04   \n",
       "89  ...     4.96    6.39    6.09    8.13  13.99   16.96  11.30     8.37   \n",
       "90  ...     3.44   40.28   47.57   -1.32   4.77    1.29  -0.14     1.70   \n",
       "91  ...     2.07  -13.74  -15.80   -0.13   1.56   21.28   6.03     2.56   \n",
       "\n",
       "      X84                                               text  \n",
       "0   -4.64  当社グループの経営成績、株価及び財務状況等に重要な影響を及ぼす可能性のある事業等のリスクには...  \n",
       "1    3.03  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "2   -2.33  当グループの経営成績、財務状況等に影響を及ぼす可能性のあるリスクには次のようなものがある。た...  \n",
       "3  -10.88  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "4  -44.19  （１）法的規制のリスク\\n　当社グループの属する建設、不動産業界は、建設業法、建築基準法、都...  \n",
       "..    ...                                                ...  \n",
       "87  -7.91  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "88 -28.06  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "89  55.29  以下において、当社グループの事業展開上のリスク要因となる可能性があると考えられる主な事項を記...  \n",
       "90  67.83  　有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影...  \n",
       "91  28.75  当社グループの経営成績及び財政状態は、今後起こりうる様々な要因により影響を受ける可能性があり...  \n",
       "\n",
       "[92 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X (train): 92 | Length of Y (train): 92\n",
      "Length of X (validation): 20 | Length of Y (validation): 20\n",
      "Length of X (test): 25 | Length of Y (test): 25\n"
     ]
    }
   ],
   "source": [
    "print('Length of X (train): {} | Length of Y (train): {}'.format(len(X_train_both), len(y_train_both)))\n",
    "print('Length of X (validation): {} | Length of Y (validation): {}'.format(len(X_val_both), len(y_val_both)))\n",
    "print('Length of X (test): {} | Length of Y (test): {}'.format(len(X_test_both), len(y_test_both)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test_both)\n",
    "# print(X_train_both['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.charfilter import *\n",
    "from janome.tokenfilter import *\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(risk_report_test):\n",
    "    \"\"\"Returns cleaned text data.\"\"\"\n",
    "    \n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/stop_words.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        stop_words = file.read()\n",
    "    \n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/stop_words_accounting.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        stop_words_acc = file.read()\n",
    "    \n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/onaji_risk_vocab.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        onaji_risk_vocab = file.read()\n",
    "        \n",
    "    \n",
    "    char_filters = [UnicodeNormalizeCharFilter(), \n",
    "                    RegexReplaceCharFilter(u'キャッシュ・フロー', u'キャッシュフロー')]\n",
    "    tokenizer = Tokenizer()\n",
    "    token_filters = [CompoundNounFilter(), \n",
    "                     POSStopFilter(['記号','助詞', '数', '数接続', '接続詞','連体詞', '接頭詞', '名詞,数','非自立', '代名詞', '自動詞', '他動詞']), \n",
    "                     LowerCaseFilter()]\n",
    "\n",
    "\n",
    "    a = Analyzer(char_filters=char_filters, tokenizer=tokenizer, token_filters=token_filters)\n",
    "    \n",
    "    def filter(text):\n",
    "        \"\"\"\n",
    "        :param text: str\n",
    "        :rtype : str\n",
    "        \"\"\"\n",
    "       # アルファベットと半角英数と記号と改行とタブを排除\n",
    "        text = re.sub(r'[a-zA-Z0-9¥\"¥.¥,¥@]+', '', text)\n",
    "        text = re.sub(r'[!\"“#$%&()\\*\\+\\-\\.,\\/:;<=>?@\\[\\\\\\]^_`{|}~]', '', text)\n",
    "        text = re.sub(r'[\\n|\\r|\\t]', '', text)\n",
    "        \n",
    "        # 日本語以外の文字を排除\n",
    "        jp_chartype_tokenizer = nltk.RegexpTokenizer(u'([ぁ-んー]+|[ァ-ンー]+|[\\u4e00-\\u9FFF]+|[ぁ-んァ-ンー\\u4e00-\\u9FFF]+)')\n",
    "        text = ''.join(jp_chartype_tokenizer.tokenize(text))\n",
    "        \n",
    "        return text\n",
    "\n",
    "    nosymbol_test = filter(risk_report_test)\n",
    "    \n",
    "    doc = []\n",
    "    for token in a.analyze(nosymbol_test):\n",
    "        doc.append(token.surface)\n",
    "    doc = [x for x in doc if x not in stop_words]\n",
    "    doc = [x for x in doc if x not in stop_words_acc]\n",
    "    doc = [x for x in doc if x not in onaji_risk_vocab]\n",
    "    doc = np.array(doc)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "#     corpus = ' '.join(doc)\n",
    "#     corpus = [corpus]\n",
    "    \n",
    "#     return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      当社グループの経営成績、株価及び財務状況等に重要な影響を及ぼす可能性のある事業等のリスクには...\n",
      "1      有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...\n",
      "2      当グループの経営成績、財務状況等に影響を及ぼす可能性のあるリスクには次のようなものがある。た...\n",
      "3      有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...\n",
      "4      （１）法的規制のリスク\\n　当社グループの属する建設、不動産業界は、建設業法、建築基準法、都...\n",
      "                             ...                        \n",
      "132    当社及び当社の関係会社（以下「当社グループ」といいます）の経営成績、株価及び財務状況等に影響...\n",
      "133    以下において、当社グループの事業展開上、リスク要因となる可能性があると考えられる主な事項を記...\n",
      "134    当社グループの経営成績及び財政状態などに重要な影響を及ぼす可能性がある事項には、以下のような...\n",
      "135    本書に記載した事業の状況、経理に関する事項のうち、投資家の判断に重要な影響を及ぼす可能性のあ...\n",
      "136    有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...\n",
      "Name: text, Length: 137, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_text_only = pd.concat([X_train_both['text'], X_val_both['text'], X_test_both['text']], ignore_index=True)\n",
    "print(df_text_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_text_only[91]) #train 0 a 92\n",
    "# print(df_text_only[111]) #val 92 a 112\n",
    "# print(df_text_only[112]) #test 112 a 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file_transformer = CountVectorizer(analyzer=clean_data).fit(df_text_only)\n",
    "# print(clean_file_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11888\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_file_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (137, 11888)\n"
     ]
    }
   ],
   "source": [
    "clean_file_bow = clean_file_transformer.transform(df_text_only)\n",
    "# print(clean_file_bow)\n",
    "print('Shape of Sparse Matrix: ', clean_file_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 11888)\n"
     ]
    }
   ],
   "source": [
    "transformer_tfidf = TfidfTransformer().fit(clean_file_bow)\n",
    "clean_file_tfidf = transformer_tfidf.transform(clean_file_bow)\n",
    "\n",
    "# print(clean_file_tfidf)\n",
    "print(clean_file_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X29</th>\n",
       "      <th>X47</th>\n",
       "      <th>X51</th>\n",
       "      <th>X54</th>\n",
       "      <th>X59</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>...</th>\n",
       "      <th>X71</th>\n",
       "      <th>X72</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X79</th>\n",
       "      <th>X80</th>\n",
       "      <th>X84</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-56.50</td>\n",
       "      <td>-12.14</td>\n",
       "      <td>4.35</td>\n",
       "      <td>-143.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.17</td>\n",
       "      <td>217.91</td>\n",
       "      <td>48.72</td>\n",
       "      <td>173.50</td>\n",
       "      <td>36.20</td>\n",
       "      <td>...</td>\n",
       "      <td>-1102.48</td>\n",
       "      <td>333.84</td>\n",
       "      <td>257.75</td>\n",
       "      <td>228.53</td>\n",
       "      <td>-26.80</td>\n",
       "      <td>-44.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>308.94</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>当社グループの経営成績、株価及び財務状況等に重要な影響を及ぼす可能性のある事業等のリスクには...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.33</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.72</td>\n",
       "      <td>51.61</td>\n",
       "      <td>123.96</td>\n",
       "      <td>1288.35</td>\n",
       "      <td>7.12</td>\n",
       "      <td>...</td>\n",
       "      <td>111.11</td>\n",
       "      <td>203.17</td>\n",
       "      <td>570.71</td>\n",
       "      <td>-103.33</td>\n",
       "      <td>-4.49</td>\n",
       "      <td>-838.37</td>\n",
       "      <td>-12.80</td>\n",
       "      <td>-1495.54</td>\n",
       "      <td>3.03</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-220.42</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-23.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.36</td>\n",
       "      <td>56.14</td>\n",
       "      <td>206.41</td>\n",
       "      <td>844.44</td>\n",
       "      <td>10.64</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.03</td>\n",
       "      <td>-50.36</td>\n",
       "      <td>-36.22</td>\n",
       "      <td>914.70</td>\n",
       "      <td>-24.20</td>\n",
       "      <td>12.38</td>\n",
       "      <td>-21.79</td>\n",
       "      <td>-2198.07</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>当グループの経営成績、財務状況等に影響を及ぼす可能性のあるリスクには次のようなものがある。た...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.13</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.37</td>\n",
       "      <td>132.09</td>\n",
       "      <td>30.43</td>\n",
       "      <td>204.28</td>\n",
       "      <td>32.86</td>\n",
       "      <td>...</td>\n",
       "      <td>9.69</td>\n",
       "      <td>33.15</td>\n",
       "      <td>295.54</td>\n",
       "      <td>-111.94</td>\n",
       "      <td>-8.85</td>\n",
       "      <td>10.06</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-114.86</td>\n",
       "      <td>-10.88</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.44</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1.91</td>\n",
       "      <td>18.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.39</td>\n",
       "      <td>39.96</td>\n",
       "      <td>14.71</td>\n",
       "      <td>283.68</td>\n",
       "      <td>26.06</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>42.59</td>\n",
       "      <td>44.35</td>\n",
       "      <td>61.80</td>\n",
       "      <td>77.84</td>\n",
       "      <td>76.70</td>\n",
       "      <td>2.81</td>\n",
       "      <td>64.88</td>\n",
       "      <td>-44.19</td>\n",
       "      <td>（１）法的規制のリスク\\n　当社グループの属する建設、不動産業界は、建設業法、建築基準法、都...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.42</td>\n",
       "      <td>20.61</td>\n",
       "      <td>23.69</td>\n",
       "      <td>46.37</td>\n",
       "      <td>104.47</td>\n",
       "      <td>445.89</td>\n",
       "      <td>18.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.34</td>\n",
       "      <td>-91.01</td>\n",
       "      <td>-99.84</td>\n",
       "      <td>-106.65</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-28.94</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-71.98</td>\n",
       "      <td>-7.91</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.82</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>192.25</td>\n",
       "      <td>53.71</td>\n",
       "      <td>49.12</td>\n",
       "      <td>67.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.03</td>\n",
       "      <td>-34.88</td>\n",
       "      <td>-34.81</td>\n",
       "      <td>-48.63</td>\n",
       "      <td>-14.17</td>\n",
       "      <td>4.40</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-21.04</td>\n",
       "      <td>-28.06</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>25.94</td>\n",
       "      <td>30.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>309.99</td>\n",
       "      <td>15.18</td>\n",
       "      <td>42.85</td>\n",
       "      <td>69.84</td>\n",
       "      <td>...</td>\n",
       "      <td>4.96</td>\n",
       "      <td>6.39</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.13</td>\n",
       "      <td>13.99</td>\n",
       "      <td>16.96</td>\n",
       "      <td>11.30</td>\n",
       "      <td>8.37</td>\n",
       "      <td>55.29</td>\n",
       "      <td>以下において、当社グループの事業展開上のリスク要因となる可能性があると考えられる主な事項を記...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.15</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.79</td>\n",
       "      <td>30.26</td>\n",
       "      <td>36.38</td>\n",
       "      <td>2.63</td>\n",
       "      <td>95.92</td>\n",
       "      <td>96.99</td>\n",
       "      <td>66.94</td>\n",
       "      <td>58.92</td>\n",
       "      <td>...</td>\n",
       "      <td>3.44</td>\n",
       "      <td>40.28</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1.70</td>\n",
       "      <td>67.83</td>\n",
       "      <td>有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>14.57</td>\n",
       "      <td>8.28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>16.63</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.68</td>\n",
       "      <td>122.27</td>\n",
       "      <td>79.58</td>\n",
       "      <td>241.40</td>\n",
       "      <td>27.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-13.74</td>\n",
       "      <td>-15.80</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>1.56</td>\n",
       "      <td>21.28</td>\n",
       "      <td>6.03</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.75</td>\n",
       "      <td>当社グループの経営成績及び財政状態は、今後起こりうる様々な要因により影響を受ける可能性があり...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X19    X20   X29     X47    X51    X54     X59     X62      X63    X64  \\\n",
       "0   -56.50 -12.14  4.35 -143.28   0.00  -3.17  217.91   48.72   173.50  36.20   \n",
       "1     4.33   1.34  1.36    1.67   0.00  81.72   51.61  123.96  1288.35   7.12   \n",
       "2  -220.42   0.81  1.81  -23.60   0.00  -7.36   56.14  206.41   844.44  10.64   \n",
       "3     9.13   2.01  0.18    2.24   0.00   8.37  132.09   30.43   204.28  32.86   \n",
       "4    19.44   8.63  1.91   18.37   0.00  10.39   39.96   14.71   283.68  26.06   \n",
       "..     ...    ...   ...     ...    ...    ...     ...     ...      ...    ...   \n",
       "87   -1.10   0.00  1.06    4.42  20.61  23.69   46.37  104.47   445.89  18.27   \n",
       "88    5.82   7.83  0.00   13.00   0.84   0.00  192.25   53.71    49.12  67.05   \n",
       "89   25.94  30.94  0.00    7.39   0.00   0.07  309.99   15.18    42.85  69.84   \n",
       "90    2.15   3.50  0.79   30.26  36.38   2.63   95.92   96.99    66.94  58.92   \n",
       "91   14.57   8.28  0.23   16.63   3.25   5.68  122.27   79.58   241.40  27.25   \n",
       "\n",
       "    ...      X71     X72     X73     X74    X76     X77    X79      X80  \\\n",
       "0   ... -1102.48  333.84  257.75  228.53 -26.80  -44.75   0.00   308.94   \n",
       "1   ...   111.11  203.17  570.71 -103.33  -4.49 -838.37 -12.80 -1495.54   \n",
       "2   ...   -29.03  -50.36  -36.22  914.70 -24.20   12.38 -21.79 -2198.07   \n",
       "3   ...     9.69   33.15  295.54 -111.94  -8.85   10.06  -0.34  -114.86   \n",
       "4   ...    32.01   42.59   44.35   61.80  77.84   76.70   2.81    64.88   \n",
       "..  ...      ...     ...     ...     ...    ...     ...    ...      ...   \n",
       "87  ...   -28.34  -91.01  -99.84 -106.65  -1.26  -28.94   5.42   -71.98   \n",
       "88  ...   -23.03  -34.88  -34.81  -48.63 -14.17    4.40  -6.25   -21.04   \n",
       "89  ...     4.96    6.39    6.09    8.13  13.99   16.96  11.30     8.37   \n",
       "90  ...     3.44   40.28   47.57   -1.32   4.77    1.29  -0.14     1.70   \n",
       "91  ...     2.07  -13.74  -15.80   -0.13   1.56   21.28   6.03     2.56   \n",
       "\n",
       "      X84                                               text  \n",
       "0   -4.64  当社グループの経営成績、株価及び財務状況等に重要な影響を及ぼす可能性のある事業等のリスクには...  \n",
       "1    3.03  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "2   -2.33  当グループの経営成績、財務状況等に影響を及ぼす可能性のあるリスクには次のようなものがある。た...  \n",
       "3  -10.88  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "4  -44.19  （１）法的規制のリスク\\n　当社グループの属する建設、不動産業界は、建設業法、建築基準法、都...  \n",
       "..    ...                                                ...  \n",
       "87  -7.91  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "88 -28.06  有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影響...  \n",
       "89  55.29  以下において、当社グループの事業展開上のリスク要因となる可能性があると考えられる主な事項を記...  \n",
       "90  67.83  　有価証券報告書に記載した事業の状況、経理の状況等に関する事項のうち、投資者の判断に重要な影...  \n",
       "91  28.75  当社グループの経営成績及び財政状態は、今後起こりうる様々な要因により影響を受ける可能性があり...  \n",
       "\n",
       "[92 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_ratio = scaler.fit_transform(X_train_ratio.drop('text', axis=1))\n",
    "X_val_ratio = scaler.transform(X_val_ratio.drop('text', axis=1))\n",
    "X_test_ratio = scaler.transform(X_test_ratio.drop('text', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION TASK - NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 22) (20, 22) (25, 22)\n"
     ]
    }
   ],
   "source": [
    "# RATIOS\n",
    "Xtrain_ratio = pd.DataFrame(X_train_ratio)\n",
    "Xval_ratio = pd.DataFrame(X_val_ratio)\n",
    "Xtest_ratio = pd.DataFrame(X_test_ratio)\n",
    "\n",
    "# rename columns\n",
    "Xtrain_ratio.columns = ['X19','X20','X29','X47', 'X51', 'X54', 'X59', 'X62','X63','X64','X67', 'X69', 'X70', 'X71','X72', 'X73', 'X74', 'X76','X77', 'X79', 'X80', 'X84']\n",
    "Xval_ratio.columns = ['X19','X20','X29','X47', 'X51', 'X54', 'X59', 'X62','X63','X64','X67', 'X69', 'X70', 'X71','X72', 'X73', 'X74', 'X76','X77', 'X79', 'X80', 'X84']\n",
    "Xtest_ratio.columns = ['X19','X20','X29','X47', 'X51', 'X54', 'X59', 'X62','X63','X64','X67', 'X69', 'X70', 'X71','X72', 'X73', 'X74', 'X76','X77', 'X79', 'X80', 'X84']\n",
    "\n",
    "print(Xtrain_ratio.shape, Xval_ratio.shape, Xtest_ratio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtest_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT\n",
    "X = clean_file_tfidf\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "X_train_text = X[:92]\n",
    "X_val_text = pd.DataFrame(X[92:112])\n",
    "X_test_text = pd.DataFrame(X[112:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_text.index.delete\n",
    "X_val_text = X_val_text.reset_index(drop=True)\n",
    "# X_val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text.index.delete\n",
    "X_test_text = X_test_text.reset_index(drop=True)\n",
    "# X_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 11888) (20, 11888) (25, 11888)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_text.shape, X_val_text.shape, X_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 11910) (20, 11910) (25, 11910)\n"
     ]
    }
   ],
   "source": [
    "# INPUT VALUES X\n",
    "\n",
    "X_train = pd.concat([Xtrain_ratio, X_train_text], ignore_index=True, axis=1)\n",
    "X_val = pd.concat([Xval_ratio, X_val_text], ignore_index=True, axis=1)\n",
    "X_test = pd.concat([Xtest_ratio, X_test_text], ignore_index=True, axis=1)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 1) (20, 1) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "# TARGET VALUE Y\n",
    "\n",
    "y_train = pd.DataFrame(y_train_ratio)\n",
    "y_val = pd.DataFrame(y_val_ratio)\n",
    "y_test = pd.DataFrame(y_test_ratio)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              11911000  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 11,912,001\n",
      "Trainable params: 11,912,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=1000, \n",
    "          kernel_initializer='normal', \n",
    "#           kernel_regularizer=regularizers.l2(0.02),\n",
    "          activation='relu', \n",
    "          input_dim=X_train.shape[1]),\n",
    "    Dropout(0.5),\n",
    "#     Dense(units=1000,\n",
    "#           kernel_initializer='normal',\n",
    "#           kernel_regularizer=regularizers.l2(0.02),\n",
    "#           activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "    Dense(units=1,\n",
    "          activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "3/3 - 0s - loss: 0.7047 - accuracy: 0.5000 - val_loss: 0.6842 - val_accuracy: 0.6000\n",
      "Epoch 2/2000\n",
      "3/3 - 0s - loss: 0.6090 - accuracy: 0.8696 - val_loss: 0.6669 - val_accuracy: 0.5500\n",
      "Epoch 3/2000\n",
      "3/3 - 0s - loss: 0.5297 - accuracy: 0.9565 - val_loss: 0.6495 - val_accuracy: 0.6000\n",
      "Epoch 4/2000\n",
      "3/3 - 0s - loss: 0.4481 - accuracy: 0.9783 - val_loss: 0.6310 - val_accuracy: 0.6500\n",
      "Epoch 5/2000\n",
      "3/3 - 0s - loss: 0.3622 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9000\n",
      "Epoch 6/2000\n",
      "3/3 - 0s - loss: 0.3018 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9000\n",
      "Epoch 7/2000\n",
      "3/3 - 0s - loss: 0.2490 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.9000\n",
      "Epoch 8/2000\n",
      "3/3 - 0s - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9000\n",
      "Epoch 9/2000\n",
      "3/3 - 0s - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9000\n",
      "Epoch 10/2000\n",
      "3/3 - 0s - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9000\n",
      "Epoch 11/2000\n",
      "3/3 - 0s - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9000\n",
      "Epoch 12/2000\n",
      "3/3 - 0s - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9000\n",
      "Epoch 13/2000\n",
      "3/3 - 0s - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9000\n",
      "Epoch 14/2000\n",
      "3/3 - 0s - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9000\n",
      "Epoch 15/2000\n",
      "3/3 - 0s - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.9000\n",
      "Epoch 16/2000\n",
      "3/3 - 0s - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9500\n",
      "Epoch 17/2000\n",
      "3/3 - 0s - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9500\n",
      "Epoch 18/2000\n",
      "3/3 - 0s - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "3/3 - 0s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "3/3 - 0s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9500\n",
      "Epoch 21/2000\n",
      "3/3 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9500\n",
      "Epoch 22/2000\n",
      "3/3 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9500\n",
      "Epoch 23/2000\n",
      "3/3 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9500\n",
      "Epoch 24/2000\n",
      "3/3 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9500\n",
      "Epoch 25/2000\n",
      "3/3 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9500\n",
      "Epoch 26/2000\n",
      "3/3 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9500\n",
      "Epoch 27/2000\n",
      "3/3 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9500\n",
      "Epoch 28/2000\n",
      "3/3 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9500\n",
      "Epoch 29/2000\n",
      "3/3 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9500\n",
      "Epoch 30/2000\n",
      "3/3 - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "3/3 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "3/3 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "3/3 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "3/3 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "3/3 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "3/3 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "3/3 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "3/3 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "3/3 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "3/3 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "3/3 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "3/3 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "3/3 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "3/3 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "3/3 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "3/3 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "3/3 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "3/3 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "3/3 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "3/3 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "3/3 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "3/3 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "3/3 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 1.0000\n",
      "Epoch 54/2000\n",
      "3/3 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 1.0000\n",
      "Epoch 55/2000\n",
      "3/3 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 1.0000\n",
      "Epoch 56/2000\n",
      "3/3 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 1.0000\n",
      "Epoch 57/2000\n",
      "3/3 - 0s - loss: 9.9360e-04 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 1.0000\n",
      "Epoch 58/2000\n",
      "3/3 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 1.0000\n",
      "Epoch 59/2000\n",
      "3/3 - 0s - loss: 8.6592e-04 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 1.0000\n",
      "Epoch 60/2000\n",
      "3/3 - 0s - loss: 9.0319e-04 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 1.0000\n",
      "Epoch 61/2000\n",
      "3/3 - 0s - loss: 7.9959e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 1.0000\n",
      "Epoch 62/2000\n",
      "3/3 - 0s - loss: 9.2989e-04 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 1.0000\n",
      "Epoch 63/2000\n",
      "3/3 - 0s - loss: 7.4948e-04 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 1.0000\n",
      "Epoch 64/2000\n",
      "3/3 - 0s - loss: 7.9090e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 1.0000\n",
      "Epoch 65/2000\n",
      "3/3 - 0s - loss: 8.3705e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 1.0000\n",
      "Epoch 66/2000\n",
      "3/3 - 0s - loss: 7.3002e-04 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 1.0000\n",
      "Epoch 67/2000\n",
      "3/3 - 0s - loss: 7.6463e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 1.0000\n",
      "Epoch 68/2000\n",
      "3/3 - 0s - loss: 7.0298e-04 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 1.0000\n",
      "Epoch 69/2000\n",
      "3/3 - 0s - loss: 6.6925e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 1.0000\n",
      "Epoch 70/2000\n",
      "3/3 - 0s - loss: 6.5022e-04 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 1.0000\n",
      "Epoch 71/2000\n",
      "3/3 - 0s - loss: 5.5646e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 1.0000\n",
      "Epoch 72/2000\n",
      "3/3 - 0s - loss: 7.0879e-04 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 1.0000\n",
      "Epoch 73/2000\n",
      "3/3 - 0s - loss: 6.9906e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 1.0000\n",
      "Epoch 74/2000\n",
      "3/3 - 0s - loss: 5.8074e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 1.0000\n",
      "Epoch 75/2000\n",
      "3/3 - 0s - loss: 5.4460e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 1.0000\n",
      "Epoch 76/2000\n",
      "3/3 - 0s - loss: 5.8217e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 1.0000\n",
      "Epoch 77/2000\n",
      "3/3 - 0s - loss: 4.9899e-04 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 1.0000\n",
      "Epoch 78/2000\n",
      "3/3 - 0s - loss: 4.9681e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 1.0000\n",
      "Epoch 79/2000\n",
      "3/3 - 0s - loss: 4.8602e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 1.0000\n",
      "Epoch 80/2000\n",
      "3/3 - 0s - loss: 4.8036e-04 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 1.0000\n",
      "Epoch 81/2000\n",
      "3/3 - 0s - loss: 4.5283e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 1.0000\n",
      "Epoch 82/2000\n",
      "3/3 - 0s - loss: 4.8315e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/2000\n",
      "3/3 - 0s - loss: 5.8290e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 1.0000\n",
      "Epoch 84/2000\n",
      "3/3 - 0s - loss: 4.6284e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 1.0000\n",
      "Epoch 85/2000\n",
      "3/3 - 0s - loss: 4.0946e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 1.0000\n",
      "Epoch 86/2000\n",
      "3/3 - 0s - loss: 4.1763e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 1.0000\n",
      "Epoch 87/2000\n",
      "3/3 - 0s - loss: 4.0597e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 1.0000\n",
      "Epoch 88/2000\n",
      "3/3 - 0s - loss: 4.0286e-04 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 1.0000\n",
      "Epoch 89/2000\n",
      "3/3 - 0s - loss: 4.2285e-04 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 1.0000\n",
      "Epoch 90/2000\n",
      "3/3 - 0s - loss: 4.1216e-04 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 1.0000\n",
      "Epoch 91/2000\n",
      "3/3 - 0s - loss: 3.6308e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 1.0000\n",
      "Epoch 92/2000\n",
      "3/3 - 0s - loss: 4.5238e-04 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 1.0000\n",
      "Epoch 93/2000\n",
      "3/3 - 0s - loss: 3.5156e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 1.0000\n",
      "Epoch 94/2000\n",
      "3/3 - 0s - loss: 3.0640e-04 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 1.0000\n",
      "Epoch 95/2000\n",
      "3/3 - 0s - loss: 3.9653e-04 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 1.0000\n",
      "Epoch 96/2000\n",
      "3/3 - 0s - loss: 2.8574e-04 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
      "Epoch 97/2000\n",
      "3/3 - 0s - loss: 2.7789e-04 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 1.0000\n",
      "Epoch 98/2000\n",
      "3/3 - 0s - loss: 2.7894e-04 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 1.0000\n",
      "Epoch 99/2000\n",
      "3/3 - 0s - loss: 2.9658e-04 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 1.0000\n",
      "Epoch 100/2000\n",
      "3/3 - 0s - loss: 2.9396e-04 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 1.0000\n",
      "Epoch 101/2000\n",
      "3/3 - 0s - loss: 3.2527e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 1.0000\n",
      "Epoch 102/2000\n",
      "3/3 - 0s - loss: 3.0051e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 1.0000\n",
      "Epoch 103/2000\n",
      "3/3 - 0s - loss: 2.8709e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 1.0000\n",
      "Epoch 104/2000\n",
      "3/3 - 0s - loss: 2.8434e-04 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 1.0000\n",
      "Epoch 105/2000\n",
      "3/3 - 0s - loss: 2.6702e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 1.0000\n",
      "Epoch 106/2000\n",
      "3/3 - 0s - loss: 2.5439e-04 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 1.0000\n",
      "Epoch 107/2000\n",
      "3/3 - 0s - loss: 2.4846e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 1.0000\n",
      "Epoch 108/2000\n",
      "3/3 - 0s - loss: 2.5791e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 1.0000\n",
      "Epoch 109/2000\n",
      "3/3 - 0s - loss: 2.3845e-04 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 1.0000\n",
      "Epoch 110/2000\n",
      "3/3 - 0s - loss: 2.4114e-04 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 1.0000\n",
      "Epoch 111/2000\n",
      "3/3 - 0s - loss: 2.6487e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 1.0000\n",
      "Epoch 112/2000\n",
      "3/3 - 0s - loss: 2.6420e-04 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 1.0000\n",
      "Epoch 113/2000\n",
      "3/3 - 0s - loss: 1.9750e-04 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 1.0000\n",
      "Epoch 114/2000\n",
      "3/3 - 0s - loss: 2.4379e-04 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 1.0000\n",
      "Epoch 115/2000\n",
      "3/3 - 0s - loss: 2.0668e-04 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 1.0000\n",
      "Epoch 116/2000\n",
      "3/3 - 0s - loss: 2.6096e-04 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 1.0000\n",
      "Epoch 117/2000\n",
      "3/3 - 0s - loss: 1.6573e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 1.0000\n",
      "Epoch 118/2000\n",
      "3/3 - 0s - loss: 2.1634e-04 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 1.0000\n",
      "Epoch 119/2000\n",
      "3/3 - 0s - loss: 1.7083e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 1.0000\n",
      "Epoch 120/2000\n",
      "3/3 - 0s - loss: 2.0896e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 1.0000\n",
      "Epoch 121/2000\n",
      "3/3 - 0s - loss: 1.7694e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 1.0000\n",
      "Epoch 122/2000\n",
      "3/3 - 0s - loss: 2.2319e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 1.0000\n",
      "Epoch 123/2000\n",
      "3/3 - 0s - loss: 1.7610e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 1.0000\n",
      "Epoch 124/2000\n",
      "3/3 - 0s - loss: 1.7087e-04 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 1.0000\n",
      "Epoch 125/2000\n",
      "3/3 - 0s - loss: 1.9192e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 1.0000\n",
      "Epoch 126/2000\n",
      "3/3 - 0s - loss: 1.9880e-04 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 1.0000\n",
      "Epoch 127/2000\n",
      "3/3 - 0s - loss: 1.9233e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 1.0000\n",
      "Epoch 128/2000\n",
      "3/3 - 0s - loss: 1.7263e-04 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 1.0000\n",
      "Epoch 129/2000\n",
      "3/3 - 0s - loss: 1.6014e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 1.0000\n",
      "Epoch 130/2000\n",
      "3/3 - 0s - loss: 1.3816e-04 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 1.0000\n",
      "Epoch 131/2000\n",
      "3/3 - 0s - loss: 1.5476e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 1.0000\n",
      "Epoch 132/2000\n",
      "3/3 - 0s - loss: 1.6980e-04 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 1.0000\n",
      "Epoch 133/2000\n",
      "3/3 - 0s - loss: 1.6737e-04 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 1.0000\n",
      "Epoch 134/2000\n",
      "3/3 - 0s - loss: 1.7477e-04 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 1.0000\n",
      "Epoch 135/2000\n",
      "3/3 - 0s - loss: 1.8533e-04 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 1.0000\n",
      "Epoch 136/2000\n",
      "3/3 - 0s - loss: 1.4792e-04 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 1.0000\n",
      "Epoch 137/2000\n",
      "3/3 - 0s - loss: 1.4440e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 1.0000\n",
      "Epoch 138/2000\n",
      "3/3 - 0s - loss: 1.5450e-04 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 1.0000\n",
      "Epoch 139/2000\n",
      "3/3 - 0s - loss: 1.3729e-04 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 1.0000\n",
      "Epoch 140/2000\n",
      "3/3 - 0s - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 1.0000\n",
      "Epoch 141/2000\n",
      "3/3 - 0s - loss: 1.7620e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 1.0000\n",
      "Epoch 142/2000\n",
      "3/3 - 0s - loss: 1.4995e-04 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 1.0000\n",
      "Epoch 143/2000\n",
      "3/3 - 0s - loss: 1.4540e-04 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 1.0000\n",
      "Epoch 144/2000\n",
      "3/3 - 0s - loss: 1.3707e-04 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 1.0000\n",
      "Epoch 145/2000\n",
      "3/3 - 0s - loss: 1.4714e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 1.0000\n",
      "Epoch 146/2000\n",
      "3/3 - 0s - loss: 1.3010e-04 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 1.0000\n",
      "Epoch 147/2000\n",
      "3/3 - 0s - loss: 1.1892e-04 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 1.0000\n",
      "Epoch 148/2000\n",
      "3/3 - 0s - loss: 1.2876e-04 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 1.0000\n",
      "Epoch 149/2000\n",
      "3/3 - 0s - loss: 1.0708e-04 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 1.0000\n",
      "Epoch 150/2000\n",
      "3/3 - 0s - loss: 1.1194e-04 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 1.0000\n",
      "Epoch 151/2000\n",
      "3/3 - 0s - loss: 1.0826e-04 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 1.0000\n",
      "Epoch 152/2000\n",
      "3/3 - 0s - loss: 1.3687e-04 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 1.0000\n",
      "Epoch 153/2000\n",
      "3/3 - 0s - loss: 1.1922e-04 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 1.0000\n",
      "Epoch 154/2000\n",
      "3/3 - 0s - loss: 1.1758e-04 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 1.0000\n",
      "Epoch 155/2000\n",
      "3/3 - 0s - loss: 1.1456e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 1.0000\n",
      "Epoch 156/2000\n",
      "3/3 - 0s - loss: 1.1628e-04 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 1.0000\n",
      "Epoch 157/2000\n",
      "3/3 - 0s - loss: 1.1257e-04 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 1.0000\n",
      "Epoch 158/2000\n",
      "3/3 - 0s - loss: 1.0247e-04 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 1.0000\n",
      "Epoch 159/2000\n",
      "3/3 - 0s - loss: 9.8011e-05 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 1.0000\n",
      "Epoch 160/2000\n",
      "3/3 - 0s - loss: 1.0572e-04 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 1.0000\n",
      "Epoch 161/2000\n",
      "3/3 - 0s - loss: 1.0160e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/2000\n",
      "3/3 - 0s - loss: 1.0578e-04 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 1.0000\n",
      "Epoch 163/2000\n",
      "3/3 - 0s - loss: 9.8804e-05 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 1.0000\n",
      "Epoch 164/2000\n",
      "3/3 - 0s - loss: 9.8047e-05 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 1.0000\n",
      "Epoch 165/2000\n",
      "3/3 - 0s - loss: 1.0061e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 1.0000\n",
      "Epoch 166/2000\n",
      "3/3 - 0s - loss: 9.8854e-05 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 1.0000\n",
      "Epoch 167/2000\n",
      "3/3 - 0s - loss: 9.8218e-05 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 1.0000\n",
      "Epoch 168/2000\n",
      "3/3 - 0s - loss: 1.0857e-04 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 1.0000\n",
      "Epoch 169/2000\n",
      "3/3 - 0s - loss: 9.5257e-05 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 1.0000\n",
      "Epoch 170/2000\n",
      "3/3 - 0s - loss: 9.8963e-05 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 1.0000\n",
      "Epoch 171/2000\n",
      "3/3 - 0s - loss: 1.0281e-04 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 1.0000\n",
      "Epoch 172/2000\n",
      "3/3 - 0s - loss: 8.5658e-05 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 1.0000\n",
      "Epoch 173/2000\n",
      "3/3 - 0s - loss: 9.2917e-05 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 1.0000\n",
      "Epoch 174/2000\n",
      "3/3 - 0s - loss: 8.5390e-05 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 1.0000\n",
      "Epoch 175/2000\n",
      "3/3 - 0s - loss: 8.4656e-05 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 1.0000\n",
      "Epoch 176/2000\n",
      "3/3 - 0s - loss: 8.5228e-05 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 1.0000\n",
      "Epoch 177/2000\n",
      "3/3 - 0s - loss: 8.8463e-05 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 1.0000\n",
      "Epoch 178/2000\n",
      "3/3 - 0s - loss: 7.6311e-05 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 1.0000\n",
      "Epoch 179/2000\n",
      "3/3 - 0s - loss: 7.5166e-05 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 1.0000\n",
      "Epoch 180/2000\n",
      "3/3 - 0s - loss: 8.6342e-05 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 1.0000\n",
      "Epoch 181/2000\n",
      "3/3 - 0s - loss: 8.7269e-05 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 1.0000\n",
      "Epoch 182/2000\n",
      "3/3 - 0s - loss: 7.4039e-05 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 1.0000\n",
      "Epoch 183/2000\n",
      "3/3 - 0s - loss: 6.8650e-05 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 1.0000\n",
      "Epoch 184/2000\n",
      "3/3 - 0s - loss: 6.3648e-05 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 1.0000\n",
      "Epoch 185/2000\n",
      "3/3 - 0s - loss: 6.5632e-05 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 1.0000\n",
      "Epoch 186/2000\n",
      "3/3 - 0s - loss: 8.3683e-05 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 1.0000\n",
      "Epoch 187/2000\n",
      "3/3 - 0s - loss: 9.0058e-05 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 1.0000\n",
      "Epoch 188/2000\n",
      "3/3 - 0s - loss: 7.7046e-05 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 1.0000\n",
      "Epoch 189/2000\n",
      "3/3 - 0s - loss: 7.4356e-05 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 1.0000\n",
      "Epoch 190/2000\n",
      "3/3 - 0s - loss: 6.4065e-05 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 1.0000\n",
      "Epoch 191/2000\n",
      "3/3 - 0s - loss: 8.4091e-05 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 1.0000\n",
      "Epoch 192/2000\n",
      "3/3 - 0s - loss: 8.1422e-05 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 1.0000\n",
      "Epoch 193/2000\n",
      "3/3 - 0s - loss: 7.3411e-05 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 1.0000\n",
      "Epoch 194/2000\n",
      "3/3 - 0s - loss: 6.8053e-05 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 1.0000\n",
      "Epoch 195/2000\n",
      "3/3 - 0s - loss: 8.3393e-05 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
      "Epoch 196/2000\n",
      "3/3 - 0s - loss: 5.9797e-05 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 1.0000\n",
      "Epoch 197/2000\n",
      "3/3 - 0s - loss: 6.8662e-05 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 1.0000\n",
      "Epoch 198/2000\n",
      "3/3 - 0s - loss: 8.2831e-05 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 1.0000\n",
      "Epoch 199/2000\n",
      "3/3 - 0s - loss: 7.1971e-05 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 1.0000\n",
      "Epoch 200/2000\n",
      "3/3 - 0s - loss: 6.3821e-05 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 1.0000\n",
      "Epoch 201/2000\n",
      "3/3 - 0s - loss: 6.3954e-05 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 1.0000\n",
      "Epoch 202/2000\n",
      "3/3 - 0s - loss: 6.4592e-05 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 1.0000\n",
      "Epoch 203/2000\n",
      "3/3 - 0s - loss: 6.2094e-05 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 1.0000\n",
      "Epoch 204/2000\n",
      "3/3 - 0s - loss: 6.9675e-05 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 1.0000\n",
      "Epoch 205/2000\n",
      "3/3 - 0s - loss: 7.8517e-05 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 1.0000\n",
      "Epoch 206/2000\n",
      "3/3 - 0s - loss: 7.7259e-05 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 1.0000\n",
      "Epoch 207/2000\n",
      "3/3 - 0s - loss: 6.4308e-05 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 1.0000\n",
      "Epoch 208/2000\n",
      "3/3 - 0s - loss: 5.2634e-05 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 1.0000\n",
      "Epoch 209/2000\n",
      "3/3 - 0s - loss: 5.0356e-05 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 1.0000\n",
      "Epoch 210/2000\n",
      "3/3 - 0s - loss: 5.9229e-05 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 1.0000\n",
      "Epoch 211/2000\n",
      "3/3 - 0s - loss: 5.3845e-05 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 1.0000\n",
      "Epoch 212/2000\n",
      "3/3 - 0s - loss: 7.3476e-05 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 1.0000\n",
      "Epoch 213/2000\n",
      "3/3 - 0s - loss: 5.3849e-05 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 1.0000\n",
      "Epoch 214/2000\n",
      "3/3 - 0s - loss: 5.3994e-05 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 1.0000\n",
      "Epoch 215/2000\n",
      "3/3 - 0s - loss: 6.5824e-05 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 1.0000\n",
      "Epoch 216/2000\n",
      "3/3 - 0s - loss: 6.4017e-05 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 1.0000\n",
      "Epoch 217/2000\n",
      "3/3 - 0s - loss: 5.9195e-05 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 1.0000\n",
      "Epoch 218/2000\n",
      "3/3 - 0s - loss: 5.3905e-05 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 1.0000\n",
      "Epoch 219/2000\n",
      "3/3 - 0s - loss: 7.1185e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 1.0000\n",
      "Epoch 220/2000\n",
      "3/3 - 0s - loss: 4.4772e-05 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 1.0000\n",
      "Epoch 221/2000\n",
      "3/3 - 0s - loss: 4.7199e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 1.0000\n",
      "Epoch 222/2000\n",
      "3/3 - 0s - loss: 4.8613e-05 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 1.0000\n",
      "Epoch 223/2000\n",
      "3/3 - 0s - loss: 5.5166e-05 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 1.0000\n",
      "Epoch 224/2000\n",
      "3/3 - 0s - loss: 4.2648e-05 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 1.0000\n",
      "Epoch 225/2000\n",
      "3/3 - 0s - loss: 6.6522e-05 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 1.0000\n",
      "Epoch 226/2000\n",
      "3/3 - 0s - loss: 5.5497e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
      "Epoch 227/2000\n",
      "3/3 - 0s - loss: 5.3713e-05 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 1.0000\n",
      "Epoch 228/2000\n",
      "3/3 - 0s - loss: 4.8396e-05 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 1.0000\n",
      "Epoch 229/2000\n",
      "3/3 - 0s - loss: 4.3884e-05 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 1.0000\n",
      "Epoch 230/2000\n",
      "3/3 - 0s - loss: 4.3731e-05 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 1.0000\n",
      "Epoch 231/2000\n",
      "3/3 - 0s - loss: 5.6905e-05 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 1.0000\n",
      "Epoch 232/2000\n",
      "3/3 - 0s - loss: 4.6006e-05 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 1.0000\n",
      "Epoch 233/2000\n",
      "3/3 - 0s - loss: 4.5645e-05 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
      "Epoch 234/2000\n",
      "3/3 - 0s - loss: 5.6549e-05 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 1.0000\n",
      "Epoch 235/2000\n",
      "3/3 - 0s - loss: 5.1642e-05 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 1.0000\n",
      "Epoch 236/2000\n",
      "3/3 - 0s - loss: 5.1843e-05 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 1.0000\n",
      "Epoch 237/2000\n",
      "3/3 - 0s - loss: 4.3606e-05 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 1.0000\n",
      "Epoch 238/2000\n",
      "3/3 - 0s - loss: 5.3312e-05 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 1.0000\n",
      "Epoch 239/2000\n",
      "3/3 - 0s - loss: 4.1714e-05 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 1.0000\n",
      "Epoch 240/2000\n",
      "3/3 - 0s - loss: 4.0907e-05 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2000\n",
      "3/3 - 0s - loss: 3.8503e-05 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 1.0000\n",
      "Epoch 242/2000\n",
      "3/3 - 0s - loss: 4.5540e-05 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 1.0000\n",
      "Epoch 243/2000\n",
      "3/3 - 0s - loss: 4.4216e-05 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 1.0000\n",
      "Epoch 244/2000\n",
      "3/3 - 0s - loss: 3.8037e-05 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 1.0000\n",
      "Epoch 245/2000\n",
      "3/3 - 0s - loss: 4.6508e-05 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
      "Epoch 246/2000\n",
      "3/3 - 0s - loss: 3.2173e-05 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 1.0000\n",
      "Epoch 247/2000\n",
      "3/3 - 0s - loss: 3.8814e-05 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
      "Epoch 248/2000\n",
      "3/3 - 0s - loss: 4.1517e-05 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 1.0000\n",
      "Epoch 249/2000\n",
      "3/3 - 0s - loss: 4.8069e-05 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 1.0000\n",
      "Epoch 250/2000\n",
      "3/3 - 0s - loss: 4.6544e-05 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 1.0000\n",
      "Epoch 251/2000\n",
      "3/3 - 0s - loss: 4.3448e-05 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 1.0000\n",
      "Epoch 252/2000\n",
      "3/3 - 0s - loss: 3.4895e-05 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 1.0000\n",
      "Epoch 253/2000\n",
      "3/3 - 0s - loss: 4.4880e-05 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 1.0000\n",
      "Epoch 254/2000\n",
      "3/3 - 0s - loss: 3.7102e-05 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
      "Epoch 255/2000\n",
      "3/3 - 0s - loss: 5.6927e-05 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
      "Epoch 256/2000\n",
      "3/3 - 0s - loss: 4.0292e-05 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
      "Epoch 257/2000\n",
      "3/3 - 0s - loss: 4.2652e-05 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
      "Epoch 258/2000\n",
      "3/3 - 0s - loss: 3.8111e-05 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 1.0000\n",
      "Epoch 259/2000\n",
      "3/3 - 0s - loss: 3.3168e-05 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 1.0000\n",
      "Epoch 260/2000\n",
      "3/3 - 0s - loss: 4.5487e-05 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 1.0000\n",
      "Epoch 261/2000\n",
      "3/3 - 0s - loss: 3.5724e-05 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 1.0000\n",
      "Epoch 262/2000\n",
      "3/3 - 0s - loss: 5.2260e-05 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 1.0000\n",
      "Epoch 263/2000\n",
      "3/3 - 0s - loss: 3.9744e-05 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 1.0000\n",
      "Epoch 264/2000\n",
      "3/3 - 0s - loss: 5.3283e-05 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 1.0000\n",
      "Epoch 265/2000\n",
      "3/3 - 0s - loss: 2.7741e-05 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 1.0000\n",
      "Epoch 266/2000\n",
      "3/3 - 0s - loss: 3.2584e-05 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 1.0000\n",
      "Epoch 267/2000\n",
      "3/3 - 0s - loss: 3.5709e-05 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
      "Epoch 268/2000\n",
      "3/3 - 0s - loss: 3.7389e-05 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 1.0000\n",
      "Epoch 269/2000\n",
      "3/3 - 0s - loss: 2.7206e-05 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 1.0000\n",
      "Epoch 270/2000\n",
      "3/3 - 0s - loss: 3.7860e-05 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 1.0000\n",
      "Epoch 271/2000\n",
      "3/3 - 0s - loss: 3.3248e-05 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 1.0000\n",
      "Epoch 272/2000\n",
      "3/3 - 0s - loss: 3.4699e-05 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 1.0000\n",
      "Epoch 273/2000\n",
      "3/3 - 0s - loss: 3.4906e-05 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 1.0000\n",
      "Epoch 274/2000\n",
      "3/3 - 0s - loss: 3.1836e-05 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 1.0000\n",
      "Epoch 275/2000\n",
      "3/3 - 0s - loss: 3.7795e-05 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 1.0000\n",
      "Epoch 276/2000\n",
      "3/3 - 0s - loss: 3.3665e-05 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 1.0000\n",
      "Epoch 277/2000\n",
      "3/3 - 0s - loss: 3.4276e-05 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 1.0000\n",
      "Epoch 278/2000\n",
      "3/3 - 0s - loss: 3.9111e-05 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 1.0000\n",
      "Epoch 279/2000\n",
      "3/3 - 0s - loss: 3.8974e-05 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 1.0000\n",
      "Epoch 280/2000\n",
      "3/3 - 0s - loss: 2.8911e-05 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 1.0000\n",
      "Epoch 281/2000\n",
      "3/3 - 0s - loss: 2.9615e-05 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 1.0000\n",
      "Epoch 282/2000\n",
      "3/3 - 0s - loss: 3.9848e-05 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 1.0000\n",
      "Epoch 283/2000\n",
      "3/3 - 0s - loss: 2.9854e-05 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 1.0000\n",
      "Epoch 284/2000\n",
      "3/3 - 0s - loss: 2.8845e-05 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 1.0000\n",
      "Epoch 285/2000\n",
      "3/3 - 0s - loss: 3.9746e-05 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 1.0000\n",
      "Epoch 286/2000\n",
      "3/3 - 0s - loss: 3.5390e-05 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 1.0000\n",
      "Epoch 287/2000\n",
      "3/3 - 0s - loss: 3.0464e-05 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 1.0000\n",
      "Epoch 288/2000\n",
      "3/3 - 0s - loss: 3.0058e-05 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
      "Epoch 289/2000\n",
      "3/3 - 0s - loss: 2.9409e-05 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 1.0000\n",
      "Epoch 290/2000\n",
      "3/3 - 0s - loss: 3.8219e-05 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 1.0000\n",
      "Epoch 291/2000\n",
      "3/3 - 0s - loss: 3.0502e-05 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 1.0000\n",
      "Epoch 292/2000\n",
      "3/3 - 0s - loss: 2.5489e-05 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 1.0000\n",
      "Epoch 293/2000\n",
      "3/3 - 0s - loss: 3.5899e-05 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 1.0000\n",
      "Epoch 294/2000\n",
      "3/3 - 0s - loss: 3.4587e-05 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 1.0000\n",
      "Epoch 295/2000\n",
      "3/3 - 0s - loss: 2.4629e-05 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 1.0000\n",
      "Epoch 296/2000\n",
      "3/3 - 0s - loss: 3.0443e-05 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 1.0000\n",
      "Epoch 297/2000\n",
      "3/3 - 0s - loss: 2.8106e-05 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 1.0000\n",
      "Epoch 298/2000\n",
      "3/3 - 0s - loss: 2.9675e-05 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 1.0000\n",
      "Epoch 299/2000\n",
      "3/3 - 0s - loss: 2.6034e-05 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 1.0000\n",
      "Epoch 300/2000\n",
      "3/3 - 0s - loss: 2.8665e-05 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 1.0000\n",
      "Epoch 301/2000\n",
      "3/3 - 0s - loss: 2.4816e-05 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 1.0000\n",
      "Epoch 302/2000\n",
      "3/3 - 0s - loss: 2.7685e-05 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 1.0000\n",
      "Epoch 303/2000\n",
      "3/3 - 0s - loss: 2.7707e-05 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
      "Epoch 304/2000\n",
      "3/3 - 0s - loss: 2.4963e-05 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 1.0000\n",
      "Epoch 305/2000\n",
      "3/3 - 0s - loss: 2.6048e-05 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 1.0000\n",
      "Epoch 306/2000\n",
      "3/3 - 0s - loss: 2.3857e-05 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 1.0000\n",
      "Epoch 307/2000\n",
      "3/3 - 0s - loss: 3.1171e-05 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 1.0000\n",
      "Epoch 308/2000\n",
      "3/3 - 0s - loss: 3.3177e-05 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 1.0000\n",
      "Epoch 309/2000\n",
      "3/3 - 0s - loss: 2.9019e-05 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 1.0000\n",
      "Epoch 310/2000\n",
      "3/3 - 0s - loss: 2.9263e-05 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 1.0000\n",
      "Epoch 311/2000\n",
      "3/3 - 0s - loss: 3.1559e-05 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 1.0000\n",
      "Epoch 312/2000\n",
      "3/3 - 0s - loss: 2.3819e-05 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 1.0000\n",
      "Epoch 313/2000\n",
      "3/3 - 0s - loss: 3.6894e-05 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 1.0000\n",
      "Epoch 314/2000\n",
      "3/3 - 0s - loss: 2.4163e-05 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 1.0000\n",
      "Epoch 315/2000\n",
      "3/3 - 0s - loss: 3.2935e-05 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 1.0000\n",
      "Epoch 316/2000\n",
      "3/3 - 0s - loss: 1.8183e-05 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 1.0000\n",
      "Epoch 317/2000\n",
      "3/3 - 0s - loss: 2.8167e-05 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 1.0000\n",
      "Epoch 318/2000\n",
      "3/3 - 0s - loss: 1.8472e-05 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 1.0000\n",
      "Epoch 319/2000\n",
      "3/3 - 0s - loss: 2.1734e-05 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/2000\n",
      "3/3 - 0s - loss: 2.4897e-05 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 1.0000\n",
      "Epoch 321/2000\n",
      "3/3 - 0s - loss: 2.3174e-05 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 1.0000\n",
      "Epoch 322/2000\n",
      "3/3 - 0s - loss: 2.5027e-05 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 1.0000\n",
      "Epoch 323/2000\n",
      "3/3 - 0s - loss: 2.3039e-05 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 1.0000\n",
      "Epoch 324/2000\n",
      "3/3 - 0s - loss: 2.7045e-05 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 1.0000\n",
      "Epoch 325/2000\n",
      "3/3 - 0s - loss: 1.7821e-05 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 1.0000\n",
      "Epoch 326/2000\n",
      "3/3 - 0s - loss: 2.5574e-05 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 1.0000\n",
      "Epoch 327/2000\n",
      "3/3 - 0s - loss: 2.2880e-05 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 1.0000\n",
      "Epoch 328/2000\n",
      "3/3 - 0s - loss: 2.9626e-05 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 1.0000\n",
      "Epoch 329/2000\n",
      "3/3 - 0s - loss: 1.9461e-05 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 1.0000\n",
      "Epoch 330/2000\n",
      "3/3 - 0s - loss: 2.3913e-05 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 1.0000\n",
      "Epoch 331/2000\n",
      "3/3 - 0s - loss: 2.4955e-05 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 1.0000\n",
      "Epoch 332/2000\n",
      "3/3 - 0s - loss: 2.2564e-05 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 1.0000\n",
      "Epoch 333/2000\n",
      "3/3 - 0s - loss: 2.2874e-05 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 1.0000\n",
      "Epoch 334/2000\n",
      "3/3 - 0s - loss: 3.3009e-05 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 1.0000\n",
      "Epoch 335/2000\n",
      "3/3 - 0s - loss: 2.0593e-05 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 1.0000\n",
      "Epoch 336/2000\n",
      "3/3 - 0s - loss: 2.4392e-05 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 1.0000\n",
      "Epoch 337/2000\n",
      "3/3 - 0s - loss: 2.4138e-05 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 1.0000\n",
      "Epoch 338/2000\n",
      "3/3 - 0s - loss: 2.2584e-05 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 1.0000\n",
      "Epoch 339/2000\n",
      "3/3 - 0s - loss: 2.0281e-05 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 1.0000\n",
      "Epoch 340/2000\n",
      "3/3 - 0s - loss: 2.6267e-05 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 1.0000\n",
      "Epoch 341/2000\n",
      "3/3 - 0s - loss: 1.9735e-05 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 1.0000\n",
      "Epoch 342/2000\n",
      "3/3 - 0s - loss: 2.0734e-05 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 1.0000\n",
      "Epoch 343/2000\n",
      "3/3 - 0s - loss: 2.2802e-05 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 1.0000\n",
      "Epoch 344/2000\n",
      "3/3 - 0s - loss: 1.8442e-05 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 1.0000\n",
      "Epoch 345/2000\n",
      "3/3 - 0s - loss: 2.2739e-05 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 1.0000\n",
      "Epoch 346/2000\n",
      "3/3 - 0s - loss: 2.0288e-05 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 1.0000\n",
      "Epoch 347/2000\n",
      "3/3 - 0s - loss: 1.9696e-05 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 1.0000\n",
      "Epoch 348/2000\n",
      "3/3 - 0s - loss: 2.1091e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 1.0000\n",
      "Epoch 349/2000\n",
      "3/3 - 0s - loss: 2.4420e-05 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 1.0000\n",
      "Epoch 350/2000\n",
      "3/3 - 0s - loss: 2.0974e-05 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 1.0000\n",
      "Epoch 351/2000\n",
      "3/3 - 0s - loss: 2.1322e-05 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 1.0000\n",
      "Epoch 352/2000\n",
      "3/3 - 0s - loss: 1.6573e-05 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 1.0000\n",
      "Epoch 353/2000\n",
      "3/3 - 0s - loss: 1.8220e-05 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 1.0000\n",
      "Epoch 354/2000\n",
      "3/3 - 0s - loss: 1.7043e-05 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 1.0000\n",
      "Epoch 355/2000\n",
      "3/3 - 0s - loss: 1.8444e-05 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 1.0000\n",
      "Epoch 356/2000\n",
      "3/3 - 0s - loss: 1.6700e-05 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 1.0000\n",
      "Epoch 357/2000\n",
      "3/3 - 0s - loss: 1.9095e-05 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 1.0000\n",
      "Epoch 358/2000\n",
      "3/3 - 0s - loss: 2.0191e-05 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 1.0000\n",
      "Epoch 359/2000\n",
      "3/3 - 0s - loss: 1.8075e-05 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 1.0000\n",
      "Epoch 360/2000\n",
      "3/3 - 0s - loss: 1.6970e-05 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 1.0000\n",
      "Epoch 361/2000\n",
      "3/3 - 0s - loss: 1.7002e-05 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 1.0000\n",
      "Epoch 362/2000\n",
      "3/3 - 0s - loss: 2.0220e-05 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 1.0000\n",
      "Epoch 363/2000\n",
      "3/3 - 0s - loss: 1.8319e-05 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 1.0000\n",
      "Epoch 364/2000\n",
      "3/3 - 0s - loss: 1.7603e-05 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 1.0000\n",
      "Epoch 365/2000\n",
      "3/3 - 0s - loss: 1.8905e-05 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 1.0000\n",
      "Epoch 366/2000\n",
      "3/3 - 0s - loss: 2.2858e-05 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 1.0000\n",
      "Epoch 367/2000\n",
      "3/3 - 0s - loss: 2.0400e-05 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 1.0000\n",
      "Epoch 368/2000\n",
      "3/3 - 0s - loss: 1.7436e-05 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 1.0000\n",
      "Epoch 369/2000\n",
      "3/3 - 0s - loss: 1.8518e-05 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 1.0000\n",
      "Epoch 370/2000\n",
      "3/3 - 0s - loss: 1.5841e-05 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 1.0000\n",
      "Epoch 371/2000\n",
      "3/3 - 0s - loss: 1.8534e-05 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 1.0000\n",
      "Epoch 372/2000\n",
      "3/3 - 0s - loss: 1.7661e-05 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 373/2000\n",
      "3/3 - 0s - loss: 1.8534e-05 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 374/2000\n",
      "3/3 - 0s - loss: 2.4587e-05 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 1.0000\n",
      "Epoch 375/2000\n",
      "3/3 - 0s - loss: 1.6011e-05 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 1.0000\n",
      "Epoch 376/2000\n",
      "3/3 - 0s - loss: 1.4333e-05 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
      "Epoch 377/2000\n",
      "3/3 - 0s - loss: 2.0052e-05 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
      "Epoch 378/2000\n",
      "3/3 - 0s - loss: 1.7895e-05 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
      "Epoch 379/2000\n",
      "3/3 - 0s - loss: 1.4308e-05 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 1.0000\n",
      "Epoch 380/2000\n",
      "3/3 - 0s - loss: 2.0210e-05 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 1.0000\n",
      "Epoch 381/2000\n",
      "3/3 - 0s - loss: 1.5872e-05 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 1.0000\n",
      "Epoch 382/2000\n",
      "3/3 - 0s - loss: 1.5209e-05 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 1.0000\n",
      "Epoch 383/2000\n",
      "3/3 - 0s - loss: 1.5927e-05 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 1.0000\n",
      "Epoch 384/2000\n",
      "3/3 - 0s - loss: 1.8531e-05 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 385/2000\n",
      "3/3 - 0s - loss: 1.8685e-05 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 1.0000\n",
      "Epoch 386/2000\n",
      "3/3 - 0s - loss: 1.7782e-05 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 1.0000\n",
      "Epoch 387/2000\n",
      "3/3 - 0s - loss: 1.5510e-05 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 1.0000\n",
      "Epoch 388/2000\n",
      "3/3 - 0s - loss: 1.5590e-05 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 1.0000\n",
      "Epoch 389/2000\n",
      "3/3 - 0s - loss: 1.6628e-05 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 1.0000\n",
      "Epoch 390/2000\n",
      "3/3 - 0s - loss: 1.9182e-05 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 1.0000\n",
      "Epoch 391/2000\n",
      "3/3 - 0s - loss: 1.8104e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 1.0000\n",
      "Epoch 392/2000\n",
      "3/3 - 0s - loss: 1.6170e-05 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 1.0000\n",
      "Epoch 393/2000\n",
      "3/3 - 0s - loss: 1.6550e-05 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 1.0000\n",
      "Epoch 394/2000\n",
      "3/3 - 0s - loss: 1.5392e-05 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 1.0000\n",
      "Epoch 395/2000\n",
      "3/3 - 0s - loss: 1.6803e-05 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 1.0000\n",
      "Epoch 396/2000\n",
      "3/3 - 0s - loss: 1.6446e-05 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 1.0000\n",
      "Epoch 397/2000\n",
      "3/3 - 0s - loss: 2.6842e-05 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 1.0000\n",
      "Epoch 398/2000\n",
      "3/3 - 0s - loss: 1.5463e-05 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/2000\n",
      "3/3 - 0s - loss: 1.8705e-05 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
      "Epoch 400/2000\n",
      "3/3 - 0s - loss: 1.4986e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
      "Epoch 401/2000\n",
      "3/3 - 0s - loss: 1.8094e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
      "Epoch 402/2000\n",
      "3/3 - 0s - loss: 1.7035e-05 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
      "Epoch 403/2000\n",
      "3/3 - 0s - loss: 1.6786e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
      "Epoch 404/2000\n",
      "3/3 - 0s - loss: 1.5955e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
      "Epoch 405/2000\n",
      "3/3 - 0s - loss: 1.5261e-05 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
      "Epoch 406/2000\n",
      "3/3 - 0s - loss: 1.3848e-05 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 1.0000\n",
      "Epoch 407/2000\n",
      "3/3 - 0s - loss: 1.8033e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
      "Epoch 408/2000\n",
      "3/3 - 0s - loss: 1.6330e-05 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
      "Epoch 409/2000\n",
      "3/3 - 0s - loss: 1.1358e-05 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 1.0000\n",
      "Epoch 410/2000\n",
      "3/3 - 0s - loss: 1.4048e-05 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 1.0000\n",
      "Epoch 411/2000\n",
      "3/3 - 0s - loss: 1.6244e-05 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 1.0000\n",
      "Epoch 412/2000\n",
      "3/3 - 0s - loss: 1.6684e-05 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 1.0000\n",
      "Epoch 413/2000\n",
      "3/3 - 0s - loss: 1.6700e-05 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 1.0000\n",
      "Epoch 414/2000\n",
      "3/3 - 0s - loss: 1.7724e-05 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 1.0000\n",
      "Epoch 415/2000\n",
      "3/3 - 0s - loss: 1.5551e-05 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 1.0000\n",
      "Epoch 416/2000\n",
      "3/3 - 0s - loss: 1.1089e-05 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
      "Epoch 417/2000\n",
      "3/3 - 0s - loss: 2.2713e-05 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
      "Epoch 418/2000\n",
      "3/3 - 0s - loss: 1.4913e-05 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
      "Epoch 419/2000\n",
      "3/3 - 0s - loss: 1.3629e-05 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
      "Epoch 420/2000\n",
      "3/3 - 0s - loss: 1.4315e-05 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 1.0000\n",
      "Epoch 421/2000\n",
      "3/3 - 0s - loss: 1.3268e-05 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 1.0000\n",
      "Epoch 422/2000\n",
      "3/3 - 0s - loss: 1.4253e-05 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 1.0000\n",
      "Epoch 423/2000\n",
      "3/3 - 0s - loss: 1.5861e-05 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 1.0000\n",
      "Epoch 424/2000\n",
      "3/3 - 0s - loss: 1.3739e-05 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 1.0000\n",
      "Epoch 425/2000\n",
      "3/3 - 0s - loss: 1.2868e-05 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
      "Epoch 426/2000\n",
      "3/3 - 0s - loss: 1.5126e-05 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 1.0000\n",
      "Epoch 427/2000\n",
      "3/3 - 0s - loss: 1.3450e-05 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 1.0000\n",
      "Epoch 428/2000\n",
      "3/3 - 0s - loss: 1.4844e-05 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 1.0000\n",
      "Epoch 429/2000\n",
      "3/3 - 0s - loss: 1.4481e-05 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 1.0000\n",
      "Epoch 430/2000\n",
      "3/3 - 0s - loss: 1.4955e-05 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
      "Epoch 431/2000\n",
      "3/3 - 0s - loss: 1.5609e-05 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
      "Epoch 432/2000\n",
      "3/3 - 0s - loss: 1.3289e-05 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 1.0000\n",
      "Epoch 433/2000\n",
      "3/3 - 0s - loss: 1.2573e-05 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
      "Epoch 434/2000\n",
      "3/3 - 0s - loss: 1.2698e-05 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
      "Epoch 435/2000\n",
      "3/3 - 0s - loss: 1.0916e-05 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 1.0000\n",
      "Epoch 436/2000\n",
      "3/3 - 0s - loss: 1.6941e-05 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 1.0000\n",
      "Epoch 437/2000\n",
      "3/3 - 0s - loss: 1.0245e-05 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 1.0000\n",
      "Epoch 438/2000\n",
      "3/3 - 0s - loss: 1.5348e-05 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 1.0000\n",
      "Epoch 439/2000\n",
      "3/3 - 0s - loss: 1.6035e-05 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 440/2000\n",
      "3/3 - 0s - loss: 1.1170e-05 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 441/2000\n",
      "3/3 - 0s - loss: 1.4788e-05 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 442/2000\n",
      "3/3 - 0s - loss: 1.5116e-05 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 1.0000\n",
      "Epoch 443/2000\n",
      "3/3 - 0s - loss: 1.2252e-05 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 1.0000\n",
      "Epoch 444/2000\n",
      "3/3 - 0s - loss: 1.1368e-05 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 1.0000\n",
      "Epoch 445/2000\n",
      "3/3 - 0s - loss: 1.5020e-05 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 1.0000\n",
      "Epoch 446/2000\n",
      "3/3 - 0s - loss: 1.1340e-05 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 1.0000\n",
      "Epoch 447/2000\n",
      "3/3 - 0s - loss: 1.5797e-05 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 1.0000\n",
      "Epoch 448/2000\n",
      "3/3 - 0s - loss: 1.0346e-05 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 1.0000\n",
      "Epoch 449/2000\n",
      "3/3 - 0s - loss: 1.0792e-05 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 1.0000\n",
      "Epoch 450/2000\n",
      "3/3 - 0s - loss: 1.3261e-05 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 1.0000\n",
      "Epoch 451/2000\n",
      "3/3 - 0s - loss: 1.4832e-05 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 1.0000\n",
      "Epoch 452/2000\n",
      "3/3 - 0s - loss: 1.7235e-05 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 1.0000\n",
      "Epoch 453/2000\n",
      "3/3 - 0s - loss: 1.3322e-05 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 1.0000\n",
      "Epoch 454/2000\n",
      "3/3 - 0s - loss: 1.3705e-05 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 1.0000\n",
      "Epoch 455/2000\n",
      "3/3 - 0s - loss: 1.1355e-05 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 1.0000\n",
      "Epoch 456/2000\n",
      "3/3 - 0s - loss: 1.4154e-05 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 1.0000\n",
      "Epoch 457/2000\n",
      "3/3 - 0s - loss: 1.3450e-05 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 1.0000\n",
      "Epoch 458/2000\n",
      "3/3 - 0s - loss: 1.7175e-05 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 1.0000\n",
      "Epoch 459/2000\n",
      "3/3 - 0s - loss: 1.2837e-05 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 1.0000\n",
      "Epoch 460/2000\n",
      "3/3 - 0s - loss: 1.1103e-05 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 1.0000\n",
      "Epoch 461/2000\n",
      "3/3 - 0s - loss: 1.3045e-05 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 1.0000\n",
      "Epoch 462/2000\n",
      "3/3 - 0s - loss: 1.0350e-05 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 1.0000\n",
      "Epoch 463/2000\n",
      "3/3 - 0s - loss: 1.1078e-05 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 1.0000\n",
      "Epoch 464/2000\n",
      "3/3 - 0s - loss: 1.2640e-05 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 1.0000\n",
      "Epoch 465/2000\n",
      "3/3 - 0s - loss: 1.1231e-05 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 1.0000\n",
      "Epoch 466/2000\n",
      "3/3 - 0s - loss: 1.3885e-05 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 1.0000\n",
      "Epoch 467/2000\n",
      "3/3 - 0s - loss: 1.0963e-05 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 1.0000\n",
      "Epoch 468/2000\n",
      "3/3 - 0s - loss: 1.1026e-05 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 1.0000\n",
      "Epoch 469/2000\n",
      "3/3 - 0s - loss: 1.0718e-05 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 1.0000\n",
      "Epoch 470/2000\n",
      "3/3 - 0s - loss: 1.1897e-05 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 1.0000\n",
      "Epoch 471/2000\n",
      "3/3 - 0s - loss: 1.5437e-05 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 1.0000\n",
      "Epoch 472/2000\n",
      "3/3 - 0s - loss: 1.0571e-05 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 1.0000\n",
      "Epoch 473/2000\n",
      "3/3 - 0s - loss: 1.1949e-05 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 1.0000\n",
      "Epoch 474/2000\n",
      "3/3 - 0s - loss: 1.3372e-05 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 1.0000\n",
      "Epoch 475/2000\n",
      "3/3 - 0s - loss: 9.3985e-06 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 1.0000\n",
      "Epoch 476/2000\n",
      "3/3 - 0s - loss: 8.6431e-06 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 1.0000\n",
      "Epoch 477/2000\n",
      "3/3 - 0s - loss: 9.9453e-06 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/2000\n",
      "3/3 - 0s - loss: 1.5260e-05 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 1.0000\n",
      "Epoch 479/2000\n",
      "3/3 - 0s - loss: 9.7812e-06 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 1.0000\n",
      "Epoch 480/2000\n",
      "3/3 - 0s - loss: 9.0388e-06 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 1.0000\n",
      "Epoch 481/2000\n",
      "3/3 - 0s - loss: 1.1088e-05 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 1.0000\n",
      "Epoch 482/2000\n",
      "3/3 - 0s - loss: 1.1977e-05 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 1.0000\n",
      "Epoch 483/2000\n",
      "3/3 - 0s - loss: 1.1056e-05 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 1.0000\n",
      "Epoch 484/2000\n",
      "3/3 - 0s - loss: 1.1175e-05 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 1.0000\n",
      "Epoch 485/2000\n",
      "3/3 - 0s - loss: 1.1125e-05 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 1.0000\n",
      "Epoch 486/2000\n",
      "3/3 - 0s - loss: 1.3469e-05 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 1.0000\n",
      "Epoch 487/2000\n",
      "3/3 - 0s - loss: 1.2311e-05 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 1.0000\n",
      "Epoch 488/2000\n",
      "3/3 - 0s - loss: 9.1150e-06 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 1.0000\n",
      "Epoch 489/2000\n",
      "3/3 - 0s - loss: 1.2271e-05 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 1.0000\n",
      "Epoch 490/2000\n",
      "3/3 - 0s - loss: 1.2261e-05 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 1.0000\n",
      "Epoch 491/2000\n",
      "3/3 - 0s - loss: 1.1416e-05 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 1.0000\n",
      "Epoch 492/2000\n",
      "3/3 - 0s - loss: 1.2493e-05 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 1.0000\n",
      "Epoch 493/2000\n",
      "3/3 - 0s - loss: 1.0577e-05 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 1.0000\n",
      "Epoch 494/2000\n",
      "3/3 - 0s - loss: 1.1059e-05 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 1.0000\n",
      "Epoch 495/2000\n",
      "3/3 - 0s - loss: 1.2326e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 1.0000\n",
      "Epoch 496/2000\n",
      "3/3 - 0s - loss: 1.0370e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 1.0000\n",
      "Epoch 497/2000\n",
      "3/3 - 0s - loss: 9.3649e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
      "Epoch 498/2000\n",
      "3/3 - 0s - loss: 1.5555e-05 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
      "Epoch 499/2000\n",
      "3/3 - 0s - loss: 9.0809e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
      "Epoch 500/2000\n",
      "3/3 - 0s - loss: 1.1256e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 1.0000\n",
      "Epoch 501/2000\n",
      "3/3 - 0s - loss: 1.1126e-05 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
      "Epoch 502/2000\n",
      "3/3 - 0s - loss: 9.0624e-06 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 1.0000\n",
      "Epoch 503/2000\n",
      "3/3 - 0s - loss: 8.0970e-06 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 1.0000\n",
      "Epoch 504/2000\n",
      "3/3 - 0s - loss: 1.9588e-05 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 1.0000\n",
      "Epoch 505/2000\n",
      "3/3 - 0s - loss: 7.9912e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 1.0000\n",
      "Epoch 506/2000\n",
      "3/3 - 0s - loss: 9.3199e-06 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 1.0000\n",
      "Epoch 507/2000\n",
      "3/3 - 0s - loss: 1.0977e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 508/2000\n",
      "3/3 - 0s - loss: 1.3610e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 509/2000\n",
      "3/3 - 0s - loss: 1.1674e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 510/2000\n",
      "3/3 - 0s - loss: 1.2793e-05 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 511/2000\n",
      "3/3 - 0s - loss: 9.6664e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 512/2000\n",
      "3/3 - 0s - loss: 8.8859e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 513/2000\n",
      "3/3 - 0s - loss: 8.1452e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 514/2000\n",
      "3/3 - 0s - loss: 7.9926e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 515/2000\n",
      "3/3 - 0s - loss: 9.9083e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 516/2000\n",
      "3/3 - 0s - loss: 9.1964e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 517/2000\n",
      "3/3 - 0s - loss: 8.6452e-06 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 1.0000\n",
      "Epoch 518/2000\n",
      "3/3 - 0s - loss: 1.0165e-05 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 1.0000\n",
      "Epoch 519/2000\n",
      "3/3 - 0s - loss: 8.6961e-06 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 1.0000\n",
      "Epoch 520/2000\n",
      "3/3 - 0s - loss: 8.2063e-06 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 1.0000\n",
      "Epoch 521/2000\n",
      "3/3 - 0s - loss: 8.6586e-06 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 1.0000\n",
      "Epoch 522/2000\n",
      "3/3 - 0s - loss: 1.2706e-05 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 1.0000\n",
      "Epoch 523/2000\n",
      "3/3 - 0s - loss: 8.2963e-06 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 1.0000\n",
      "Epoch 524/2000\n",
      "3/3 - 0s - loss: 7.4465e-06 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 1.0000\n",
      "Epoch 525/2000\n",
      "3/3 - 0s - loss: 1.2743e-05 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 1.0000\n",
      "Epoch 526/2000\n",
      "3/3 - 0s - loss: 9.2269e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 1.0000\n",
      "Epoch 527/2000\n",
      "3/3 - 0s - loss: 1.2470e-05 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 1.0000\n",
      "Epoch 528/2000\n",
      "3/3 - 0s - loss: 1.1296e-05 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 1.0000\n",
      "Epoch 529/2000\n",
      "3/3 - 0s - loss: 8.7772e-06 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 1.0000\n",
      "Epoch 530/2000\n",
      "3/3 - 0s - loss: 9.8527e-06 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 1.0000\n",
      "Epoch 531/2000\n",
      "3/3 - 0s - loss: 9.8083e-06 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 1.0000\n",
      "Epoch 532/2000\n",
      "3/3 - 0s - loss: 7.9566e-06 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 1.0000\n",
      "Epoch 533/2000\n",
      "3/3 - 0s - loss: 9.6159e-06 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 1.0000\n",
      "Epoch 534/2000\n",
      "3/3 - 0s - loss: 9.2568e-06 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 1.0000\n",
      "Epoch 535/2000\n",
      "3/3 - 0s - loss: 1.0877e-05 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
      "Epoch 536/2000\n",
      "3/3 - 0s - loss: 8.3581e-06 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
      "Epoch 537/2000\n",
      "3/3 - 0s - loss: 8.9078e-06 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
      "Epoch 538/2000\n",
      "3/3 - 0s - loss: 9.6974e-06 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
      "Epoch 539/2000\n",
      "3/3 - 0s - loss: 8.4045e-06 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 1.0000\n",
      "Epoch 540/2000\n",
      "3/3 - 0s - loss: 1.2357e-05 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 1.0000\n",
      "Epoch 541/2000\n",
      "3/3 - 0s - loss: 7.0832e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
      "Epoch 542/2000\n",
      "3/3 - 0s - loss: 8.2204e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
      "Epoch 543/2000\n",
      "3/3 - 0s - loss: 9.6581e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
      "Epoch 544/2000\n",
      "3/3 - 0s - loss: 7.4895e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
      "Epoch 545/2000\n",
      "3/3 - 0s - loss: 6.6687e-06 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 1.0000\n",
      "Epoch 546/2000\n",
      "3/3 - 0s - loss: 8.7443e-06 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 1.0000\n",
      "Epoch 547/2000\n",
      "3/3 - 0s - loss: 8.4573e-06 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 1.0000\n",
      "Epoch 548/2000\n",
      "3/3 - 0s - loss: 8.6008e-06 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 1.0000\n",
      "Epoch 549/2000\n",
      "3/3 - 0s - loss: 8.6917e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 550/2000\n",
      "3/3 - 0s - loss: 9.4713e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 551/2000\n",
      "3/3 - 0s - loss: 8.5801e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 552/2000\n",
      "3/3 - 0s - loss: 8.0675e-06 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 553/2000\n",
      "3/3 - 0s - loss: 7.3563e-06 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 554/2000\n",
      "3/3 - 0s - loss: 7.1950e-06 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 1.0000\n",
      "Epoch 555/2000\n",
      "3/3 - 0s - loss: 8.8168e-06 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 1.0000\n",
      "Epoch 556/2000\n",
      "3/3 - 0s - loss: 9.2374e-06 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/2000\n",
      "3/3 - 0s - loss: 7.9297e-06 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 1.0000\n",
      "Epoch 558/2000\n",
      "3/3 - 0s - loss: 6.8200e-06 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 1.0000\n",
      "Epoch 559/2000\n",
      "3/3 - 0s - loss: 9.3352e-06 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 1.0000\n",
      "Epoch 560/2000\n",
      "3/3 - 0s - loss: 5.9357e-06 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 1.0000\n",
      "Epoch 561/2000\n",
      "3/3 - 0s - loss: 7.8656e-06 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 1.0000\n",
      "Epoch 562/2000\n",
      "3/3 - 0s - loss: 8.0905e-06 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 1.0000\n",
      "Epoch 563/2000\n",
      "3/3 - 0s - loss: 5.9969e-06 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 1.0000\n",
      "Epoch 564/2000\n",
      "3/3 - 0s - loss: 6.5207e-06 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 1.0000\n",
      "Epoch 565/2000\n",
      "3/3 - 0s - loss: 6.8988e-06 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 1.0000\n",
      "Epoch 566/2000\n",
      "3/3 - 0s - loss: 7.7728e-06 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 1.0000\n",
      "Epoch 567/2000\n",
      "3/3 - 0s - loss: 9.4468e-06 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
      "Epoch 568/2000\n",
      "3/3 - 0s - loss: 7.1062e-06 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 1.0000\n",
      "Epoch 569/2000\n",
      "3/3 - 0s - loss: 9.1487e-06 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 1.0000\n",
      "Epoch 570/2000\n",
      "3/3 - 0s - loss: 7.8654e-06 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 1.0000\n",
      "Epoch 571/2000\n",
      "3/3 - 0s - loss: 7.4756e-06 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 1.0000\n",
      "Epoch 572/2000\n",
      "3/3 - 0s - loss: 6.6452e-06 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
      "Epoch 573/2000\n",
      "3/3 - 0s - loss: 6.7616e-06 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
      "Epoch 574/2000\n",
      "3/3 - 0s - loss: 9.3318e-06 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 1.0000\n",
      "Epoch 575/2000\n",
      "3/3 - 0s - loss: 8.4307e-06 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 1.0000\n",
      "Epoch 576/2000\n",
      "3/3 - 0s - loss: 7.4726e-06 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 1.0000\n",
      "Epoch 577/2000\n",
      "3/3 - 0s - loss: 6.4063e-06 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 1.0000\n",
      "Epoch 578/2000\n",
      "3/3 - 0s - loss: 9.2364e-06 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 1.0000\n",
      "Epoch 579/2000\n",
      "3/3 - 0s - loss: 8.6657e-06 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 1.0000\n",
      "Epoch 580/2000\n",
      "3/3 - 0s - loss: 7.1983e-06 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 1.0000\n",
      "Epoch 581/2000\n",
      "3/3 - 0s - loss: 7.4018e-06 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 1.0000\n",
      "Epoch 582/2000\n",
      "3/3 - 0s - loss: 5.9577e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 583/2000\n",
      "3/3 - 0s - loss: 7.3514e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 584/2000\n",
      "3/3 - 0s - loss: 1.0021e-05 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 585/2000\n",
      "3/3 - 0s - loss: 6.2879e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 586/2000\n",
      "3/3 - 0s - loss: 6.4928e-06 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 1.0000\n",
      "Epoch 587/2000\n",
      "3/3 - 0s - loss: 9.6015e-06 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 1.0000\n",
      "Epoch 588/2000\n",
      "3/3 - 0s - loss: 6.9398e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 589/2000\n",
      "3/3 - 0s - loss: 5.6444e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 590/2000\n",
      "3/3 - 0s - loss: 9.8821e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 591/2000\n",
      "3/3 - 0s - loss: 6.7949e-06 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 1.0000\n",
      "Epoch 592/2000\n",
      "3/3 - 0s - loss: 5.5236e-06 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 1.0000\n",
      "Epoch 593/2000\n",
      "3/3 - 0s - loss: 7.2767e-06 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 1.0000\n",
      "Epoch 594/2000\n",
      "3/3 - 0s - loss: 4.8015e-06 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 595/2000\n",
      "3/3 - 0s - loss: 6.3274e-06 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 596/2000\n",
      "3/3 - 0s - loss: 9.3411e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 597/2000\n",
      "3/3 - 0s - loss: 6.6436e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 598/2000\n",
      "3/3 - 0s - loss: 5.8320e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 599/2000\n",
      "3/3 - 0s - loss: 8.9588e-06 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 600/2000\n",
      "3/3 - 0s - loss: 6.3217e-06 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 601/2000\n",
      "3/3 - 0s - loss: 5.9361e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 602/2000\n",
      "3/3 - 0s - loss: 7.6050e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 603/2000\n",
      "3/3 - 0s - loss: 1.0396e-05 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 604/2000\n",
      "3/3 - 0s - loss: 7.1757e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 605/2000\n",
      "3/3 - 0s - loss: 8.9888e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 606/2000\n",
      "3/3 - 0s - loss: 8.0827e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 607/2000\n",
      "3/3 - 0s - loss: 6.5096e-06 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 608/2000\n",
      "3/3 - 0s - loss: 9.6041e-06 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 609/2000\n",
      "3/3 - 0s - loss: 6.5286e-06 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 1.0000\n",
      "Epoch 610/2000\n",
      "3/3 - 0s - loss: 6.9844e-06 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 1.0000\n",
      "Epoch 611/2000\n",
      "3/3 - 0s - loss: 7.9060e-06 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 1.0000\n",
      "Epoch 612/2000\n",
      "3/3 - 0s - loss: 8.6678e-06 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 1.0000\n",
      "Epoch 613/2000\n",
      "3/3 - 0s - loss: 6.5392e-06 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 1.0000\n",
      "Epoch 614/2000\n",
      "3/3 - 0s - loss: 6.5301e-06 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 1.0000\n",
      "Epoch 615/2000\n",
      "3/3 - 0s - loss: 6.9177e-06 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 1.0000\n",
      "Epoch 616/2000\n",
      "3/3 - 0s - loss: 6.7011e-06 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 1.0000\n",
      "Epoch 617/2000\n",
      "3/3 - 0s - loss: 5.7806e-06 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 1.0000\n",
      "Epoch 618/2000\n",
      "3/3 - 0s - loss: 6.5173e-06 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 1.0000\n",
      "Epoch 619/2000\n",
      "3/3 - 0s - loss: 8.4836e-06 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 1.0000\n",
      "Epoch 620/2000\n",
      "3/3 - 0s - loss: 9.2892e-06 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 1.0000\n",
      "Epoch 621/2000\n",
      "3/3 - 0s - loss: 5.7529e-06 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 1.0000\n",
      "Epoch 622/2000\n",
      "3/3 - 0s - loss: 5.0814e-06 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 1.0000\n",
      "Epoch 623/2000\n",
      "3/3 - 0s - loss: 5.0523e-06 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 1.0000\n",
      "Epoch 624/2000\n",
      "3/3 - 0s - loss: 5.6463e-06 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 1.0000\n",
      "Epoch 625/2000\n",
      "3/3 - 0s - loss: 4.6092e-06 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 1.0000\n",
      "Epoch 626/2000\n",
      "3/3 - 0s - loss: 6.7314e-06 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 1.0000\n",
      "Epoch 627/2000\n",
      "3/3 - 0s - loss: 7.7857e-06 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 1.0000\n",
      "Epoch 628/2000\n",
      "3/3 - 0s - loss: 6.9766e-06 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 1.0000\n",
      "Epoch 629/2000\n",
      "3/3 - 0s - loss: 7.5142e-06 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 1.0000\n",
      "Epoch 630/2000\n",
      "3/3 - 0s - loss: 8.5570e-06 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 1.0000\n",
      "Epoch 631/2000\n",
      "3/3 - 0s - loss: 7.1779e-06 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 1.0000\n",
      "Epoch 632/2000\n",
      "3/3 - 0s - loss: 4.5065e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 633/2000\n",
      "3/3 - 0s - loss: 5.7174e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 634/2000\n",
      "3/3 - 0s - loss: 6.2163e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
      "Epoch 635/2000\n",
      "3/3 - 0s - loss: 8.9973e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/2000\n",
      "3/3 - 0s - loss: 6.7158e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 637/2000\n",
      "3/3 - 0s - loss: 5.8085e-06 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 1.0000\n",
      "Epoch 638/2000\n",
      "3/3 - 0s - loss: 6.2226e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 639/2000\n",
      "3/3 - 0s - loss: 6.3470e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 640/2000\n",
      "3/3 - 0s - loss: 8.2116e-06 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 1.0000\n",
      "Epoch 641/2000\n",
      "3/3 - 0s - loss: 7.5056e-06 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
      "Epoch 642/2000\n",
      "3/3 - 0s - loss: 4.4471e-06 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 1.0000\n",
      "Epoch 643/2000\n",
      "3/3 - 0s - loss: 5.7654e-06 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 1.0000\n",
      "Epoch 644/2000\n",
      "3/3 - 0s - loss: 8.3368e-06 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 1.0000\n",
      "Epoch 645/2000\n",
      "3/3 - 0s - loss: 8.2003e-06 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 1.0000\n",
      "Epoch 646/2000\n",
      "3/3 - 0s - loss: 5.4273e-06 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 1.0000\n",
      "Epoch 647/2000\n",
      "3/3 - 0s - loss: 5.1683e-06 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 1.0000\n",
      "Epoch 648/2000\n",
      "3/3 - 0s - loss: 5.7217e-06 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 1.0000\n",
      "Epoch 649/2000\n",
      "3/3 - 0s - loss: 6.9034e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 650/2000\n",
      "3/3 - 0s - loss: 4.5368e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 651/2000\n",
      "3/3 - 0s - loss: 8.7764e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 652/2000\n",
      "3/3 - 0s - loss: 9.1369e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 653/2000\n",
      "3/3 - 0s - loss: 5.6854e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 654/2000\n",
      "3/3 - 0s - loss: 4.5650e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 655/2000\n",
      "3/3 - 0s - loss: 6.3826e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 656/2000\n",
      "3/3 - 0s - loss: 5.9633e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 657/2000\n",
      "3/3 - 0s - loss: 5.8333e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 658/2000\n",
      "3/3 - 0s - loss: 5.5874e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 659/2000\n",
      "3/3 - 0s - loss: 6.5073e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 660/2000\n",
      "3/3 - 0s - loss: 4.7568e-06 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 661/2000\n",
      "3/3 - 0s - loss: 5.4839e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 662/2000\n",
      "3/3 - 0s - loss: 5.9841e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 663/2000\n",
      "3/3 - 0s - loss: 4.6217e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 1.0000\n",
      "Epoch 664/2000\n",
      "3/3 - 0s - loss: 8.0066e-06 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 1.0000\n",
      "Epoch 665/2000\n",
      "3/3 - 0s - loss: 5.5561e-06 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 1.0000\n",
      "Epoch 666/2000\n",
      "3/3 - 0s - loss: 6.7410e-06 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 667/2000\n",
      "3/3 - 0s - loss: 5.1575e-06 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 668/2000\n",
      "3/3 - 0s - loss: 7.6526e-06 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 1.0000\n",
      "Epoch 669/2000\n",
      "3/3 - 0s - loss: 3.9585e-06 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 1.0000\n",
      "Epoch 670/2000\n",
      "3/3 - 0s - loss: 4.8809e-06 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 1.0000\n",
      "Epoch 671/2000\n",
      "3/3 - 0s - loss: 3.4659e-06 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 1.0000\n",
      "Epoch 672/2000\n",
      "3/3 - 0s - loss: 6.3636e-06 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 1.0000\n",
      "Epoch 673/2000\n",
      "3/3 - 0s - loss: 6.4651e-06 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 1.0000\n",
      "Epoch 674/2000\n",
      "3/3 - 0s - loss: 5.1739e-06 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 1.0000\n",
      "Epoch 675/2000\n",
      "3/3 - 0s - loss: 4.7998e-06 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 1.0000\n",
      "Epoch 676/2000\n",
      "3/3 - 0s - loss: 7.1557e-06 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 1.0000\n",
      "Epoch 677/2000\n",
      "3/3 - 0s - loss: 6.5195e-06 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 1.0000\n",
      "Epoch 678/2000\n",
      "3/3 - 0s - loss: 9.5601e-06 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 1.0000\n",
      "Epoch 679/2000\n",
      "3/3 - 0s - loss: 6.8448e-06 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 1.0000\n",
      "Epoch 680/2000\n",
      "3/3 - 0s - loss: 3.5970e-06 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 1.0000\n",
      "Epoch 681/2000\n",
      "3/3 - 0s - loss: 4.1796e-06 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
      "Epoch 682/2000\n",
      "3/3 - 0s - loss: 6.7019e-06 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
      "Epoch 683/2000\n",
      "3/3 - 0s - loss: 5.1895e-06 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 1.0000\n",
      "Epoch 684/2000\n",
      "3/3 - 0s - loss: 4.8957e-06 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 1.0000\n",
      "Epoch 685/2000\n",
      "3/3 - 0s - loss: 5.9832e-06 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 1.0000\n",
      "Epoch 686/2000\n",
      "3/3 - 0s - loss: 5.0122e-06 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 1.0000\n",
      "Epoch 687/2000\n",
      "3/3 - 0s - loss: 5.3774e-06 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 1.0000\n",
      "Epoch 688/2000\n",
      "3/3 - 0s - loss: 7.4625e-06 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 1.0000\n",
      "Epoch 689/2000\n",
      "3/3 - 0s - loss: 5.2668e-06 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 1.0000\n",
      "Epoch 690/2000\n",
      "3/3 - 0s - loss: 4.7945e-06 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 1.0000\n",
      "Epoch 691/2000\n",
      "3/3 - 0s - loss: 3.8067e-06 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 1.0000\n",
      "Epoch 692/2000\n",
      "3/3 - 0s - loss: 5.0874e-06 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 1.0000\n",
      "Epoch 693/2000\n",
      "3/3 - 0s - loss: 5.8086e-06 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 1.0000\n",
      "Epoch 694/2000\n",
      "3/3 - 0s - loss: 4.0558e-06 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 1.0000\n",
      "Epoch 695/2000\n",
      "3/3 - 0s - loss: 5.5697e-06 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 1.0000\n",
      "Epoch 696/2000\n",
      "3/3 - 0s - loss: 4.0863e-06 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 1.0000\n",
      "Epoch 697/2000\n",
      "3/3 - 0s - loss: 5.7831e-06 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 1.0000\n",
      "Epoch 698/2000\n",
      "3/3 - 0s - loss: 4.1177e-06 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 1.0000\n",
      "Epoch 699/2000\n",
      "3/3 - 0s - loss: 6.9609e-06 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 1.0000\n",
      "Epoch 700/2000\n",
      "3/3 - 0s - loss: 5.8685e-06 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "Epoch 701/2000\n",
      "3/3 - 0s - loss: 5.0020e-06 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 1.0000\n",
      "Epoch 702/2000\n",
      "3/3 - 0s - loss: 4.5162e-06 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 1.0000\n",
      "Epoch 703/2000\n",
      "3/3 - 0s - loss: 5.9976e-06 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 1.0000\n",
      "Epoch 704/2000\n",
      "3/3 - 0s - loss: 5.4649e-06 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 1.0000\n",
      "Epoch 705/2000\n",
      "3/3 - 0s - loss: 5.4848e-06 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
      "Epoch 706/2000\n",
      "3/3 - 0s - loss: 4.0045e-06 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 1.0000\n",
      "Epoch 707/2000\n",
      "3/3 - 0s - loss: 4.6572e-06 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
      "Epoch 708/2000\n",
      "3/3 - 0s - loss: 6.1773e-06 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
      "Epoch 709/2000\n",
      "3/3 - 0s - loss: 6.6317e-06 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
      "Epoch 710/2000\n",
      "3/3 - 0s - loss: 5.3354e-06 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 711/2000\n",
      "3/3 - 0s - loss: 4.8284e-06 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 712/2000\n",
      "3/3 - 0s - loss: 5.4965e-06 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 713/2000\n",
      "3/3 - 0s - loss: 6.6988e-06 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 714/2000\n",
      "3/3 - 0s - loss: 6.1931e-06 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/2000\n",
      "3/3 - 0s - loss: 3.2419e-06 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 1.0000\n",
      "Epoch 716/2000\n",
      "3/3 - 0s - loss: 4.8139e-06 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 1.0000\n",
      "Epoch 717/2000\n",
      "3/3 - 0s - loss: 4.6205e-06 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 1.0000\n",
      "Epoch 718/2000\n",
      "3/3 - 0s - loss: 4.7362e-06 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 1.0000\n",
      "Epoch 719/2000\n",
      "3/3 - 0s - loss: 5.0378e-06 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 1.0000\n",
      "Epoch 720/2000\n",
      "3/3 - 0s - loss: 4.4599e-06 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 1.0000\n",
      "Epoch 721/2000\n",
      "3/3 - 0s - loss: 7.2552e-06 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
      "Epoch 722/2000\n",
      "3/3 - 0s - loss: 4.6094e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 1.0000\n",
      "Epoch 723/2000\n",
      "3/3 - 0s - loss: 4.0405e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 1.0000\n",
      "Epoch 724/2000\n",
      "3/3 - 0s - loss: 3.6896e-06 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 1.0000\n",
      "Epoch 725/2000\n",
      "3/3 - 0s - loss: 5.2491e-06 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 1.0000\n",
      "Epoch 726/2000\n",
      "3/3 - 0s - loss: 4.3644e-06 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
      "Epoch 727/2000\n",
      "3/3 - 0s - loss: 3.8359e-06 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
      "Epoch 728/2000\n",
      "3/3 - 0s - loss: 3.6231e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 729/2000\n",
      "3/3 - 0s - loss: 4.9277e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 730/2000\n",
      "3/3 - 0s - loss: 5.6126e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 731/2000\n",
      "3/3 - 0s - loss: 5.4477e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 732/2000\n",
      "3/3 - 0s - loss: 5.5835e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 733/2000\n",
      "3/3 - 0s - loss: 5.0235e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 734/2000\n",
      "3/3 - 0s - loss: 3.7072e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 735/2000\n",
      "3/3 - 0s - loss: 6.8144e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 736/2000\n",
      "3/3 - 0s - loss: 5.2566e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 737/2000\n",
      "3/3 - 0s - loss: 4.8296e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 738/2000\n",
      "3/3 - 0s - loss: 4.1893e-06 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 739/2000\n",
      "3/3 - 0s - loss: 5.4612e-06 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 1.0000\n",
      "Epoch 740/2000\n",
      "3/3 - 0s - loss: 4.6632e-06 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 1.0000\n",
      "Epoch 741/2000\n",
      "3/3 - 0s - loss: 3.6641e-06 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 1.0000\n",
      "Epoch 742/2000\n",
      "3/3 - 0s - loss: 3.6629e-06 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 1.0000\n",
      "Epoch 743/2000\n",
      "3/3 - 0s - loss: 4.7645e-06 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 1.0000\n",
      "Epoch 744/2000\n",
      "3/3 - 0s - loss: 5.8329e-06 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 1.0000\n",
      "Epoch 745/2000\n",
      "3/3 - 0s - loss: 3.5341e-06 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 1.0000\n",
      "Epoch 746/2000\n",
      "3/3 - 0s - loss: 4.8318e-06 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 1.0000\n",
      "Epoch 747/2000\n",
      "3/3 - 0s - loss: 4.8465e-06 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 1.0000\n",
      "Epoch 748/2000\n",
      "3/3 - 0s - loss: 4.8136e-06 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 1.0000\n",
      "Epoch 749/2000\n",
      "3/3 - 0s - loss: 3.7642e-06 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 1.0000\n",
      "Epoch 750/2000\n",
      "3/3 - 0s - loss: 3.0032e-06 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 1.0000\n",
      "Epoch 751/2000\n",
      "3/3 - 0s - loss: 3.9078e-06 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 1.0000\n",
      "Epoch 752/2000\n",
      "3/3 - 0s - loss: 5.0726e-06 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 1.0000\n",
      "Epoch 753/2000\n",
      "3/3 - 0s - loss: 3.5879e-06 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 1.0000\n",
      "Epoch 754/2000\n",
      "3/3 - 0s - loss: 3.3754e-06 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 1.0000\n",
      "Epoch 755/2000\n",
      "3/3 - 0s - loss: 4.3946e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 756/2000\n",
      "3/3 - 0s - loss: 5.1870e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 757/2000\n",
      "3/3 - 0s - loss: 3.5728e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 758/2000\n",
      "3/3 - 0s - loss: 4.3501e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 759/2000\n",
      "3/3 - 0s - loss: 5.0412e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 760/2000\n",
      "3/3 - 0s - loss: 4.2700e-06 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
      "Epoch 761/2000\n",
      "3/3 - 0s - loss: 5.9344e-06 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
      "Epoch 762/2000\n",
      "3/3 - 0s - loss: 4.9826e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 763/2000\n",
      "3/3 - 0s - loss: 3.8959e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 764/2000\n",
      "3/3 - 0s - loss: 3.6361e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 765/2000\n",
      "3/3 - 0s - loss: 3.5388e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 766/2000\n",
      "3/3 - 0s - loss: 4.2128e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 767/2000\n",
      "3/3 - 0s - loss: 3.1619e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 768/2000\n",
      "3/3 - 0s - loss: 4.4717e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 769/2000\n",
      "3/3 - 0s - loss: 3.6011e-06 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 770/2000\n",
      "3/3 - 0s - loss: 4.3828e-06 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
      "Epoch 771/2000\n",
      "3/3 - 0s - loss: 3.4081e-06 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
      "Epoch 772/2000\n",
      "3/3 - 0s - loss: 3.5871e-06 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
      "Epoch 773/2000\n",
      "3/3 - 0s - loss: 3.6360e-06 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
      "Epoch 774/2000\n",
      "3/3 - 0s - loss: 5.1863e-06 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
      "Epoch 775/2000\n",
      "3/3 - 0s - loss: 5.1501e-06 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 1.0000\n",
      "Epoch 776/2000\n",
      "3/3 - 0s - loss: 4.9937e-06 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 1.0000\n",
      "Epoch 777/2000\n",
      "3/3 - 0s - loss: 4.8928e-06 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 1.0000\n",
      "Epoch 778/2000\n",
      "3/3 - 0s - loss: 3.4829e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 779/2000\n",
      "3/3 - 0s - loss: 3.3715e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 780/2000\n",
      "3/3 - 0s - loss: 5.1965e-06 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 1.0000\n",
      "Epoch 781/2000\n",
      "3/3 - 0s - loss: 4.5383e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 782/2000\n",
      "3/3 - 0s - loss: 2.7612e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 783/2000\n",
      "3/3 - 0s - loss: 3.7327e-06 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 1.0000\n",
      "Epoch 784/2000\n",
      "3/3 - 0s - loss: 3.5094e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 785/2000\n",
      "3/3 - 0s - loss: 3.4573e-06 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 786/2000\n",
      "3/3 - 0s - loss: 3.9093e-06 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 1.0000\n",
      "Epoch 787/2000\n",
      "3/3 - 0s - loss: 4.5952e-06 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 788/2000\n",
      "3/3 - 0s - loss: 3.2392e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 789/2000\n",
      "3/3 - 0s - loss: 3.7671e-06 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 790/2000\n",
      "3/3 - 0s - loss: 4.6381e-06 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 791/2000\n",
      "3/3 - 0s - loss: 3.6824e-06 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 792/2000\n",
      "3/3 - 0s - loss: 3.4702e-06 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 793/2000\n",
      "3/3 - 0s - loss: 3.3058e-06 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/2000\n",
      "3/3 - 0s - loss: 5.7909e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 795/2000\n",
      "3/3 - 0s - loss: 5.4942e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 796/2000\n",
      "3/3 - 0s - loss: 4.8771e-06 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 797/2000\n",
      "3/3 - 0s - loss: 4.2097e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 798/2000\n",
      "3/3 - 0s - loss: 4.3020e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 799/2000\n",
      "3/3 - 0s - loss: 3.7700e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 1.0000\n",
      "Epoch 800/2000\n",
      "3/3 - 0s - loss: 4.0908e-06 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 1.0000\n",
      "Epoch 801/2000\n",
      "3/3 - 0s - loss: 3.5682e-06 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 1.0000\n",
      "Epoch 802/2000\n",
      "3/3 - 0s - loss: 3.8970e-06 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 803/2000\n",
      "3/3 - 0s - loss: 3.7864e-06 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 1.0000\n",
      "Epoch 804/2000\n",
      "3/3 - 0s - loss: 3.7746e-06 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 1.0000\n",
      "Epoch 805/2000\n",
      "3/3 - 0s - loss: 3.8241e-06 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 1.0000\n",
      "Epoch 806/2000\n",
      "3/3 - 0s - loss: 2.6588e-06 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 1.0000\n",
      "Epoch 807/2000\n",
      "3/3 - 0s - loss: 3.5033e-06 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 1.0000\n",
      "Epoch 808/2000\n",
      "3/3 - 0s - loss: 2.8963e-06 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 1.0000\n",
      "Epoch 809/2000\n",
      "3/3 - 0s - loss: 3.4227e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 810/2000\n",
      "3/3 - 0s - loss: 4.9171e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 811/2000\n",
      "3/3 - 0s - loss: 3.4508e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 1.0000\n",
      "Epoch 812/2000\n",
      "3/3 - 0s - loss: 3.8750e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 1.0000\n",
      "Epoch 813/2000\n",
      "3/3 - 0s - loss: 3.8044e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 1.0000\n",
      "Epoch 814/2000\n",
      "3/3 - 0s - loss: 4.0993e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 1.0000\n",
      "Epoch 815/2000\n",
      "3/3 - 0s - loss: 2.8341e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 1.0000\n",
      "Epoch 816/2000\n",
      "3/3 - 0s - loss: 2.9355e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 817/2000\n",
      "3/3 - 0s - loss: 3.1590e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 818/2000\n",
      "3/3 - 0s - loss: 3.3092e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 819/2000\n",
      "3/3 - 0s - loss: 3.8410e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 820/2000\n",
      "3/3 - 0s - loss: 6.5425e-06 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 821/2000\n",
      "3/3 - 0s - loss: 3.5873e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 1.0000\n",
      "Epoch 822/2000\n",
      "3/3 - 0s - loss: 3.8919e-06 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 1.0000\n",
      "Epoch 823/2000\n",
      "3/3 - 0s - loss: 3.0120e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 824/2000\n",
      "3/3 - 0s - loss: 3.2911e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 825/2000\n",
      "3/3 - 0s - loss: 4.0951e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 826/2000\n",
      "3/3 - 0s - loss: 3.6113e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 827/2000\n",
      "3/3 - 0s - loss: 4.3892e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 828/2000\n",
      "3/3 - 0s - loss: 3.1301e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 829/2000\n",
      "3/3 - 0s - loss: 4.6283e-06 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 1.0000\n",
      "Epoch 830/2000\n",
      "3/3 - 0s - loss: 2.9838e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 831/2000\n",
      "3/3 - 0s - loss: 3.7147e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 832/2000\n",
      "3/3 - 0s - loss: 2.9444e-06 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 1.0000\n",
      "Epoch 833/2000\n",
      "3/3 - 0s - loss: 3.2349e-06 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 1.0000\n",
      "Epoch 834/2000\n",
      "3/3 - 0s - loss: 4.9964e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 835/2000\n",
      "3/3 - 0s - loss: 3.9785e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 836/2000\n",
      "3/3 - 0s - loss: 3.4055e-06 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 837/2000\n",
      "3/3 - 0s - loss: 2.9801e-06 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 1.0000\n",
      "Epoch 838/2000\n",
      "3/3 - 0s - loss: 3.8187e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 839/2000\n",
      "3/3 - 0s - loss: 4.2016e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 840/2000\n",
      "3/3 - 0s - loss: 4.7351e-06 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 841/2000\n",
      "3/3 - 0s - loss: 2.9247e-06 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 1.0000\n",
      "Epoch 842/2000\n",
      "3/3 - 0s - loss: 4.8258e-06 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 1.0000\n",
      "Epoch 843/2000\n",
      "3/3 - 0s - loss: 3.0901e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 844/2000\n",
      "3/3 - 0s - loss: 4.0019e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 845/2000\n",
      "3/3 - 0s - loss: 3.5680e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 846/2000\n",
      "3/3 - 0s - loss: 2.6186e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 847/2000\n",
      "3/3 - 0s - loss: 2.8312e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 848/2000\n",
      "3/3 - 0s - loss: 3.8761e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 849/2000\n",
      "3/3 - 0s - loss: 3.7343e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
      "Epoch 850/2000\n",
      "3/3 - 0s - loss: 5.0337e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
      "Epoch 851/2000\n",
      "3/3 - 0s - loss: 4.2162e-06 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 1.0000\n",
      "Epoch 852/2000\n",
      "3/3 - 0s - loss: 2.7463e-06 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 1.0000\n",
      "Epoch 853/2000\n",
      "3/3 - 0s - loss: 4.3591e-06 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 1.0000\n",
      "Epoch 854/2000\n",
      "3/3 - 0s - loss: 3.8665e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 855/2000\n",
      "3/3 - 0s - loss: 3.0668e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 856/2000\n",
      "3/3 - 0s - loss: 2.8284e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 857/2000\n",
      "3/3 - 0s - loss: 5.4961e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 858/2000\n",
      "3/3 - 0s - loss: 2.8034e-06 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 1.0000\n",
      "Epoch 859/2000\n",
      "3/3 - 0s - loss: 2.7187e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 860/2000\n",
      "3/3 - 0s - loss: 2.5166e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 861/2000\n",
      "3/3 - 0s - loss: 2.9175e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 862/2000\n",
      "3/3 - 0s - loss: 3.2286e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 863/2000\n",
      "3/3 - 0s - loss: 4.6798e-06 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 1.0000\n",
      "Epoch 864/2000\n",
      "3/3 - 0s - loss: 2.7307e-06 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 1.0000\n",
      "Epoch 865/2000\n",
      "3/3 - 0s - loss: 3.2832e-06 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 1.0000\n",
      "Epoch 866/2000\n",
      "3/3 - 0s - loss: 3.8277e-06 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 1.0000\n",
      "Epoch 867/2000\n",
      "3/3 - 0s - loss: 4.1044e-06 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
      "Epoch 868/2000\n",
      "3/3 - 0s - loss: 3.0987e-06 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
      "Epoch 869/2000\n",
      "3/3 - 0s - loss: 2.9241e-06 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 1.0000\n",
      "Epoch 870/2000\n",
      "3/3 - 0s - loss: 4.6185e-06 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 1.0000\n",
      "Epoch 871/2000\n",
      "3/3 - 0s - loss: 3.0663e-06 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 1.0000\n",
      "Epoch 872/2000\n",
      "3/3 - 0s - loss: 2.3504e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/2000\n",
      "3/3 - 0s - loss: 3.8248e-06 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 874/2000\n",
      "3/3 - 0s - loss: 3.9193e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 875/2000\n",
      "3/3 - 0s - loss: 2.5829e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 876/2000\n",
      "3/3 - 0s - loss: 4.1446e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 877/2000\n",
      "3/3 - 0s - loss: 3.4280e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 878/2000\n",
      "3/3 - 0s - loss: 2.2330e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 879/2000\n",
      "3/3 - 0s - loss: 4.5049e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 880/2000\n",
      "3/3 - 0s - loss: 2.5271e-06 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 881/2000\n",
      "3/3 - 0s - loss: 3.2934e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 882/2000\n",
      "3/3 - 0s - loss: 3.5635e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 883/2000\n",
      "3/3 - 0s - loss: 2.2257e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 884/2000\n",
      "3/3 - 0s - loss: 2.6267e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 885/2000\n",
      "3/3 - 0s - loss: 3.6594e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 886/2000\n",
      "3/3 - 0s - loss: 3.0855e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 887/2000\n",
      "3/3 - 0s - loss: 3.1605e-06 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
      "Epoch 888/2000\n",
      "3/3 - 0s - loss: 2.9372e-06 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 889/2000\n",
      "3/3 - 0s - loss: 3.4910e-06 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 890/2000\n",
      "3/3 - 0s - loss: 1.9621e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 891/2000\n",
      "3/3 - 0s - loss: 2.4843e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 892/2000\n",
      "3/3 - 0s - loss: 3.3106e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 893/2000\n",
      "3/3 - 0s - loss: 4.4354e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 894/2000\n",
      "3/3 - 0s - loss: 2.9513e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 895/2000\n",
      "3/3 - 0s - loss: 2.6343e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 896/2000\n",
      "3/3 - 0s - loss: 3.5032e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 897/2000\n",
      "3/3 - 0s - loss: 2.9334e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 898/2000\n",
      "3/3 - 0s - loss: 3.2253e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 899/2000\n",
      "3/3 - 0s - loss: 2.0614e-06 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 900/2000\n",
      "3/3 - 0s - loss: 3.3537e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 901/2000\n",
      "3/3 - 0s - loss: 2.3821e-06 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 902/2000\n",
      "3/3 - 0s - loss: 2.8228e-06 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 1.0000\n",
      "Epoch 903/2000\n",
      "3/3 - 0s - loss: 3.4051e-06 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 1.0000\n",
      "Epoch 904/2000\n",
      "3/3 - 0s - loss: 2.4648e-06 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 1.0000\n",
      "Epoch 905/2000\n",
      "3/3 - 0s - loss: 2.7708e-06 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 1.0000\n",
      "Epoch 906/2000\n",
      "3/3 - 0s - loss: 3.8145e-06 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 907/2000\n",
      "3/3 - 0s - loss: 4.0685e-06 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 1.0000\n",
      "Epoch 908/2000\n",
      "3/3 - 0s - loss: 2.6928e-06 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 1.0000\n",
      "Epoch 909/2000\n",
      "3/3 - 0s - loss: 2.4605e-06 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 1.0000\n",
      "Epoch 910/2000\n",
      "3/3 - 0s - loss: 4.7189e-06 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 1.0000\n",
      "Epoch 911/2000\n",
      "3/3 - 0s - loss: 2.9740e-06 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 1.0000\n",
      "Epoch 912/2000\n",
      "3/3 - 0s - loss: 2.9925e-06 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 1.0000\n",
      "Epoch 913/2000\n",
      "3/3 - 0s - loss: 2.8573e-06 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 1.0000\n",
      "Epoch 914/2000\n",
      "3/3 - 0s - loss: 2.8043e-06 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 1.0000\n",
      "Epoch 915/2000\n",
      "3/3 - 0s - loss: 2.4317e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 916/2000\n",
      "3/3 - 0s - loss: 2.9137e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 917/2000\n",
      "3/3 - 0s - loss: 2.8795e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 918/2000\n",
      "3/3 - 0s - loss: 2.6680e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 919/2000\n",
      "3/3 - 0s - loss: 2.8100e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 920/2000\n",
      "3/3 - 0s - loss: 3.5281e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 921/2000\n",
      "3/3 - 0s - loss: 2.7363e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 922/2000\n",
      "3/3 - 0s - loss: 2.8945e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 923/2000\n",
      "3/3 - 0s - loss: 2.9306e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 924/2000\n",
      "3/3 - 0s - loss: 2.8822e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 925/2000\n",
      "3/3 - 0s - loss: 4.5772e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 926/2000\n",
      "3/3 - 0s - loss: 2.5070e-06 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 1.0000\n",
      "Epoch 927/2000\n",
      "3/3 - 0s - loss: 2.6167e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 928/2000\n",
      "3/3 - 0s - loss: 3.1005e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 929/2000\n",
      "3/3 - 0s - loss: 2.0219e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 930/2000\n",
      "3/3 - 0s - loss: 2.7761e-06 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 931/2000\n",
      "3/3 - 0s - loss: 2.4923e-06 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 1.0000\n",
      "Epoch 932/2000\n",
      "3/3 - 0s - loss: 2.8206e-06 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
      "Epoch 933/2000\n",
      "3/3 - 0s - loss: 2.2215e-06 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "Epoch 934/2000\n",
      "3/3 - 0s - loss: 2.9402e-06 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "Epoch 935/2000\n",
      "3/3 - 0s - loss: 2.2594e-06 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 1.0000\n",
      "Epoch 936/2000\n",
      "3/3 - 0s - loss: 2.0750e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
      "Epoch 937/2000\n",
      "3/3 - 0s - loss: 3.1427e-06 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
      "Epoch 938/2000\n",
      "3/3 - 0s - loss: 2.9117e-06 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 1.0000\n",
      "Epoch 939/2000\n",
      "3/3 - 0s - loss: 2.5294e-06 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 1.0000\n",
      "Epoch 940/2000\n",
      "3/3 - 0s - loss: 3.0609e-06 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 1.0000\n",
      "Epoch 941/2000\n",
      "3/3 - 0s - loss: 2.7063e-06 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 1.0000\n",
      "Epoch 942/2000\n",
      "3/3 - 0s - loss: 2.8142e-06 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
      "Epoch 943/2000\n",
      "3/3 - 0s - loss: 2.9170e-06 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 1.0000\n",
      "Epoch 944/2000\n",
      "3/3 - 0s - loss: 2.0412e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 945/2000\n",
      "3/3 - 0s - loss: 2.4423e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 946/2000\n",
      "3/3 - 0s - loss: 3.2274e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 947/2000\n",
      "3/3 - 0s - loss: 2.7664e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 948/2000\n",
      "3/3 - 0s - loss: 2.7105e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 949/2000\n",
      "3/3 - 0s - loss: 3.2035e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 950/2000\n",
      "3/3 - 0s - loss: 2.3557e-06 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 1.0000\n",
      "Epoch 951/2000\n",
      "3/3 - 0s - loss: 3.5558e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/2000\n",
      "3/3 - 0s - loss: 2.4359e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 953/2000\n",
      "3/3 - 0s - loss: 3.1983e-06 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 1.0000\n",
      "Epoch 954/2000\n",
      "3/3 - 0s - loss: 2.8550e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 955/2000\n",
      "3/3 - 0s - loss: 2.8760e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 956/2000\n",
      "3/3 - 0s - loss: 4.0620e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 957/2000\n",
      "3/3 - 0s - loss: 2.6890e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 958/2000\n",
      "3/3 - 0s - loss: 3.2616e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 959/2000\n",
      "3/3 - 0s - loss: 3.0144e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 960/2000\n",
      "3/3 - 0s - loss: 3.4744e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 961/2000\n",
      "3/3 - 0s - loss: 1.9152e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 962/2000\n",
      "3/3 - 0s - loss: 2.6626e-06 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 963/2000\n",
      "3/3 - 0s - loss: 3.5790e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 964/2000\n",
      "3/3 - 0s - loss: 3.3701e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 965/2000\n",
      "3/3 - 0s - loss: 2.3167e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 966/2000\n",
      "3/3 - 0s - loss: 2.8574e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 967/2000\n",
      "3/3 - 0s - loss: 2.1383e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 968/2000\n",
      "3/3 - 0s - loss: 2.1181e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 969/2000\n",
      "3/3 - 0s - loss: 2.1969e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 970/2000\n",
      "3/3 - 0s - loss: 1.7979e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 971/2000\n",
      "3/3 - 0s - loss: 1.7859e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 972/2000\n",
      "3/3 - 0s - loss: 1.9945e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 973/2000\n",
      "3/3 - 0s - loss: 3.5831e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 974/2000\n",
      "3/3 - 0s - loss: 2.1832e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 975/2000\n",
      "3/3 - 0s - loss: 2.0020e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 976/2000\n",
      "3/3 - 0s - loss: 2.5136e-06 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 1.0000\n",
      "Epoch 977/2000\n",
      "3/3 - 0s - loss: 2.2967e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 978/2000\n",
      "3/3 - 0s - loss: 2.6323e-06 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 979/2000\n",
      "3/3 - 0s - loss: 1.7645e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 980/2000\n",
      "3/3 - 0s - loss: 2.0641e-06 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 1.0000\n",
      "Epoch 981/2000\n",
      "3/3 - 0s - loss: 1.9568e-06 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 1.0000\n",
      "Epoch 982/2000\n",
      "3/3 - 0s - loss: 3.2509e-06 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 1.0000\n",
      "Epoch 983/2000\n",
      "3/3 - 0s - loss: 2.4866e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
      "Epoch 984/2000\n",
      "3/3 - 0s - loss: 1.8447e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 985/2000\n",
      "3/3 - 0s - loss: 3.6077e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 986/2000\n",
      "3/3 - 0s - loss: 2.4196e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 987/2000\n",
      "3/3 - 0s - loss: 2.3049e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 988/2000\n",
      "3/3 - 0s - loss: 2.3314e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 989/2000\n",
      "3/3 - 0s - loss: 3.0488e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 990/2000\n",
      "3/3 - 0s - loss: 1.7219e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 991/2000\n",
      "3/3 - 0s - loss: 1.9821e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 992/2000\n",
      "3/3 - 0s - loss: 5.1114e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 993/2000\n",
      "3/3 - 0s - loss: 2.8206e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 994/2000\n",
      "3/3 - 0s - loss: 1.7708e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 995/2000\n",
      "3/3 - 0s - loss: 2.0710e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 996/2000\n",
      "3/3 - 0s - loss: 2.6210e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 997/2000\n",
      "3/3 - 0s - loss: 2.3557e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
      "Epoch 998/2000\n",
      "3/3 - 0s - loss: 2.0887e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 999/2000\n",
      "3/3 - 0s - loss: 1.6268e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1000/2000\n",
      "3/3 - 0s - loss: 3.0225e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1001/2000\n",
      "3/3 - 0s - loss: 2.4785e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1002/2000\n",
      "3/3 - 0s - loss: 2.1389e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1003/2000\n",
      "3/3 - 0s - loss: 3.1269e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1004/2000\n",
      "3/3 - 0s - loss: 2.0378e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1005/2000\n",
      "3/3 - 0s - loss: 1.7123e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1006/2000\n",
      "3/3 - 0s - loss: 1.6644e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1007/2000\n",
      "3/3 - 0s - loss: 2.7905e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1008/2000\n",
      "3/3 - 0s - loss: 2.5063e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1009/2000\n",
      "3/3 - 0s - loss: 3.3427e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1010/2000\n",
      "3/3 - 0s - loss: 1.8253e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1011/2000\n",
      "3/3 - 0s - loss: 2.6588e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1012/2000\n",
      "3/3 - 0s - loss: 2.4266e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1013/2000\n",
      "3/3 - 0s - loss: 2.3776e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1014/2000\n",
      "3/3 - 0s - loss: 1.6820e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1015/2000\n",
      "3/3 - 0s - loss: 1.9602e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1016/2000\n",
      "3/3 - 0s - loss: 1.6250e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1017/2000\n",
      "3/3 - 0s - loss: 2.5361e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1018/2000\n",
      "3/3 - 0s - loss: 1.8746e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1019/2000\n",
      "3/3 - 0s - loss: 2.4574e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1020/2000\n",
      "3/3 - 0s - loss: 3.0606e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1021/2000\n",
      "3/3 - 0s - loss: 1.7271e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1022/2000\n",
      "3/3 - 0s - loss: 1.8900e-06 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 1.0000\n",
      "Epoch 1023/2000\n",
      "3/3 - 0s - loss: 1.4336e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1024/2000\n",
      "3/3 - 0s - loss: 3.1113e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1025/2000\n",
      "3/3 - 0s - loss: 2.1522e-06 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
      "Epoch 1026/2000\n",
      "3/3 - 0s - loss: 1.8113e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 1027/2000\n",
      "3/3 - 0s - loss: 3.0347e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 1028/2000\n",
      "3/3 - 0s - loss: 2.4753e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 1029/2000\n",
      "3/3 - 0s - loss: 1.5038e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n",
      "Epoch 1030/2000\n",
      "3/3 - 0s - loss: 1.9026e-06 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1031/2000\n",
      "3/3 - 0s - loss: 2.9012e-06 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 1032/2000\n",
      "3/3 - 0s - loss: 2.7610e-06 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 1.0000\n",
      "Epoch 1033/2000\n",
      "3/3 - 0s - loss: 3.0435e-06 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
      "Epoch 1034/2000\n",
      "3/3 - 0s - loss: 2.7670e-06 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 1.0000\n",
      "Epoch 1035/2000\n",
      "3/3 - 0s - loss: 2.4306e-06 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 1.0000\n",
      "Epoch 1036/2000\n",
      "3/3 - 0s - loss: 1.5024e-06 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
      "Epoch 1037/2000\n",
      "3/3 - 0s - loss: 2.8401e-06 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
      "Epoch 1038/2000\n",
      "3/3 - 0s - loss: 1.7728e-06 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 1.0000\n",
      "Epoch 1039/2000\n",
      "3/3 - 0s - loss: 3.1921e-06 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 1.0000\n",
      "Epoch 1040/2000\n",
      "3/3 - 0s - loss: 2.2627e-06 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 1.0000\n",
      "Epoch 1041/2000\n",
      "3/3 - 0s - loss: 1.8389e-06 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 1.0000\n",
      "Epoch 1042/2000\n",
      "3/3 - 0s - loss: 1.7932e-06 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 1.0000\n",
      "Epoch 1043/2000\n",
      "3/3 - 0s - loss: 1.9998e-06 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 1.0000\n",
      "Epoch 1044/2000\n",
      "3/3 - 0s - loss: 1.3429e-06 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 1045/2000\n",
      "3/3 - 0s - loss: 1.9477e-06 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 1046/2000\n",
      "3/3 - 0s - loss: 2.5235e-06 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 1047/2000\n",
      "3/3 - 0s - loss: 2.0705e-06 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 1048/2000\n",
      "3/3 - 0s - loss: 2.9836e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1049/2000\n",
      "3/3 - 0s - loss: 2.3717e-06 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 1050/2000\n",
      "3/3 - 0s - loss: 2.3649e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1051/2000\n",
      "3/3 - 0s - loss: 1.4547e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1052/2000\n",
      "3/3 - 0s - loss: 2.2429e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1053/2000\n",
      "3/3 - 0s - loss: 2.6662e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1054/2000\n",
      "3/3 - 0s - loss: 1.7141e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1055/2000\n",
      "3/3 - 0s - loss: 2.3288e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1056/2000\n",
      "3/3 - 0s - loss: 1.8965e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1057/2000\n",
      "3/3 - 0s - loss: 1.8893e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1058/2000\n",
      "3/3 - 0s - loss: 2.8956e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1059/2000\n",
      "3/3 - 0s - loss: 2.0784e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1060/2000\n",
      "3/3 - 0s - loss: 2.0525e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1061/2000\n",
      "3/3 - 0s - loss: 4.0086e-06 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 1062/2000\n",
      "3/3 - 0s - loss: 3.2222e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1063/2000\n",
      "3/3 - 0s - loss: 1.9094e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1064/2000\n",
      "3/3 - 0s - loss: 1.9756e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1065/2000\n",
      "3/3 - 0s - loss: 2.8544e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1066/2000\n",
      "3/3 - 0s - loss: 1.8024e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1067/2000\n",
      "3/3 - 0s - loss: 1.9373e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1068/2000\n",
      "3/3 - 0s - loss: 1.4116e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1069/2000\n",
      "3/3 - 0s - loss: 1.6956e-06 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 1.0000\n",
      "Epoch 1070/2000\n",
      "3/3 - 0s - loss: 1.3445e-06 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 1071/2000\n",
      "3/3 - 0s - loss: 1.8365e-06 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 1072/2000\n",
      "3/3 - 0s - loss: 2.2290e-06 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 1073/2000\n",
      "3/3 - 0s - loss: 1.7355e-06 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 1074/2000\n",
      "3/3 - 0s - loss: 1.8998e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1075/2000\n",
      "3/3 - 0s - loss: 1.9030e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1076/2000\n",
      "3/3 - 0s - loss: 1.9448e-06 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 1077/2000\n",
      "3/3 - 0s - loss: 1.8641e-06 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 1.0000\n",
      "Epoch 1078/2000\n",
      "3/3 - 0s - loss: 2.2276e-06 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 1.0000\n",
      "Epoch 1079/2000\n",
      "3/3 - 0s - loss: 1.9132e-06 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 1.0000\n",
      "Epoch 1080/2000\n",
      "3/3 - 0s - loss: 1.5618e-06 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 1.0000\n",
      "Epoch 1081/2000\n",
      "3/3 - 0s - loss: 2.1084e-06 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 1.0000\n",
      "Epoch 1082/2000\n",
      "3/3 - 0s - loss: 1.6263e-06 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 1.0000\n",
      "Epoch 1083/2000\n",
      "3/3 - 0s - loss: 1.7370e-06 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 1.0000\n",
      "Epoch 1084/2000\n",
      "3/3 - 0s - loss: 1.9342e-06 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 1.0000\n",
      "Epoch 1085/2000\n",
      "3/3 - 0s - loss: 1.4343e-06 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 1.0000\n",
      "Epoch 1086/2000\n",
      "3/3 - 0s - loss: 1.9298e-06 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 1.0000\n",
      "Epoch 1087/2000\n",
      "3/3 - 0s - loss: 1.4138e-06 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 1.0000\n",
      "Epoch 1088/2000\n",
      "3/3 - 0s - loss: 2.2275e-06 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
      "Epoch 1089/2000\n",
      "3/3 - 0s - loss: 2.1110e-06 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
      "Epoch 1090/2000\n",
      "3/3 - 0s - loss: 1.5234e-06 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 1.0000\n",
      "Epoch 1091/2000\n",
      "3/3 - 0s - loss: 1.8127e-06 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 1.0000\n",
      "Epoch 1092/2000\n",
      "3/3 - 0s - loss: 1.8413e-06 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 1.0000\n",
      "Epoch 1093/2000\n",
      "3/3 - 0s - loss: 2.0735e-06 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 1.0000\n",
      "Epoch 1094/2000\n",
      "3/3 - 0s - loss: 1.9494e-06 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 1.0000\n",
      "Epoch 1095/2000\n",
      "3/3 - 0s - loss: 1.5253e-06 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 1.0000\n",
      "Epoch 1096/2000\n",
      "3/3 - 0s - loss: 2.6303e-06 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 1.0000\n",
      "Epoch 1097/2000\n",
      "3/3 - 0s - loss: 2.2858e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 1098/2000\n",
      "3/3 - 0s - loss: 1.3030e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 1099/2000\n",
      "3/3 - 0s - loss: 1.6596e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1100/2000\n",
      "3/3 - 0s - loss: 1.7049e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1101/2000\n",
      "3/3 - 0s - loss: 1.9224e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1102/2000\n",
      "3/3 - 0s - loss: 1.4788e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1103/2000\n",
      "3/3 - 0s - loss: 1.9325e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1104/2000\n",
      "3/3 - 0s - loss: 2.0670e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1105/2000\n",
      "3/3 - 0s - loss: 2.3814e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1106/2000\n",
      "3/3 - 0s - loss: 2.0501e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1107/2000\n",
      "3/3 - 0s - loss: 1.4715e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 1108/2000\n",
      "3/3 - 0s - loss: 2.4055e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1109/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.2626e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 1110/2000\n",
      "3/3 - 0s - loss: 2.1656e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 1111/2000\n",
      "3/3 - 0s - loss: 2.4719e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1112/2000\n",
      "3/3 - 0s - loss: 1.5036e-06 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 1113/2000\n",
      "3/3 - 0s - loss: 2.2320e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1114/2000\n",
      "3/3 - 0s - loss: 1.3711e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1115/2000\n",
      "3/3 - 0s - loss: 1.4288e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1116/2000\n",
      "3/3 - 0s - loss: 1.3745e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1117/2000\n",
      "3/3 - 0s - loss: 1.6963e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1118/2000\n",
      "3/3 - 0s - loss: 1.8210e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1119/2000\n",
      "3/3 - 0s - loss: 2.0119e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1120/2000\n",
      "3/3 - 0s - loss: 1.8509e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1121/2000\n",
      "3/3 - 0s - loss: 2.0216e-06 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 1122/2000\n",
      "3/3 - 0s - loss: 1.8371e-06 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 1.0000\n",
      "Epoch 1123/2000\n",
      "3/3 - 0s - loss: 2.1100e-06 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 1124/2000\n",
      "3/3 - 0s - loss: 1.7138e-06 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 1125/2000\n",
      "3/3 - 0s - loss: 1.6639e-06 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 1126/2000\n",
      "3/3 - 0s - loss: 1.2892e-06 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 1127/2000\n",
      "3/3 - 0s - loss: 2.1037e-06 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 1.0000\n",
      "Epoch 1128/2000\n",
      "3/3 - 0s - loss: 1.5885e-06 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 1.0000\n",
      "Epoch 1129/2000\n",
      "3/3 - 0s - loss: 1.3778e-06 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
      "Epoch 1130/2000\n",
      "3/3 - 0s - loss: 1.6434e-06 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
      "Epoch 1131/2000\n",
      "3/3 - 0s - loss: 2.3540e-06 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
      "Epoch 1132/2000\n",
      "3/3 - 0s - loss: 3.5586e-06 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 1.0000\n",
      "Epoch 1133/2000\n",
      "3/3 - 0s - loss: 1.9046e-06 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 1.0000\n",
      "Epoch 1134/2000\n",
      "3/3 - 0s - loss: 1.9555e-06 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 1.0000\n",
      "Epoch 1135/2000\n",
      "3/3 - 0s - loss: 1.5794e-06 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 1.0000\n",
      "Epoch 1136/2000\n",
      "3/3 - 0s - loss: 2.0973e-06 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 1.0000\n",
      "Epoch 1137/2000\n",
      "3/3 - 0s - loss: 1.8348e-06 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
      "Epoch 1138/2000\n",
      "3/3 - 0s - loss: 1.3681e-06 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
      "Epoch 1139/2000\n",
      "3/3 - 0s - loss: 1.5838e-06 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 1140/2000\n",
      "3/3 - 0s - loss: 1.4383e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 1.0000\n",
      "Epoch 1141/2000\n",
      "3/3 - 0s - loss: 1.4100e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 1.0000\n",
      "Epoch 1142/2000\n",
      "3/3 - 0s - loss: 1.4246e-06 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 1143/2000\n",
      "3/3 - 0s - loss: 1.4100e-06 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 1144/2000\n",
      "3/3 - 0s - loss: 1.3363e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 1145/2000\n",
      "3/3 - 0s - loss: 1.3484e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 1146/2000\n",
      "3/3 - 0s - loss: 2.0674e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 1147/2000\n",
      "3/3 - 0s - loss: 1.3887e-06 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 1148/2000\n",
      "3/3 - 0s - loss: 2.4471e-06 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 1149/2000\n",
      "3/3 - 0s - loss: 1.8498e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 1.0000\n",
      "Epoch 1150/2000\n",
      "3/3 - 0s - loss: 2.1702e-06 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 1151/2000\n",
      "3/3 - 0s - loss: 1.1661e-06 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 1152/2000\n",
      "3/3 - 0s - loss: 1.1328e-06 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 1.0000\n",
      "Epoch 1153/2000\n",
      "3/3 - 0s - loss: 1.5532e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 1.0000\n",
      "Epoch 1154/2000\n",
      "3/3 - 0s - loss: 1.6750e-06 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 1.0000\n",
      "Epoch 1155/2000\n",
      "3/3 - 0s - loss: 2.1995e-06 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 1156/2000\n",
      "3/3 - 0s - loss: 1.3370e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 1157/2000\n",
      "3/3 - 0s - loss: 1.7148e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 1158/2000\n",
      "3/3 - 0s - loss: 1.8431e-06 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 1.0000\n",
      "Epoch 1159/2000\n",
      "3/3 - 0s - loss: 1.5819e-06 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 1.0000\n",
      "Epoch 1160/2000\n",
      "3/3 - 0s - loss: 1.6687e-06 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 1.0000\n",
      "Epoch 1161/2000\n",
      "3/3 - 0s - loss: 1.0899e-06 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 1.0000\n",
      "Epoch 1162/2000\n",
      "3/3 - 0s - loss: 2.3022e-06 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 1.0000\n",
      "Epoch 1163/2000\n",
      "3/3 - 0s - loss: 1.8567e-06 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 1.0000\n",
      "Epoch 1164/2000\n",
      "3/3 - 0s - loss: 1.2296e-06 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 1.0000\n",
      "Epoch 1165/2000\n",
      "3/3 - 0s - loss: 1.5017e-06 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 1.0000\n",
      "Epoch 1166/2000\n",
      "3/3 - 0s - loss: 1.2316e-06 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 1.0000\n",
      "Epoch 1167/2000\n",
      "3/3 - 0s - loss: 1.7329e-06 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 1.0000\n",
      "Epoch 1168/2000\n",
      "3/3 - 0s - loss: 1.3569e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1169/2000\n",
      "3/3 - 0s - loss: 1.2264e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1170/2000\n",
      "3/3 - 0s - loss: 2.3610e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1171/2000\n",
      "3/3 - 0s - loss: 1.3873e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1172/2000\n",
      "3/3 - 0s - loss: 1.2149e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1173/2000\n",
      "3/3 - 0s - loss: 1.5386e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1174/2000\n",
      "3/3 - 0s - loss: 1.4649e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1175/2000\n",
      "3/3 - 0s - loss: 1.6768e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1176/2000\n",
      "3/3 - 0s - loss: 1.3919e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1177/2000\n",
      "3/3 - 0s - loss: 1.6172e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1178/2000\n",
      "3/3 - 0s - loss: 2.1724e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1179/2000\n",
      "3/3 - 0s - loss: 1.5839e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1180/2000\n",
      "3/3 - 0s - loss: 1.3307e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1181/2000\n",
      "3/3 - 0s - loss: 1.5657e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1182/2000\n",
      "3/3 - 0s - loss: 1.7277e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1183/2000\n",
      "3/3 - 0s - loss: 1.7705e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1184/2000\n",
      "3/3 - 0s - loss: 1.3704e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1185/2000\n",
      "3/3 - 0s - loss: 1.7803e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1186/2000\n",
      "3/3 - 0s - loss: 1.5461e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1187/2000\n",
      "3/3 - 0s - loss: 2.1046e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1188/2000\n",
      "3/3 - 0s - loss: 1.7159e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1189/2000\n",
      "3/3 - 0s - loss: 1.0792e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1190/2000\n",
      "3/3 - 0s - loss: 2.0324e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1191/2000\n",
      "3/3 - 0s - loss: 1.1987e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1192/2000\n",
      "3/3 - 0s - loss: 1.5900e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1193/2000\n",
      "3/3 - 0s - loss: 1.5922e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1194/2000\n",
      "3/3 - 0s - loss: 1.5498e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1195/2000\n",
      "3/3 - 0s - loss: 1.3286e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1196/2000\n",
      "3/3 - 0s - loss: 9.3087e-07 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1197/2000\n",
      "3/3 - 0s - loss: 1.4680e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1198/2000\n",
      "3/3 - 0s - loss: 1.3677e-06 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 1199/2000\n",
      "3/3 - 0s - loss: 1.8341e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1200/2000\n",
      "3/3 - 0s - loss: 1.5610e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1201/2000\n",
      "3/3 - 0s - loss: 1.2896e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1202/2000\n",
      "3/3 - 0s - loss: 1.8376e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1203/2000\n",
      "3/3 - 0s - loss: 1.0645e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1204/2000\n",
      "3/3 - 0s - loss: 1.4712e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1205/2000\n",
      "3/3 - 0s - loss: 1.5250e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1206/2000\n",
      "3/3 - 0s - loss: 1.6939e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1207/2000\n",
      "3/3 - 0s - loss: 1.2382e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1208/2000\n",
      "3/3 - 0s - loss: 1.9284e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1209/2000\n",
      "3/3 - 0s - loss: 2.4178e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1210/2000\n",
      "3/3 - 0s - loss: 2.0085e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1211/2000\n",
      "3/3 - 0s - loss: 1.3798e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1212/2000\n",
      "3/3 - 0s - loss: 1.7753e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 1.0000\n",
      "Epoch 1213/2000\n",
      "3/3 - 0s - loss: 1.0492e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1214/2000\n",
      "3/3 - 0s - loss: 1.4997e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1215/2000\n",
      "3/3 - 0s - loss: 9.4929e-07 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1216/2000\n",
      "3/3 - 0s - loss: 1.7020e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1217/2000\n",
      "3/3 - 0s - loss: 2.0368e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1218/2000\n",
      "3/3 - 0s - loss: 1.0630e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1219/2000\n",
      "3/3 - 0s - loss: 1.4054e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1220/2000\n",
      "3/3 - 0s - loss: 1.8060e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1221/2000\n",
      "3/3 - 0s - loss: 1.2971e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1222/2000\n",
      "3/3 - 0s - loss: 1.5797e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1223/2000\n",
      "3/3 - 0s - loss: 1.6376e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 1224/2000\n",
      "3/3 - 0s - loss: 1.4301e-06 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 1.0000\n",
      "Epoch 1225/2000\n",
      "3/3 - 0s - loss: 1.4829e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1226/2000\n",
      "3/3 - 0s - loss: 1.7107e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1227/2000\n",
      "3/3 - 0s - loss: 1.7584e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1228/2000\n",
      "3/3 - 0s - loss: 1.9405e-06 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 1229/2000\n",
      "3/3 - 0s - loss: 1.1608e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1230/2000\n",
      "3/3 - 0s - loss: 1.5448e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1231/2000\n",
      "3/3 - 0s - loss: 1.2297e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1232/2000\n",
      "3/3 - 0s - loss: 1.8476e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1233/2000\n",
      "3/3 - 0s - loss: 1.3567e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1234/2000\n",
      "3/3 - 0s - loss: 1.8731e-06 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 1235/2000\n",
      "3/3 - 0s - loss: 1.4289e-06 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 1236/2000\n",
      "3/3 - 0s - loss: 1.1951e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1237/2000\n",
      "3/3 - 0s - loss: 1.3415e-06 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 1238/2000\n",
      "3/3 - 0s - loss: 2.4875e-06 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 1239/2000\n",
      "3/3 - 0s - loss: 8.8497e-07 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 1.0000\n",
      "Epoch 1240/2000\n",
      "3/3 - 0s - loss: 1.5784e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 1.0000\n",
      "Epoch 1241/2000\n",
      "3/3 - 0s - loss: 1.2801e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 1.0000\n",
      "Epoch 1242/2000\n",
      "3/3 - 0s - loss: 1.5304e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 1.0000\n",
      "Epoch 1243/2000\n",
      "3/3 - 0s - loss: 1.1041e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 1.0000\n",
      "Epoch 1244/2000\n",
      "3/3 - 0s - loss: 1.7093e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 1.0000\n",
      "Epoch 1245/2000\n",
      "3/3 - 0s - loss: 1.0478e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 1.0000\n",
      "Epoch 1246/2000\n",
      "3/3 - 0s - loss: 1.0909e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 1.0000\n",
      "Epoch 1247/2000\n",
      "3/3 - 0s - loss: 1.5679e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 1.0000\n",
      "Epoch 1248/2000\n",
      "3/3 - 0s - loss: 1.7397e-06 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 1.0000\n",
      "Epoch 1249/2000\n",
      "3/3 - 0s - loss: 1.4019e-06 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
      "Epoch 1250/2000\n",
      "3/3 - 0s - loss: 1.6456e-06 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
      "Epoch 1251/2000\n",
      "3/3 - 0s - loss: 1.1716e-06 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 1.0000\n",
      "Epoch 1252/2000\n",
      "3/3 - 0s - loss: 1.0725e-06 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 1.0000\n",
      "Epoch 1253/2000\n",
      "3/3 - 0s - loss: 1.1931e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1254/2000\n",
      "3/3 - 0s - loss: 1.4361e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1255/2000\n",
      "3/3 - 0s - loss: 1.2836e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1256/2000\n",
      "3/3 - 0s - loss: 1.4668e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1257/2000\n",
      "3/3 - 0s - loss: 1.2890e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1258/2000\n",
      "3/3 - 0s - loss: 1.5514e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1259/2000\n",
      "3/3 - 0s - loss: 1.4153e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1260/2000\n",
      "3/3 - 0s - loss: 9.3706e-07 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1261/2000\n",
      "3/3 - 0s - loss: 1.4785e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1262/2000\n",
      "3/3 - 0s - loss: 1.2481e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1263/2000\n",
      "3/3 - 0s - loss: 1.7031e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1264/2000\n",
      "3/3 - 0s - loss: 1.9155e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1265/2000\n",
      "3/3 - 0s - loss: 1.3352e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1266/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.2497e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1267/2000\n",
      "3/3 - 0s - loss: 1.4321e-06 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1268/2000\n",
      "3/3 - 0s - loss: 8.3565e-07 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1269/2000\n",
      "3/3 - 0s - loss: 9.7179e-07 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 1270/2000\n",
      "3/3 - 0s - loss: 1.4000e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1271/2000\n",
      "3/3 - 0s - loss: 1.0110e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 1272/2000\n",
      "3/3 - 0s - loss: 1.3173e-06 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
      "Epoch 1273/2000\n",
      "3/3 - 0s - loss: 1.3772e-06 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
      "Epoch 1274/2000\n",
      "3/3 - 0s - loss: 1.5061e-06 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
      "Epoch 1275/2000\n",
      "3/3 - 0s - loss: 1.5770e-06 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 1.0000\n",
      "Epoch 1276/2000\n",
      "3/3 - 0s - loss: 1.0253e-06 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 1.0000\n",
      "Epoch 1277/2000\n",
      "3/3 - 0s - loss: 1.1779e-06 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 1.0000\n",
      "Epoch 1278/2000\n",
      "3/3 - 0s - loss: 1.5235e-06 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 1.0000\n",
      "Epoch 1279/2000\n",
      "3/3 - 0s - loss: 1.2673e-06 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 1.0000\n",
      "Epoch 1280/2000\n",
      "3/3 - 0s - loss: 1.6293e-06 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 1.0000\n",
      "Epoch 1281/2000\n",
      "3/3 - 0s - loss: 1.2007e-06 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 1.0000\n",
      "Epoch 1282/2000\n",
      "3/3 - 0s - loss: 1.3558e-06 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 1.0000\n",
      "Epoch 1283/2000\n",
      "3/3 - 0s - loss: 1.3401e-06 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 1.0000\n",
      "Epoch 1284/2000\n",
      "3/3 - 0s - loss: 2.0736e-06 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 1.0000\n",
      "Epoch 1285/2000\n",
      "3/3 - 0s - loss: 1.0207e-06 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
      "Epoch 1286/2000\n",
      "3/3 - 0s - loss: 1.4775e-06 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
      "Epoch 1287/2000\n",
      "3/3 - 0s - loss: 1.5253e-06 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 1.0000\n",
      "Epoch 1288/2000\n",
      "3/3 - 0s - loss: 1.2408e-06 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 1.0000\n",
      "Epoch 1289/2000\n",
      "3/3 - 0s - loss: 1.1015e-06 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 1.0000\n",
      "Epoch 1290/2000\n",
      "3/3 - 0s - loss: 1.1433e-06 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 1.0000\n",
      "Epoch 1291/2000\n",
      "3/3 - 0s - loss: 1.3782e-06 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 1.0000\n",
      "Epoch 1292/2000\n",
      "3/3 - 0s - loss: 1.4528e-06 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 1.0000\n",
      "Epoch 1293/2000\n",
      "3/3 - 0s - loss: 1.6974e-06 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 1294/2000\n",
      "3/3 - 0s - loss: 1.3894e-06 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 1295/2000\n",
      "3/3 - 0s - loss: 1.4884e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1296/2000\n",
      "3/3 - 0s - loss: 1.4230e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1297/2000\n",
      "3/3 - 0s - loss: 1.5496e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1298/2000\n",
      "3/3 - 0s - loss: 9.1395e-07 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1299/2000\n",
      "3/3 - 0s - loss: 1.1082e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1300/2000\n",
      "3/3 - 0s - loss: 1.1639e-06 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 1301/2000\n",
      "3/3 - 0s - loss: 9.3590e-07 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 1302/2000\n",
      "3/3 - 0s - loss: 1.2442e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1303/2000\n",
      "3/3 - 0s - loss: 1.0267e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1304/2000\n",
      "3/3 - 0s - loss: 7.9943e-07 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1305/2000\n",
      "3/3 - 0s - loss: 1.0191e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1306/2000\n",
      "3/3 - 0s - loss: 1.2794e-06 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 1307/2000\n",
      "3/3 - 0s - loss: 1.2255e-06 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 1308/2000\n",
      "3/3 - 0s - loss: 1.6832e-06 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 1309/2000\n",
      "3/3 - 0s - loss: 1.2903e-06 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 1310/2000\n",
      "3/3 - 0s - loss: 9.1449e-07 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 1311/2000\n",
      "3/3 - 0s - loss: 1.0004e-06 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 1312/2000\n",
      "3/3 - 0s - loss: 1.5320e-06 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 1313/2000\n",
      "3/3 - 0s - loss: 9.8913e-07 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 1314/2000\n",
      "3/3 - 0s - loss: 1.3855e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1315/2000\n",
      "3/3 - 0s - loss: 1.3523e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1316/2000\n",
      "3/3 - 0s - loss: 1.5606e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1317/2000\n",
      "3/3 - 0s - loss: 9.4658e-07 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1318/2000\n",
      "3/3 - 0s - loss: 1.1070e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1319/2000\n",
      "3/3 - 0s - loss: 1.3150e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1320/2000\n",
      "3/3 - 0s - loss: 1.5461e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1321/2000\n",
      "3/3 - 0s - loss: 1.4891e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1322/2000\n",
      "3/3 - 0s - loss: 1.0972e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1323/2000\n",
      "3/3 - 0s - loss: 1.4037e-06 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 1324/2000\n",
      "3/3 - 0s - loss: 1.5534e-06 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 1325/2000\n",
      "3/3 - 0s - loss: 1.3210e-06 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 1326/2000\n",
      "3/3 - 0s - loss: 1.2549e-06 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 1327/2000\n",
      "3/3 - 0s - loss: 1.9006e-06 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 1328/2000\n",
      "3/3 - 0s - loss: 1.2027e-06 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 1329/2000\n",
      "3/3 - 0s - loss: 8.8491e-07 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 1.0000\n",
      "Epoch 1330/2000\n",
      "3/3 - 0s - loss: 1.6062e-06 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 1.0000\n",
      "Epoch 1331/2000\n",
      "3/3 - 0s - loss: 1.5321e-06 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 1.0000\n",
      "Epoch 1332/2000\n",
      "3/3 - 0s - loss: 1.1080e-06 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
      "Epoch 1333/2000\n",
      "3/3 - 0s - loss: 1.6285e-06 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 1.0000\n",
      "Epoch 1334/2000\n",
      "3/3 - 0s - loss: 1.9557e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1335/2000\n",
      "3/3 - 0s - loss: 9.7810e-07 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1336/2000\n",
      "3/3 - 0s - loss: 1.5770e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1337/2000\n",
      "3/3 - 0s - loss: 1.0427e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1338/2000\n",
      "3/3 - 0s - loss: 1.0894e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1339/2000\n",
      "3/3 - 0s - loss: 1.8799e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1340/2000\n",
      "3/3 - 0s - loss: 1.3169e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1341/2000\n",
      "3/3 - 0s - loss: 1.1753e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1342/2000\n",
      "3/3 - 0s - loss: 1.4847e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1343/2000\n",
      "3/3 - 0s - loss: 1.1576e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1344/2000\n",
      "3/3 - 0s - loss: 9.5184e-07 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1345/2000\n",
      "3/3 - 0s - loss: 8.2424e-07 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1346/2000\n",
      "3/3 - 0s - loss: 1.3067e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1347/2000\n",
      "3/3 - 0s - loss: 1.0645e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1348/2000\n",
      "3/3 - 0s - loss: 6.7341e-07 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1349/2000\n",
      "3/3 - 0s - loss: 1.1197e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1350/2000\n",
      "3/3 - 0s - loss: 1.0632e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1351/2000\n",
      "3/3 - 0s - loss: 1.1651e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1352/2000\n",
      "3/3 - 0s - loss: 1.9295e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1353/2000\n",
      "3/3 - 0s - loss: 1.0730e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1354/2000\n",
      "3/3 - 0s - loss: 1.1568e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1355/2000\n",
      "3/3 - 0s - loss: 1.6666e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1356/2000\n",
      "3/3 - 0s - loss: 8.7640e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1357/2000\n",
      "3/3 - 0s - loss: 5.8491e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1358/2000\n",
      "3/3 - 0s - loss: 1.0441e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1359/2000\n",
      "3/3 - 0s - loss: 1.3728e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1360/2000\n",
      "3/3 - 0s - loss: 1.2545e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1361/2000\n",
      "3/3 - 0s - loss: 8.5324e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1362/2000\n",
      "3/3 - 0s - loss: 1.3020e-06 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1363/2000\n",
      "3/3 - 0s - loss: 9.6264e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 1364/2000\n",
      "3/3 - 0s - loss: 1.6446e-06 - accuracy: 1.0000 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 1365/2000\n",
      "3/3 - 0s - loss: 9.9546e-07 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1366/2000\n",
      "3/3 - 0s - loss: 1.1331e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1367/2000\n",
      "3/3 - 0s - loss: 1.2392e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1368/2000\n",
      "3/3 - 0s - loss: 1.2859e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1369/2000\n",
      "3/3 - 0s - loss: 1.2001e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1370/2000\n",
      "3/3 - 0s - loss: 9.4067e-07 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1371/2000\n",
      "3/3 - 0s - loss: 1.4259e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1372/2000\n",
      "3/3 - 0s - loss: 1.0484e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1373/2000\n",
      "3/3 - 0s - loss: 1.1397e-06 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 1374/2000\n",
      "3/3 - 0s - loss: 9.3729e-07 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
      "Epoch 1375/2000\n",
      "3/3 - 0s - loss: 1.2294e-06 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
      "Epoch 1376/2000\n",
      "3/3 - 0s - loss: 1.0672e-06 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1377/2000\n",
      "3/3 - 0s - loss: 1.1391e-06 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 1378/2000\n",
      "3/3 - 0s - loss: 2.1845e-06 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 1379/2000\n",
      "3/3 - 0s - loss: 9.8035e-07 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1380/2000\n",
      "3/3 - 0s - loss: 1.0398e-06 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1381/2000\n",
      "3/3 - 0s - loss: 9.2869e-07 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1382/2000\n",
      "3/3 - 0s - loss: 1.1415e-06 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1383/2000\n",
      "3/3 - 0s - loss: 1.3875e-06 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1384/2000\n",
      "3/3 - 0s - loss: 1.2857e-06 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 1385/2000\n",
      "3/3 - 0s - loss: 2.3243e-06 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1386/2000\n",
      "3/3 - 0s - loss: 1.3323e-06 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1387/2000\n",
      "3/3 - 0s - loss: 6.3470e-07 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1388/2000\n",
      "3/3 - 0s - loss: 8.4824e-07 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
      "Epoch 1389/2000\n",
      "3/3 - 0s - loss: 1.1756e-06 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
      "Epoch 1390/2000\n",
      "3/3 - 0s - loss: 1.1854e-06 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1391/2000\n",
      "3/3 - 0s - loss: 1.3248e-06 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1392/2000\n",
      "3/3 - 0s - loss: 9.8614e-07 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 1393/2000\n",
      "3/3 - 0s - loss: 9.4724e-07 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1394/2000\n",
      "3/3 - 0s - loss: 8.8263e-07 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1395/2000\n",
      "3/3 - 0s - loss: 1.0647e-06 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 1396/2000\n",
      "3/3 - 0s - loss: 1.6516e-06 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 1397/2000\n",
      "3/3 - 0s - loss: 1.0561e-06 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
      "Epoch 1398/2000\n",
      "3/3 - 0s - loss: 2.0236e-06 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
      "Epoch 1399/2000\n",
      "3/3 - 0s - loss: 7.4643e-07 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
      "Epoch 1400/2000\n",
      "3/3 - 0s - loss: 1.0931e-06 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
      "Epoch 1401/2000\n",
      "3/3 - 0s - loss: 8.2511e-07 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 1402/2000\n",
      "3/3 - 0s - loss: 9.9795e-07 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 1403/2000\n",
      "3/3 - 0s - loss: 1.2149e-06 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 1404/2000\n",
      "3/3 - 0s - loss: 2.2474e-06 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 1.0000\n",
      "Epoch 1405/2000\n",
      "3/3 - 0s - loss: 9.1385e-07 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
      "Epoch 1406/2000\n",
      "3/3 - 0s - loss: 1.1377e-06 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1407/2000\n",
      "3/3 - 0s - loss: 9.7710e-07 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1408/2000\n",
      "3/3 - 0s - loss: 1.0147e-06 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 1409/2000\n",
      "3/3 - 0s - loss: 9.6415e-07 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 1410/2000\n",
      "3/3 - 0s - loss: 9.3659e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1411/2000\n",
      "3/3 - 0s - loss: 9.2841e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1412/2000\n",
      "3/3 - 0s - loss: 1.2034e-06 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1413/2000\n",
      "3/3 - 0s - loss: 8.1911e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1414/2000\n",
      "3/3 - 0s - loss: 9.9232e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1415/2000\n",
      "3/3 - 0s - loss: 9.1701e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1416/2000\n",
      "3/3 - 0s - loss: 1.2321e-06 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 1417/2000\n",
      "3/3 - 0s - loss: 6.5520e-07 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 1418/2000\n",
      "3/3 - 0s - loss: 1.0494e-06 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1419/2000\n",
      "3/3 - 0s - loss: 1.3657e-06 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1420/2000\n",
      "3/3 - 0s - loss: 7.9439e-07 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1421/2000\n",
      "3/3 - 0s - loss: 8.8905e-07 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1422/2000\n",
      "3/3 - 0s - loss: 7.5213e-07 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1423/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.2025e-06 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 1.0000\n",
      "Epoch 1424/2000\n",
      "3/3 - 0s - loss: 1.1374e-06 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 1425/2000\n",
      "3/3 - 0s - loss: 1.2837e-06 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 1426/2000\n",
      "3/3 - 0s - loss: 8.5083e-07 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 1.0000\n",
      "Epoch 1427/2000\n",
      "3/3 - 0s - loss: 1.1100e-06 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1428/2000\n",
      "3/3 - 0s - loss: 1.0631e-06 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1429/2000\n",
      "3/3 - 0s - loss: 9.7545e-07 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 1430/2000\n",
      "3/3 - 0s - loss: 1.1004e-06 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 1431/2000\n",
      "3/3 - 0s - loss: 1.3306e-06 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
      "Epoch 1432/2000\n",
      "3/3 - 0s - loss: 8.8417e-07 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
      "Epoch 1433/2000\n",
      "3/3 - 0s - loss: 1.1942e-06 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1434/2000\n",
      "3/3 - 0s - loss: 1.1211e-06 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1435/2000\n",
      "3/3 - 0s - loss: 8.1508e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1436/2000\n",
      "3/3 - 0s - loss: 8.8437e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1437/2000\n",
      "3/3 - 0s - loss: 7.3543e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1438/2000\n",
      "3/3 - 0s - loss: 6.4087e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1439/2000\n",
      "3/3 - 0s - loss: 8.7849e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1440/2000\n",
      "3/3 - 0s - loss: 8.7234e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1441/2000\n",
      "3/3 - 0s - loss: 1.1125e-06 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1442/2000\n",
      "3/3 - 0s - loss: 1.0932e-06 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1443/2000\n",
      "3/3 - 0s - loss: 8.7902e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1444/2000\n",
      "3/3 - 0s - loss: 1.5277e-06 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
      "Epoch 1445/2000\n",
      "3/3 - 0s - loss: 1.0905e-06 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 1446/2000\n",
      "3/3 - 0s - loss: 1.0654e-06 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 1447/2000\n",
      "3/3 - 0s - loss: 8.9400e-07 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 1448/2000\n",
      "3/3 - 0s - loss: 6.7800e-07 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1449/2000\n",
      "3/3 - 0s - loss: 8.2586e-07 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1450/2000\n",
      "3/3 - 0s - loss: 8.4033e-07 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1451/2000\n",
      "3/3 - 0s - loss: 1.0919e-06 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1452/2000\n",
      "3/3 - 0s - loss: 1.0764e-06 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1453/2000\n",
      "3/3 - 0s - loss: 9.0874e-07 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 1454/2000\n",
      "3/3 - 0s - loss: 1.0626e-06 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 1455/2000\n",
      "3/3 - 0s - loss: 9.8665e-07 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
      "Epoch 1456/2000\n",
      "3/3 - 0s - loss: 7.4673e-07 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 1.0000\n",
      "Epoch 1457/2000\n",
      "3/3 - 0s - loss: 9.0695e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1458/2000\n",
      "3/3 - 0s - loss: 9.2164e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1459/2000\n",
      "3/3 - 0s - loss: 9.3978e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1460/2000\n",
      "3/3 - 0s - loss: 7.1100e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1461/2000\n",
      "3/3 - 0s - loss: 8.5984e-07 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1462/2000\n",
      "3/3 - 0s - loss: 1.1370e-06 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 1463/2000\n",
      "3/3 - 0s - loss: 7.6412e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1464/2000\n",
      "3/3 - 0s - loss: 1.0266e-06 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1465/2000\n",
      "3/3 - 0s - loss: 9.6367e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1466/2000\n",
      "3/3 - 0s - loss: 6.6078e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1467/2000\n",
      "3/3 - 0s - loss: 7.1926e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 1468/2000\n",
      "3/3 - 0s - loss: 1.3331e-06 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 1.0000\n",
      "Epoch 1469/2000\n",
      "3/3 - 0s - loss: 8.3587e-07 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
      "Epoch 1470/2000\n",
      "3/3 - 0s - loss: 1.1979e-06 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
      "Epoch 1471/2000\n",
      "3/3 - 0s - loss: 9.5968e-07 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
      "Epoch 1472/2000\n",
      "3/3 - 0s - loss: 7.6614e-07 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 1.0000\n",
      "Epoch 1473/2000\n",
      "3/3 - 0s - loss: 1.0389e-06 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 1.0000\n",
      "Epoch 1474/2000\n",
      "3/3 - 0s - loss: 2.0191e-06 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 1.0000\n",
      "Epoch 1475/2000\n",
      "3/3 - 0s - loss: 1.1226e-06 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 1.0000\n",
      "Epoch 1476/2000\n",
      "3/3 - 0s - loss: 8.9830e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1477/2000\n",
      "3/3 - 0s - loss: 8.6187e-07 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 1478/2000\n",
      "3/3 - 0s - loss: 7.7673e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1479/2000\n",
      "3/3 - 0s - loss: 1.0045e-06 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1480/2000\n",
      "3/3 - 0s - loss: 7.7726e-07 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1481/2000\n",
      "3/3 - 0s - loss: 9.0178e-07 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1482/2000\n",
      "3/3 - 0s - loss: 9.2390e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1483/2000\n",
      "3/3 - 0s - loss: 7.0314e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1484/2000\n",
      "3/3 - 0s - loss: 8.8330e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1485/2000\n",
      "3/3 - 0s - loss: 7.4925e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1486/2000\n",
      "3/3 - 0s - loss: 8.4433e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1487/2000\n",
      "3/3 - 0s - loss: 9.4606e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1488/2000\n",
      "3/3 - 0s - loss: 1.3816e-06 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 1489/2000\n",
      "3/3 - 0s - loss: 9.4559e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1490/2000\n",
      "3/3 - 0s - loss: 7.6145e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1491/2000\n",
      "3/3 - 0s - loss: 8.4506e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1492/2000\n",
      "3/3 - 0s - loss: 1.0243e-06 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 1.0000\n",
      "Epoch 1493/2000\n",
      "3/3 - 0s - loss: 1.3488e-06 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1494/2000\n",
      "3/3 - 0s - loss: 1.2474e-06 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1495/2000\n",
      "3/3 - 0s - loss: 5.4191e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 1.0000\n",
      "Epoch 1496/2000\n",
      "3/3 - 0s - loss: 1.3521e-06 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 1497/2000\n",
      "3/3 - 0s - loss: 9.3992e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1498/2000\n",
      "3/3 - 0s - loss: 7.3458e-07 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1499/2000\n",
      "3/3 - 0s - loss: 9.4798e-07 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 1500/2000\n",
      "3/3 - 0s - loss: 7.3672e-07 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 1501/2000\n",
      "3/3 - 0s - loss: 9.5156e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1502/2000\n",
      "3/3 - 0s - loss: 8.3603e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1503/2000\n",
      "3/3 - 0s - loss: 1.1563e-06 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1504/2000\n",
      "3/3 - 0s - loss: 7.7542e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1505/2000\n",
      "3/3 - 0s - loss: 1.0177e-06 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1506/2000\n",
      "3/3 - 0s - loss: 7.0052e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1507/2000\n",
      "3/3 - 0s - loss: 8.9880e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1508/2000\n",
      "3/3 - 0s - loss: 9.2738e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1509/2000\n",
      "3/3 - 0s - loss: 5.7372e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1510/2000\n",
      "3/3 - 0s - loss: 8.7374e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1511/2000\n",
      "3/3 - 0s - loss: 8.1329e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1512/2000\n",
      "3/3 - 0s - loss: 1.0106e-06 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1513/2000\n",
      "3/3 - 0s - loss: 1.3235e-06 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1514/2000\n",
      "3/3 - 0s - loss: 8.8479e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1515/2000\n",
      "3/3 - 0s - loss: 9.9168e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1516/2000\n",
      "3/3 - 0s - loss: 7.3958e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1517/2000\n",
      "3/3 - 0s - loss: 9.1456e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1518/2000\n",
      "3/3 - 0s - loss: 1.2262e-06 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1519/2000\n",
      "3/3 - 0s - loss: 9.2535e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1520/2000\n",
      "3/3 - 0s - loss: 9.9756e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1521/2000\n",
      "3/3 - 0s - loss: 1.1865e-06 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1522/2000\n",
      "3/3 - 0s - loss: 8.8545e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1523/2000\n",
      "3/3 - 0s - loss: 5.7984e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1524/2000\n",
      "3/3 - 0s - loss: 1.0042e-06 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1525/2000\n",
      "3/3 - 0s - loss: 1.3885e-06 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1526/2000\n",
      "3/3 - 0s - loss: 9.3778e-07 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1527/2000\n",
      "3/3 - 0s - loss: 8.0739e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1528/2000\n",
      "3/3 - 0s - loss: 1.1441e-06 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1529/2000\n",
      "3/3 - 0s - loss: 6.2062e-07 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 1530/2000\n",
      "3/3 - 0s - loss: 1.0890e-06 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 1.0000\n",
      "Epoch 1531/2000\n",
      "3/3 - 0s - loss: 7.5033e-07 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 1532/2000\n",
      "3/3 - 0s - loss: 8.9065e-07 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 1.0000\n",
      "Epoch 1533/2000\n",
      "3/3 - 0s - loss: 1.2280e-06 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1534/2000\n",
      "3/3 - 0s - loss: 8.3729e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 1535/2000\n",
      "3/3 - 0s - loss: 7.0164e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1536/2000\n",
      "3/3 - 0s - loss: 7.5485e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1537/2000\n",
      "3/3 - 0s - loss: 9.6561e-07 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
      "Epoch 1538/2000\n",
      "3/3 - 0s - loss: 1.2135e-06 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1539/2000\n",
      "3/3 - 0s - loss: 6.0546e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1540/2000\n",
      "3/3 - 0s - loss: 8.8705e-07 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 1541/2000\n",
      "3/3 - 0s - loss: 8.0588e-07 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
      "Epoch 1542/2000\n",
      "3/3 - 0s - loss: 6.3376e-07 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
      "Epoch 1543/2000\n",
      "3/3 - 0s - loss: 1.1251e-06 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 1544/2000\n",
      "3/3 - 0s - loss: 8.3952e-07 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 1545/2000\n",
      "3/3 - 0s - loss: 6.4234e-07 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 1546/2000\n",
      "3/3 - 0s - loss: 6.6651e-07 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 1547/2000\n",
      "3/3 - 0s - loss: 7.2406e-07 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 1548/2000\n",
      "3/3 - 0s - loss: 7.4469e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1549/2000\n",
      "3/3 - 0s - loss: 7.2045e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1550/2000\n",
      "3/3 - 0s - loss: 9.0290e-07 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 1.0000\n",
      "Epoch 1551/2000\n",
      "3/3 - 0s - loss: 6.5469e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1552/2000\n",
      "3/3 - 0s - loss: 8.5996e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1553/2000\n",
      "3/3 - 0s - loss: 4.9480e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1554/2000\n",
      "3/3 - 0s - loss: 6.5034e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1555/2000\n",
      "3/3 - 0s - loss: 1.2617e-06 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1556/2000\n",
      "3/3 - 0s - loss: 1.4163e-06 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 1.0000\n",
      "Epoch 1557/2000\n",
      "3/3 - 0s - loss: 8.3182e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1558/2000\n",
      "3/3 - 0s - loss: 8.4656e-07 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 1.0000\n",
      "Epoch 1559/2000\n",
      "3/3 - 0s - loss: 6.0459e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1560/2000\n",
      "3/3 - 0s - loss: 7.4583e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1561/2000\n",
      "3/3 - 0s - loss: 7.0945e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1562/2000\n",
      "3/3 - 0s - loss: 8.2856e-07 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1563/2000\n",
      "3/3 - 0s - loss: 1.0129e-06 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1564/2000\n",
      "3/3 - 0s - loss: 1.1268e-06 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1565/2000\n",
      "3/3 - 0s - loss: 1.5017e-06 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 1566/2000\n",
      "3/3 - 0s - loss: 9.9428e-07 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 1.0000\n",
      "Epoch 1567/2000\n",
      "3/3 - 0s - loss: 6.5277e-07 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 1.0000\n",
      "Epoch 1568/2000\n",
      "3/3 - 0s - loss: 1.1576e-06 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 1.0000\n",
      "Epoch 1569/2000\n",
      "3/3 - 0s - loss: 7.5876e-07 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 1.0000\n",
      "Epoch 1570/2000\n",
      "3/3 - 0s - loss: 1.2538e-06 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 1571/2000\n",
      "3/3 - 0s - loss: 7.5954e-07 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 1572/2000\n",
      "3/3 - 0s - loss: 7.9823e-07 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 1573/2000\n",
      "3/3 - 0s - loss: 8.3306e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 1574/2000\n",
      "3/3 - 0s - loss: 8.1237e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 1575/2000\n",
      "3/3 - 0s - loss: 8.1977e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 1576/2000\n",
      "3/3 - 0s - loss: 7.9580e-07 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 1577/2000\n",
      "3/3 - 0s - loss: 5.5838e-07 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 1578/2000\n",
      "3/3 - 0s - loss: 8.3027e-07 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 1579/2000\n",
      "3/3 - 0s - loss: 7.6630e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1580/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 7.3915e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1581/2000\n",
      "3/3 - 0s - loss: 8.2125e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1582/2000\n",
      "3/3 - 0s - loss: 6.3390e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1583/2000\n",
      "3/3 - 0s - loss: 6.4697e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1584/2000\n",
      "3/3 - 0s - loss: 9.1987e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1585/2000\n",
      "3/3 - 0s - loss: 6.6497e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1586/2000\n",
      "3/3 - 0s - loss: 6.3753e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1587/2000\n",
      "3/3 - 0s - loss: 6.3975e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1588/2000\n",
      "3/3 - 0s - loss: 1.0388e-06 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1589/2000\n",
      "3/3 - 0s - loss: 1.0751e-06 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1590/2000\n",
      "3/3 - 0s - loss: 1.0643e-06 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1591/2000\n",
      "3/3 - 0s - loss: 7.8733e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1592/2000\n",
      "3/3 - 0s - loss: 6.2086e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1593/2000\n",
      "3/3 - 0s - loss: 6.3685e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1594/2000\n",
      "3/3 - 0s - loss: 8.6819e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1595/2000\n",
      "3/3 - 0s - loss: 8.3907e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1596/2000\n",
      "3/3 - 0s - loss: 5.1589e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1597/2000\n",
      "3/3 - 0s - loss: 5.8117e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1598/2000\n",
      "3/3 - 0s - loss: 7.9702e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1599/2000\n",
      "3/3 - 0s - loss: 7.3180e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1600/2000\n",
      "3/3 - 0s - loss: 5.7125e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1601/2000\n",
      "3/3 - 0s - loss: 9.8998e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1602/2000\n",
      "3/3 - 0s - loss: 6.9700e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1603/2000\n",
      "3/3 - 0s - loss: 7.2547e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1604/2000\n",
      "3/3 - 0s - loss: 6.2206e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1605/2000\n",
      "3/3 - 0s - loss: 1.0798e-06 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1606/2000\n",
      "3/3 - 0s - loss: 7.6368e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1607/2000\n",
      "3/3 - 0s - loss: 5.0772e-07 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1608/2000\n",
      "3/3 - 0s - loss: 1.0301e-06 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
      "Epoch 1609/2000\n",
      "3/3 - 0s - loss: 4.6224e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1610/2000\n",
      "3/3 - 0s - loss: 8.7882e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1611/2000\n",
      "3/3 - 0s - loss: 1.1089e-06 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1612/2000\n",
      "3/3 - 0s - loss: 6.6338e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1613/2000\n",
      "3/3 - 0s - loss: 5.8988e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1614/2000\n",
      "3/3 - 0s - loss: 7.2874e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1615/2000\n",
      "3/3 - 0s - loss: 5.5613e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1616/2000\n",
      "3/3 - 0s - loss: 1.1140e-06 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1617/2000\n",
      "3/3 - 0s - loss: 6.0827e-07 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 1618/2000\n",
      "3/3 - 0s - loss: 7.3064e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1619/2000\n",
      "3/3 - 0s - loss: 6.1782e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 1.0000\n",
      "Epoch 1620/2000\n",
      "3/3 - 0s - loss: 6.1944e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1621/2000\n",
      "3/3 - 0s - loss: 9.1091e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1622/2000\n",
      "3/3 - 0s - loss: 6.4066e-07 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 1623/2000\n",
      "3/3 - 0s - loss: 1.0293e-06 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1624/2000\n",
      "3/3 - 0s - loss: 6.5471e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1625/2000\n",
      "3/3 - 0s - loss: 5.6598e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1626/2000\n",
      "3/3 - 0s - loss: 1.0506e-06 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1627/2000\n",
      "3/3 - 0s - loss: 7.0154e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1628/2000\n",
      "3/3 - 0s - loss: 7.8466e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1629/2000\n",
      "3/3 - 0s - loss: 5.8210e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1630/2000\n",
      "3/3 - 0s - loss: 7.8220e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1631/2000\n",
      "3/3 - 0s - loss: 1.3960e-06 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1632/2000\n",
      "3/3 - 0s - loss: 6.2228e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1633/2000\n",
      "3/3 - 0s - loss: 5.6590e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1634/2000\n",
      "3/3 - 0s - loss: 5.6204e-07 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
      "Epoch 1635/2000\n",
      "3/3 - 0s - loss: 8.1556e-07 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 1636/2000\n",
      "3/3 - 0s - loss: 5.2849e-07 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 1637/2000\n",
      "3/3 - 0s - loss: 5.7078e-07 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 1638/2000\n",
      "3/3 - 0s - loss: 7.6061e-07 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 1639/2000\n",
      "3/3 - 0s - loss: 8.2666e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1640/2000\n",
      "3/3 - 0s - loss: 6.3805e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1641/2000\n",
      "3/3 - 0s - loss: 1.0678e-06 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 1642/2000\n",
      "3/3 - 0s - loss: 1.2480e-06 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 1643/2000\n",
      "3/3 - 0s - loss: 6.0438e-07 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
      "Epoch 1644/2000\n",
      "3/3 - 0s - loss: 4.2538e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1645/2000\n",
      "3/3 - 0s - loss: 7.4814e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1646/2000\n",
      "3/3 - 0s - loss: 9.0975e-07 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 1647/2000\n",
      "3/3 - 0s - loss: 6.5040e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1648/2000\n",
      "3/3 - 0s - loss: 4.4409e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1649/2000\n",
      "3/3 - 0s - loss: 6.7192e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1650/2000\n",
      "3/3 - 0s - loss: 5.0997e-07 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 1651/2000\n",
      "3/3 - 0s - loss: 8.1557e-07 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
      "Epoch 1652/2000\n",
      "3/3 - 0s - loss: 9.1070e-07 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 1.0000\n",
      "Epoch 1653/2000\n",
      "3/3 - 0s - loss: 8.4355e-07 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 1654/2000\n",
      "3/3 - 0s - loss: 7.3012e-07 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 1655/2000\n",
      "3/3 - 0s - loss: 6.2152e-07 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 1656/2000\n",
      "3/3 - 0s - loss: 5.9021e-07 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 1.0000\n",
      "Epoch 1657/2000\n",
      "3/3 - 0s - loss: 6.4312e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1658/2000\n",
      "3/3 - 0s - loss: 1.0702e-06 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1659/2000\n",
      "3/3 - 0s - loss: 7.3704e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1660/2000\n",
      "3/3 - 0s - loss: 6.7829e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1661/2000\n",
      "3/3 - 0s - loss: 5.4496e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1662/2000\n",
      "3/3 - 0s - loss: 7.0771e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1663/2000\n",
      "3/3 - 0s - loss: 1.0675e-06 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 1.0000\n",
      "Epoch 1664/2000\n",
      "3/3 - 0s - loss: 1.0299e-06 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1665/2000\n",
      "3/3 - 0s - loss: 5.9366e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1666/2000\n",
      "3/3 - 0s - loss: 6.3338e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1667/2000\n",
      "3/3 - 0s - loss: 9.4262e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1668/2000\n",
      "3/3 - 0s - loss: 8.9853e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1669/2000\n",
      "3/3 - 0s - loss: 7.1356e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1670/2000\n",
      "3/3 - 0s - loss: 6.6485e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1671/2000\n",
      "3/3 - 0s - loss: 1.0228e-06 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1672/2000\n",
      "3/3 - 0s - loss: 5.2560e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1673/2000\n",
      "3/3 - 0s - loss: 7.4530e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1674/2000\n",
      "3/3 - 0s - loss: 6.0802e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1675/2000\n",
      "3/3 - 0s - loss: 6.2705e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1676/2000\n",
      "3/3 - 0s - loss: 9.8801e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1677/2000\n",
      "3/3 - 0s - loss: 5.5230e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1678/2000\n",
      "3/3 - 0s - loss: 7.1469e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1679/2000\n",
      "3/3 - 0s - loss: 5.1925e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1680/2000\n",
      "3/3 - 0s - loss: 5.5309e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1681/2000\n",
      "3/3 - 0s - loss: 5.9269e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1682/2000\n",
      "3/3 - 0s - loss: 9.7907e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1683/2000\n",
      "3/3 - 0s - loss: 6.3295e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1684/2000\n",
      "3/3 - 0s - loss: 5.7581e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1685/2000\n",
      "3/3 - 0s - loss: 8.0700e-07 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 1.0000\n",
      "Epoch 1686/2000\n",
      "3/3 - 0s - loss: 5.4689e-07 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 1.0000\n",
      "Epoch 1687/2000\n",
      "3/3 - 0s - loss: 5.7989e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1688/2000\n",
      "3/3 - 0s - loss: 5.4878e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1689/2000\n",
      "3/3 - 0s - loss: 5.0067e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1690/2000\n",
      "3/3 - 0s - loss: 6.3434e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1691/2000\n",
      "3/3 - 0s - loss: 7.4427e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1692/2000\n",
      "3/3 - 0s - loss: 5.8439e-07 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 1693/2000\n",
      "3/3 - 0s - loss: 7.4260e-07 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 1.0000\n",
      "Epoch 1694/2000\n",
      "3/3 - 0s - loss: 6.5304e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1695/2000\n",
      "3/3 - 0s - loss: 6.9475e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1696/2000\n",
      "3/3 - 0s - loss: 4.7164e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1697/2000\n",
      "3/3 - 0s - loss: 1.3630e-06 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1698/2000\n",
      "3/3 - 0s - loss: 6.6399e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1699/2000\n",
      "3/3 - 0s - loss: 5.3447e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 1700/2000\n",
      "3/3 - 0s - loss: 1.2061e-06 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 1701/2000\n",
      "3/3 - 0s - loss: 5.7174e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 1702/2000\n",
      "3/3 - 0s - loss: 8.0026e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 1703/2000\n",
      "3/3 - 0s - loss: 5.2641e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 1704/2000\n",
      "3/3 - 0s - loss: 6.4070e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 1705/2000\n",
      "3/3 - 0s - loss: 5.0807e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1706/2000\n",
      "3/3 - 0s - loss: 4.7711e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1707/2000\n",
      "3/3 - 0s - loss: 7.8059e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1708/2000\n",
      "3/3 - 0s - loss: 5.8342e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1709/2000\n",
      "3/3 - 0s - loss: 6.2090e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1710/2000\n",
      "3/3 - 0s - loss: 4.0527e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1711/2000\n",
      "3/3 - 0s - loss: 1.4115e-06 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1712/2000\n",
      "3/3 - 0s - loss: 1.0086e-06 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1713/2000\n",
      "3/3 - 0s - loss: 6.1973e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1714/2000\n",
      "3/3 - 0s - loss: 6.4653e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1715/2000\n",
      "3/3 - 0s - loss: 5.2635e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1716/2000\n",
      "3/3 - 0s - loss: 6.4693e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1717/2000\n",
      "3/3 - 0s - loss: 8.7903e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1718/2000\n",
      "3/3 - 0s - loss: 8.8427e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1719/2000\n",
      "3/3 - 0s - loss: 5.1862e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1720/2000\n",
      "3/3 - 0s - loss: 7.1638e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1721/2000\n",
      "3/3 - 0s - loss: 6.6428e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1722/2000\n",
      "3/3 - 0s - loss: 5.9582e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1723/2000\n",
      "3/3 - 0s - loss: 5.1082e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1724/2000\n",
      "3/3 - 0s - loss: 1.1189e-06 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1725/2000\n",
      "3/3 - 0s - loss: 8.5465e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1726/2000\n",
      "3/3 - 0s - loss: 7.8182e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1727/2000\n",
      "3/3 - 0s - loss: 4.5047e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1728/2000\n",
      "3/3 - 0s - loss: 9.0087e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1729/2000\n",
      "3/3 - 0s - loss: 7.6137e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1730/2000\n",
      "3/3 - 0s - loss: 8.9567e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1731/2000\n",
      "3/3 - 0s - loss: 6.0154e-07 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 1.0000\n",
      "Epoch 1732/2000\n",
      "3/3 - 0s - loss: 6.8366e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1733/2000\n",
      "3/3 - 0s - loss: 5.1451e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1734/2000\n",
      "3/3 - 0s - loss: 6.1821e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1735/2000\n",
      "3/3 - 0s - loss: 5.2134e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1736/2000\n",
      "3/3 - 0s - loss: 5.6329e-07 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 1.0000\n",
      "Epoch 1737/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 5.4285e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1738/2000\n",
      "3/3 - 0s - loss: 5.6096e-07 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 1739/2000\n",
      "3/3 - 0s - loss: 4.3386e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1740/2000\n",
      "3/3 - 0s - loss: 4.6432e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1741/2000\n",
      "3/3 - 0s - loss: 6.1372e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1742/2000\n",
      "3/3 - 0s - loss: 8.8342e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1743/2000\n",
      "3/3 - 0s - loss: 5.1594e-07 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 1.0000\n",
      "Epoch 1744/2000\n",
      "3/3 - 0s - loss: 4.7561e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1745/2000\n",
      "3/3 - 0s - loss: 4.6968e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1746/2000\n",
      "3/3 - 0s - loss: 6.1839e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 1747/2000\n",
      "3/3 - 0s - loss: 5.3116e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1748/2000\n",
      "3/3 - 0s - loss: 5.8855e-07 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 1749/2000\n",
      "3/3 - 0s - loss: 6.9611e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000\n",
      "Epoch 01749: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1622fa90550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val) , epochs=2000, verbose=2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT THE LOSS\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y\n",
       "0   0\n",
       "1   0\n",
       "2   0\n",
       "3   0\n",
       "4   0\n",
       ".. ..\n",
       "87  1\n",
       "88  1\n",
       "89  1\n",
       "90  1\n",
       "91  1\n",
       "\n",
       "[92 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11900</th>\n",
       "      <th>11901</th>\n",
       "      <th>11902</th>\n",
       "      <th>11903</th>\n",
       "      <th>11904</th>\n",
       "      <th>11905</th>\n",
       "      <th>11906</th>\n",
       "      <th>11907</th>\n",
       "      <th>11908</th>\n",
       "      <th>11909</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277869</td>\n",
       "      <td>0.449457</td>\n",
       "      <td>0.137051</td>\n",
       "      <td>0.440261</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.843814</td>\n",
       "      <td>0.230333</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.279765</td>\n",
       "      <td>0.798625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360045</td>\n",
       "      <td>0.621725</td>\n",
       "      <td>0.042848</td>\n",
       "      <td>0.878256</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.922477</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>0.347492</td>\n",
       "      <td>0.686912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056428</td>\n",
       "      <td>0.614952</td>\n",
       "      <td>0.057026</td>\n",
       "      <td>0.801898</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.839931</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>0.061254</td>\n",
       "      <td>0.320525</td>\n",
       "      <td>0.700434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.366530</td>\n",
       "      <td>0.630288</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.879978</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.854507</td>\n",
       "      <td>0.137686</td>\n",
       "      <td>0.020407</td>\n",
       "      <td>0.281635</td>\n",
       "      <td>0.785794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380458</td>\n",
       "      <td>0.714888</td>\n",
       "      <td>0.060176</td>\n",
       "      <td>0.928718</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.856379</td>\n",
       "      <td>0.038227</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.759671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.352710</td>\n",
       "      <td>0.604601</td>\n",
       "      <td>0.033396</td>\n",
       "      <td>0.886566</td>\n",
       "      <td>0.630333</td>\n",
       "      <td>0.868703</td>\n",
       "      <td>0.045147</td>\n",
       "      <td>0.037593</td>\n",
       "      <td>0.296312</td>\n",
       "      <td>0.729745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.362058</td>\n",
       "      <td>0.704665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912492</td>\n",
       "      <td>0.166901</td>\n",
       "      <td>0.846751</td>\n",
       "      <td>0.202632</td>\n",
       "      <td>0.025811</td>\n",
       "      <td>0.272208</td>\n",
       "      <td>0.917137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.389239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.895540</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.846816</td>\n",
       "      <td>0.329738</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.271828</td>\n",
       "      <td>0.927855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.649329</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>0.964646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849188</td>\n",
       "      <td>0.098639</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.885905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.373879</td>\n",
       "      <td>0.710415</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.923460</td>\n",
       "      <td>0.223394</td>\n",
       "      <td>0.852015</td>\n",
       "      <td>0.127085</td>\n",
       "      <td>0.031815</td>\n",
       "      <td>0.283890</td>\n",
       "      <td>0.764243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 11910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6      \\\n",
       "0   0.277869  0.449457  0.137051  0.440261  0.147211  0.843814  0.230333   \n",
       "1   0.360045  0.621725  0.042848  0.878256  0.147211  0.922477  0.050804   \n",
       "2   0.056428  0.614952  0.057026  0.801898  0.147211  0.839931  0.055694   \n",
       "3   0.366530  0.630288  0.005671  0.879978  0.147211  0.854507  0.137686   \n",
       "4   0.380458  0.714888  0.060176  0.928718  0.147211  0.856379  0.038227   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "87  0.352710  0.604601  0.033396  0.886566  0.630333  0.868703  0.045147   \n",
       "88  0.362058  0.704665  0.000000  0.912492  0.166901  0.846751  0.202632   \n",
       "89  0.389239  1.000000  0.000000  0.895540  0.147211  0.846816  0.329738   \n",
       "90  0.357100  0.649329  0.024890  0.964646  1.000000  0.849188  0.098639   \n",
       "91  0.373879  0.710415  0.007246  0.923460  0.223394  0.852015  0.127085   \n",
       "\n",
       "       7         8         9      ...  11900     11901  11902  11903  11904  \\\n",
       "0   0.024652  0.279765  0.798625  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "1   0.042116  0.347492  0.686912  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "2   0.061254  0.320525  0.700434  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "3   0.020407  0.281635  0.785794  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "4   0.016758  0.286458  0.759671  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "..       ...       ...       ...  ...    ...       ...    ...    ...    ...   \n",
       "87  0.037593  0.296312  0.729745  ...    0.0  0.050266    0.0    0.0    0.0   \n",
       "88  0.025811  0.272208  0.917137  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "89  0.016867  0.271828  0.927855  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "90  0.035856  0.273291  0.885905  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "91  0.031815  0.283890  0.764243  ...    0.0  0.000000    0.0    0.0    0.0   \n",
       "\n",
       "    11905  11906  11907  11908  11909  \n",
       "0     0.0    0.0    0.0    0.0    0.0  \n",
       "1     0.0    0.0    0.0    0.0    0.0  \n",
       "2     0.0    0.0    0.0    0.0    0.0  \n",
       "3     0.0    0.0    0.0    0.0    0.0  \n",
       "4     0.0    0.0    0.0    0.0    0.0  \n",
       "..    ...    ...    ...    ...    ...  \n",
       "87    0.0    0.0    0.0    0.0    0.0  \n",
       "88    0.0    0.0    0.0    0.0    0.0  \n",
       "89    0.0    0.0    0.0    0.0    0.0  \n",
       "90    0.0    0.0    0.0    0.0    0.0  \n",
       "91    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[92 rows x 11910 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = []\n",
    "for predictions in model.predict(X_train):\n",
    "    if predictions < 0.5:\n",
    "        predictions = 0\n",
    "    else:\n",
    "        predictions=1\n",
    "    y_train_pred.append(predictions)\n",
    "\n",
    "\n",
    "print('training accuracy:', accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64        12\n",
      "           1       0.67      0.62      0.64        13\n",
      "\n",
      "    accuracy                           0.64        25\n",
      "   macro avg       0.64      0.64      0.64        25\n",
      "weighted avg       0.64      0.64      0.64        25\n",
      "\n",
      "\n",
      " CONFUSION MATRIX:\n",
      " [[8 4]\n",
      " [5 8]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.64\n"
     ]
    }
   ],
   "source": [
    "# PERFORMANCE EVALUATION\n",
    "\n",
    "pred_NN = []\n",
    "\n",
    "for predictions in model.predict(X_test):\n",
    "    if predictions < 0.5:\n",
    "        predictions = 0\n",
    "    else:\n",
    "        predictions=1\n",
    "    pred_NN.append(predictions)\n",
    "    \n",
    "pred = np.array(pred_NN)\n",
    "true = np.array(y_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(true, pred))\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print Area Under Curve\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "\n",
    "false_positive_rate, recall, thresholds = roc_curve(true, pred)\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.figure()\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out (1-Specificity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[ 1 11]\n",
      " [ 0 13]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.56 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Naive Bayes)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "pred_naive = nb.predict(X_test)\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_naive))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_naive), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[10  2]\n",
      " [ 7  6]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Classifier (SVM)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_model.predict(np.array(X_test))\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_svm))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[10  2]\n",
      " [ 7  6]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Logistic Regression)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "pred_log = logmodel.predict(X_test)\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_log))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[7 5]\n",
      " [6 7]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Decision Tree)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "pred_tree = dtree.predict(X_test)\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_tree))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-54-923bb84feeda>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[ 9  3]\n",
      " [ 2 11]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " train ACCURACY SCORE IS: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Random Forest)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_rfc))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_rfc))\n",
    "print('\\n\\n train ACCURACY SCORE IS:', accuracy_score(y_train, rfc.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-46-96f270b3aec5>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[ 9  3]\n",
      " [ 3 10]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Classifier(K-Nearest Neighbors)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "pred_knn = knn.predict(X_test)\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_knn))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-47-ed6a212028b3>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# FIND BEST VALUE OF K\n",
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    pred_i = pred_i.reshape(25,1)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "<ipython-input-49-33c9dcae127b>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,y_train)\n",
      "C:\\Users\\onjad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:509: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[11  1]\n",
      " [ 4  9]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.8\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=18)\n",
    "knn.fit(X_train,y_train)\n",
    "pred_knn = knn.predict(X_test)\n",
    "\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_knn))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY SCORE OF EACH CLASSIFIER:\n",
      "\n",
      "NEURAL NETWORK: 0.64\n",
      "RANDOM FOREST: 0.84\n",
      "DECISION TREE: 0.56\n",
      "SVM: 0.64\n",
      "K NEAREST NEIGHBORS: 0.8\n",
      "LOGISTIC REGRESSION: 0.64\n",
      "NAIVE BAYES: 0.56\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY SCORE OF EACH CLASSIFIER:\\n')\n",
    "print('NEURAL NETWORK:', accuracy_score(true, pred))\n",
    "print('RANDOM FOREST:', accuracy_score(true, pred_rfc))\n",
    "print('DECISION TREE:', accuracy_score(true, pred_tree))\n",
    "print('SVM:', accuracy_score(true, pred_svm))\n",
    "print('K NEAREST NEIGHBORS:', accuracy_score(true, pred_knn))\n",
    "print('LOGISTIC REGRESSION:', accuracy_score(true, pred_log))\n",
    "print('NAIVE BAYES:', accuracy_score(true, pred_naive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
