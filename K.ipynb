{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT TEXT FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET  \n",
    "#Bankrupt_perfo\n",
    "bankrupted_perfo_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/bankrupted/trainB')\n",
    "bankrupted_perfo_reports = [file for file in bankrupted_perfo_reports]\n",
    "\n",
    "bankrupted_perfo_file = []\n",
    "for report in range(0, len(bankrupted_perfo_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/bankrupted/trainB/{bankrupted_perfo_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        perfo_filesB = file.read()\n",
    "        bankrupted_perfo_file.append(perfo_filesB)\n",
    "\n",
    "\n",
    "#Bankrupt_tanshin\n",
    "bankrupted_tanshin_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/bankrupted/trainB')\n",
    "bankrupted_tanshin_reports = [file for file in bankrupted_tanshin_reports]\n",
    "\n",
    "bankrupted_file_tanshin = []\n",
    "for report in range(0, len(bankrupted_tanshin_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/bankrupted/trainB/{bankrupted_tanshin_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        filesB_tanshin = file.read()\n",
    "        bankrupted_file_tanshin.append(filesB_tanshin)\n",
    "\n",
    "df_bankrupted_perfo = pd.DataFrame(bankrupted_perfo_file)\n",
    "df_bankrupted_perfo.columns = ['perfo']\n",
    "df_bankrupted_perfo['Y'] = 0\n",
    "\n",
    "df_bankrupted_tanshin = pd.DataFrame(bankrupted_file_tanshin)\n",
    "df_bankrupted_tanshin.columns = ['tanshin']\n",
    "df_bankrupted_tanshin['Y'] = 0 \n",
    "\n",
    "\n",
    "#Nonbankrupt_perfo\n",
    "nonbankrupted_perfo_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/nonbankrupted/trainNB')\n",
    "nonbankrupted_perfo_reports = [file for file in nonbankrupted_perfo_reports]\n",
    "\n",
    "nonbankrupted_perfo_file = []\n",
    "for report in range(0, len(nonbankrupted_perfo_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/nonbankrupted/trainNB/{nonbankrupted_perfo_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        perfo_filesNB = file.read()\n",
    "        nonbankrupted_perfo_file.append(perfo_filesNB)\n",
    "\n",
    "#Nonbankrupt__tanshin\n",
    "nonbankrupted_tanshin_reports = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/nonbankrupted/trainNB')\n",
    "nonbankrupted_tanshin_reports = [file for file in nonbankrupted_tanshin_reports]\n",
    "\n",
    "nonbankrupted_file_tanshin = []\n",
    "for report in range(0, len(nonbankrupted_tanshin_reports)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/nonbankrupted/trainNB/{nonbankrupted_tanshin_reports[report]}\", encoding=\"utf8\") as file:\n",
    "        filesNB_tanshin = file.read()\n",
    "        nonbankrupted_file_tanshin.append(filesNB_tanshin) \n",
    "\n",
    "df_nonbankrupted_perfo = pd.DataFrame(nonbankrupted_perfo_file)\n",
    "df_nonbankrupted_perfo.columns = ['perfo']\n",
    "df_nonbankrupted_perfo['Y'] = 1\n",
    "\n",
    "df_nonbankrupted_tanshin = pd.DataFrame(nonbankrupted_file_tanshin)\n",
    "df_nonbankrupted_tanshin.columns = ['tanshin']\n",
    "df_nonbankrupted_tanshin['Y'] = 1\n",
    "\n",
    "\n",
    "# concatenated_train\n",
    "df_perfo_train = [df_bankrupted_perfo,df_nonbankrupted_perfo]\n",
    "df_perfo_train = pd.concat(df_perfo_train, ignore_index=True)\n",
    "# print(df_perfo_train)\n",
    "\n",
    "concatenated_tanshin_train = [df_bankrupted_tanshin, df_nonbankrupted_tanshin]\n",
    "df_tanshin_train = pd.concat(concatenated_tanshin_train, ignore_index= True)\n",
    "# print(df_tanshin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION SET     \n",
    "#Bankrupt_perfo\n",
    "bankrupted_perfo_reports_val = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/bankrupted/valB')\n",
    "bankrupted_perfo_reports_val = [file for file in bankrupted_perfo_reports_val]\n",
    "\n",
    "bankrupted_perfo_file_val = []\n",
    "for report in range(0, len(bankrupted_perfo_reports_val)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/bankrupted/valB/{bankrupted_perfo_reports_val[report]}\", encoding=\"utf8\") as file:\n",
    "        perfo_filesB_val = file.read()\n",
    "        bankrupted_perfo_file_val.append(perfo_filesB_val)\n",
    "        \n",
    "#Bankrupt_tanshin\n",
    "bankrupted_tanshin_reports_val = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/bankrupted/valB')\n",
    "bankrupted_tanshin_reports_val = [file for file in bankrupted_tanshin_reports_val]\n",
    "\n",
    "bankrupted_file_tanshin_val = []\n",
    "for report in range(0, len(bankrupted_tanshin_reports_val)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/bankrupted/valB/{bankrupted_tanshin_reports_val[report]}\", encoding=\"utf8\") as file:\n",
    "        filesB_tanshin_val = file.read()\n",
    "        bankrupted_file_tanshin_val.append(filesB_tanshin_val)       \n",
    "\n",
    "df_bankrupted_perfo_val = pd.DataFrame(bankrupted_perfo_file_val)\n",
    "df_bankrupted_perfo_val.columns = ['perfo']\n",
    "df_bankrupted_perfo_val['Y'] = 0\n",
    "\n",
    "df_bankrupted_tanshin_val = pd.DataFrame(bankrupted_file_tanshin_val)\n",
    "df_bankrupted_tanshin_val.columns = ['tanshin']\n",
    "df_bankrupted_tanshin_val['Y'] = 0\n",
    "        \n",
    "#Nonbankrupt_perfo\n",
    "nonbankrupted_perfo_reports_val = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/nonbankrupted/valNB')\n",
    "nonbankrupted_perfo_reports_val = [file for file in nonbankrupted_perfo_reports_val]\n",
    "\n",
    "nonbankrupted_perfo_file_val = []\n",
    "for report in range(0, len(nonbankrupted_perfo_reports_val)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/nonbankrupted/valNB/{nonbankrupted_perfo_reports_val[report]}\", encoding=\"utf8\") as file:\n",
    "        perfo_filesNB_val = file.read()\n",
    "        nonbankrupted_perfo_file_val.append(perfo_filesNB_val)\n",
    "        \n",
    "#Nonbankrupt_tanshin\n",
    "nonbankrupted_tanshin_reports_val = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/nonbankrupted/valNB')\n",
    "nonbankrupted_tanshin_reports_val = [file for file in nonbankrupted_tanshin_reports_val]\n",
    "\n",
    "nonbankrupted_file_tanshin_val = []\n",
    "for report in range(0, len(nonbankrupted_tanshin_reports_val)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/nonbankrupted/valNB/{nonbankrupted_tanshin_reports_val[report]}\", encoding=\"utf8\") as file:\n",
    "        filesNB_tanshin_val = file.read()\n",
    "        nonbankrupted_file_tanshin_val.append(filesNB_tanshin_val)\n",
    "\n",
    "df_nonbankrupted_perfo_val = pd.DataFrame(nonbankrupted_perfo_file_val)\n",
    "df_nonbankrupted_perfo_val.columns = ['perfo']\n",
    "df_nonbankrupted_perfo_val['Y'] = 1\n",
    "\n",
    "df_nonbankrupted_tanshin_val = pd.DataFrame(nonbankrupted_file_tanshin_val)\n",
    "df_nonbankrupted_tanshin_val.columns = ['tanshin']\n",
    "df_nonbankrupted_tanshin_val['Y'] = 1 \n",
    "\n",
    "\n",
    "# concatenated_val\n",
    "df_perfo_val = [df_bankrupted_perfo_val,df_nonbankrupted_perfo_val]\n",
    "df_perfo_val = pd.concat(df_perfo_val, ignore_index=True)\n",
    "# print(df_perfo_val)\n",
    "\n",
    "concatenated_tanshin_val = [df_bankrupted_tanshin_val, df_nonbankrupted_tanshin_val]\n",
    "df_tanshin_val = pd.concat(concatenated_tanshin_val, ignore_index=True)\n",
    "# print(df_tanshin_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "#Bankrupt_perfo(test data)\n",
    "bankrupted_perfo_reports_test = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/bankrupted/testB')\n",
    "bankrupted_perfo_reports_test = [file for file in bankrupted_perfo_reports_test]\n",
    "\n",
    "bankrupted_perfo_file_test = []\n",
    "for report in range(0, len(bankrupted_perfo_reports_test)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/bankrupted/testB/{bankrupted_perfo_reports_test[report]}\", encoding=\"utf8\") as file:\n",
    "        perfo_filesB_test = file.read()\n",
    "        bankrupted_perfo_file_test.append(perfo_filesB_test)      \n",
    "\n",
    "#Bankrupt_tanshin(test data)\n",
    "bankrupted_tanshin_reports_test = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/bankrupted/testB')\n",
    "bankrupted_tanshin_reports_test = [file for file in bankrupted_tanshin_reports_test]\n",
    "\n",
    "bankrupted_tanshin_file_test = []\n",
    "for report in range(0, len(bankrupted_tanshin_reports_test)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/bankrupted/testB/{bankrupted_tanshin_reports_test[report]}\", encoding=\"utf8\") as file:\n",
    "        tanshin_filesB_test = file.read()\n",
    "        bankrupted_tanshin_file_test.append(tanshin_filesB_test)\n",
    "\n",
    "df_bankrupted_perfo_test = pd.DataFrame(bankrupted_perfo_file_test)\n",
    "df_bankrupted_perfo_test.columns = ['perfo']\n",
    "df_bankrupted_perfo_test['Y'] = 0\n",
    "\n",
    "df_bankrupted_tanshin_test = pd.DataFrame(bankrupted_tanshin_file_test)\n",
    "df_bankrupted_tanshin_test.columns = ['tanshin']\n",
    "df_bankrupted_tanshin_test['Y'] = 0\n",
    "        \n",
    "#Nonbankrupt_perfo(test data)\n",
    "nonbankrupted_perfo_reports_test = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/nonbankrupted/testNB')\n",
    "nonbankrupted_perfo_reports_test = [file for file in nonbankrupted_perfo_reports_test]\n",
    "\n",
    "nonbankrupted_perfo_file_test = []\n",
    "for report in range(0, len(nonbankrupted_perfo_reports_test)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/performance/nonbankrupted/testNB/{nonbankrupted_perfo_reports_test[report]}\", encoding=\"utf8\") as file:\n",
    "        perfo_filesNB_test = file.read()\n",
    "        nonbankrupted_perfo_file_test.append(perfo_filesNB_test)      \n",
    "        \n",
    "#Nonbankrupt_tanshin(test data)\n",
    "nonbankrupted_tanshin_reports_test = os.listdir('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/nonbankrupted/testNB')\n",
    "nonbankrupted_tanshin_reports_test = [file for file in nonbankrupted_tanshin_reports_test]\n",
    "\n",
    "nonbankrupted_tanshin_file_test = []\n",
    "for report in range(0, len(nonbankrupted_tanshin_reports_test)):\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/tanshin/nonbankrupted/testNB/{nonbankrupted_tanshin_reports_test[report]}\", encoding=\"utf8\") as file:\n",
    "        tanshin_filesNB_test = file.read()\n",
    "        nonbankrupted_tanshin_file_test.append(tanshin_filesNB_test)\n",
    "\n",
    "df_nonbankrupted_perfo_test = pd.DataFrame(nonbankrupted_perfo_file_test)\n",
    "df_nonbankrupted_perfo_test.columns = ['perfo']\n",
    "df_nonbankrupted_perfo_test['Y'] = 1\n",
    "\n",
    "df_nonbankrupted_tanshin_test = pd.DataFrame(nonbankrupted_tanshin_file_test)\n",
    "df_nonbankrupted_tanshin_test.columns = ['tanshin']\n",
    "df_nonbankrupted_tanshin_test['Y'] = 1\n",
    "\n",
    "# concatenated_test\n",
    "df_perfo_test = [df_bankrupted_perfo_test,df_nonbankrupted_perfo_test]\n",
    "df_perfo_test = pd.concat(df_perfo_test, ignore_index=True)\n",
    "# print(df_perfo_test)\n",
    "\n",
    "df_tanshin_test = [df_bankrupted_tanshin_test,df_nonbankrupted_tanshin_test]\n",
    "df_tanshin_test = pd.concat(df_tanshin_test, ignore_index=True)\n",
    "# print(df_tanshin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT RATIO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET\n",
    "\n",
    "traindata = pd.read_csv('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/ratios/train_ratio.csv')\n",
    "# print('TRAINING DATASET \\n:', traindata.describe().transpose())\n",
    "X_train_ratio = traindata.drop('Y', axis=1)\n",
    "y_train_ratio = traindata['Y']\n",
    "# print(sns.countplot(x = 'Y', data=traindata))\n",
    "\n",
    "# VALIDATION SET\n",
    "\n",
    "valdata = pd.read_csv('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/ratios/val_ratio.csv')\n",
    "# print('VALIDATION DATASET \\n:', valdata.describe().transpose())\n",
    "X_val_ratio = valdata.drop('Y', axis=1)\n",
    "y_val_ratio = valdata['Y']\n",
    "\n",
    "# TEST SET\n",
    "\n",
    "testdata = pd.read_csv('C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/DATAFRAMES/ratios/test_ratio.csv')\n",
    "# print('TEST DATASET \\n:', testdata.describe().transpose())\n",
    "# print('TEST DATASET \\n:', testdata)\n",
    "X_test_ratio = testdata.drop('Y', axis=1)\n",
    "y_test_ratio = testdata['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINE BOTH RATIOS + TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD THE A NEW COLUMN FOR TEXT FILE\n",
    "\n",
    "X_train_ratio['perfo'] = df_perfo_train['perfo']\n",
    "X_train_ratio['tanshin'] = df_tanshin_train['tanshin']\n",
    "\n",
    "X_val_ratio['perfo'] = df_perfo_val['perfo']\n",
    "X_val_ratio['tanshin'] = df_tanshin_val['tanshin']\n",
    "\n",
    "X_test_ratio['perfo'] = df_perfo_test.drop('Y', axis=1)\n",
    "X_test_ratio['tanshin'] = df_tanshin_test.drop('Y', axis=1)\n",
    "\n",
    "# CREATE NEW DATAFRAME FOR COMBINED DATA\n",
    "\n",
    "X_train_both = X_train_ratio\n",
    "X_val_both = X_val_ratio\n",
    "X_test_both = X_test_ratio\n",
    "\n",
    "y_train_both = y_train_ratio\n",
    "y_val_both = y_val_ratio\n",
    "y_test_both = y_test_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X (train): 92 | Length of Y (train): 92\n",
      "Length of X (validation): 20 | Length of Y (validation): 20\n",
      "Length of X (test): 25 | Length of Y (test): 25\n"
     ]
    }
   ],
   "source": [
    "print('Length of X (train): {} | Length of Y (train): {}'.format(len(X_train_both), len(y_train_both)))\n",
    "print('Length of X (validation): {} | Length of Y (validation): {}'.format(len(X_val_both), len(y_val_both)))\n",
    "print('Length of X (test): {} | Length of Y (test): {}'.format(len(X_test_both), len(y_test_both)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test_both)\n",
    "# print(X_train_both['perfo'])\n",
    "# print(X_train_both['tanshin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.charfilter import *\n",
    "from janome.tokenfilter import *\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(risk_report_test):\n",
    "    \"\"\"Returns cleaned text data.\"\"\"\n",
    "    \n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/stop_words.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        stop_words = file.read()\n",
    "    \n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/stop_words_accounting.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        stop_words_acc = file.read()\n",
    "\n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/onaji_performance_vocab.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        onaji_performance_vocab = file.read()\n",
    "    \n",
    "    with open(f\"C:/Users/onjad/OneDrive/Documents/RESEARCH PHD/article 3/CODES/onaji_tanshin_vocab.txt\", mode=\"r\", encoding=\"utf8\") as file:\n",
    "        onaji_tanshin_vocab = file.read()  \n",
    "    \n",
    "    char_filters = [UnicodeNormalizeCharFilter(), \n",
    "                    RegexReplaceCharFilter(u'キャッシュ・フロー', u'キャッシュフロー')]\n",
    "    tokenizer = Tokenizer()\n",
    "    token_filters = [CompoundNounFilter(), \n",
    "                     POSStopFilter(['記号','助詞', '数', '数接続', '接続詞','連体詞', '接頭詞', '名詞,数','非自立', '代名詞', '自動詞', '他動詞']), \n",
    "                     LowerCaseFilter()]\n",
    "\n",
    "\n",
    "    a = Analyzer(char_filters=char_filters, tokenizer=tokenizer, token_filters=token_filters)\n",
    "    \n",
    "    def filter(text):\n",
    "        \"\"\"\n",
    "        :param text: str\n",
    "        :rtype : str\n",
    "        \"\"\"\n",
    "       # アルファベットと半角英数と記号と改行とタブを排除\n",
    "        text = re.sub(r'[a-zA-Z0-9¥\"¥.¥,¥@]+', '', text)\n",
    "        text = re.sub(r'[!\"“#$%&()\\*\\+\\-\\.,\\/:;<=>?@\\[\\\\\\]^_`{|}~]', '', text)\n",
    "        text = re.sub(r'[\\n|\\r|\\t]', '', text)\n",
    "        \n",
    "        # 日本語以外の文字を排除\n",
    "        jp_chartype_tokenizer = nltk.RegexpTokenizer(u'([ぁ-んー]+|[ァ-ンー]+|[\\u4e00-\\u9FFF]+|[ぁ-んァ-ンー\\u4e00-\\u9FFF]+)')\n",
    "        text = ''.join(jp_chartype_tokenizer.tokenize(text))\n",
    "        \n",
    "        return text\n",
    "\n",
    "    nosymbol_test = filter(risk_report_test)\n",
    "    \n",
    "    doc = []\n",
    "    for token in a.analyze(nosymbol_test):\n",
    "        doc.append(token.surface)\n",
    "    doc = [x for x in doc if x not in stop_words]\n",
    "    doc = [x for x in doc if x not in stop_words_acc]\n",
    "    doc = [x for x in doc if x not in onaji_performance_vocab]\n",
    "    doc = [x for x in doc if x not in onaji_tanshin_vocab]\n",
    "    doc = np.array(doc)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "#     corpus = ' '.join(doc)\n",
    "#     corpus = [corpus]\n",
    "    \n",
    "#     return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_both['texts'] = X_train_both[['perfo','tanshin']] .apply(lambda x: ''.join(x), axis=1)\n",
    "# print(X_train_both['texts'][0])\n",
    "\n",
    "X_val_both['texts'] = X_val_both[['perfo','tanshin']] .apply(lambda x: ''.join(x), axis=1)\n",
    "# print(X_val_both['texts'][0])\n",
    "\n",
    "X_test_both['texts'] = X_test_both[['perfo','tanshin']] .apply(lambda x: ''.join(x), axis=1)\n",
    "# print(X_test_both['texts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_only = pd.concat([X_train_both['texts'], X_val_both['texts'], X_test_both['texts']], ignore_index=True)\n",
    "# print(df_text_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_text_only[91]) #train 0 a 92\n",
    "# print(df_text_only[111]) #val 92 a 112\n",
    "# print(df_text_only[112]) #test 112 a 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_file_transformer = CountVectorizer(analyzer=clean_data).fit(df_text_only)\n",
    "# print(clean_file_transformer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12055\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_file_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (137, 12055)\n"
     ]
    }
   ],
   "source": [
    "clean_file_bow = clean_file_transformer.transform(df_text_only)\n",
    "# print(clean_file_bow)\n",
    "print('Shape of Sparse Matrix: ', clean_file_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 12055)\n"
     ]
    }
   ],
   "source": [
    "transformer_tfidf = TfidfTransformer().fit(clean_file_bow)\n",
    "clean_file_tfidf = transformer_tfidf.transform(clean_file_bow)\n",
    "\n",
    "# print(clean_file_tfidf)\n",
    "print(clean_file_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ratio = X_train_ratio.drop('perfo', axis=1)\n",
    "X_train_ratio = X_train_ratio.drop('tanshin', axis=1)\n",
    "# X_train_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_ratio = X_val_ratio.drop('perfo', axis=1)\n",
    "X_val_ratio = X_val_ratio.drop('tanshin', axis=1)\n",
    "# print(X_val_ratio)\n",
    "\n",
    "X_test_ratio = X_test_ratio.drop('perfo', axis=1)\n",
    "X_test_ratio = X_test_ratio.drop('tanshin', axis=1)\n",
    "# print(X_test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_ratio = scaler.fit_transform(X_train_ratio.drop('texts', axis=1))\n",
    "X_val_ratio = scaler.transform(X_val_ratio.drop('texts', axis=1))\n",
    "X_test_ratio = scaler.transform(X_test_ratio.drop('texts', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION TASK - NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 22) (20, 22) (25, 22)\n"
     ]
    }
   ],
   "source": [
    "# RATIOS\n",
    "Xtrain_ratio = pd.DataFrame(X_train_ratio)\n",
    "Xval_ratio = pd.DataFrame(X_val_ratio)\n",
    "Xtest_ratio = pd.DataFrame(X_test_ratio)\n",
    "\n",
    "# rename columns\n",
    "Xtrain_ratio.columns = ['X19','X20','X29','X47', 'X51', 'X54', 'X59', 'X62','X63','X64','X67', 'X69', 'X70', 'X71','X72', 'X73', 'X74', 'X76','X77', 'X79', 'X80', 'X84']\n",
    "Xval_ratio.columns = ['X19','X20','X29','X47', 'X51', 'X54', 'X59', 'X62','X63','X64','X67', 'X69', 'X70', 'X71','X72', 'X73', 'X74', 'X76','X77', 'X79', 'X80', 'X84']\n",
    "Xtest_ratio.columns = ['X19','X20','X29','X47', 'X51', 'X54', 'X59', 'X62','X63','X64','X67', 'X69', 'X70', 'X71','X72', 'X73', 'X74', 'X76','X77', 'X79', 'X80', 'X84']\n",
    "\n",
    "print(Xtrain_ratio.shape, Xval_ratio.shape, Xtest_ratio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtest_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT\n",
    "X = clean_file_tfidf\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "X_train_text = X[:92]\n",
    "X_val_text = pd.DataFrame(X[92:112])\n",
    "X_test_text = pd.DataFrame(X[112:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_text.index.delete\n",
    "X_val_text = X_val_text.reset_index(drop=True)\n",
    "# X_val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text.index.delete\n",
    "X_test_text = X_test_text.reset_index(drop=True)\n",
    "# X_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 12055) (20, 12055) (25, 12055)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_text.shape, X_val_text.shape, X_test_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 12077) (20, 12077) (25, 12077)\n"
     ]
    }
   ],
   "source": [
    "# INPUT VALUES X\n",
    "\n",
    "X_train = pd.concat([Xtrain_ratio, X_train_text], ignore_index=True, axis=1)\n",
    "X_val = pd.concat([Xval_ratio, X_val_text], ignore_index=True, axis=1)\n",
    "X_test = pd.concat([Xtest_ratio, X_test_text], ignore_index=True, axis=1)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 1) (20, 1) (25, 1)\n"
     ]
    }
   ],
   "source": [
    "# TARGET VALUE Y\n",
    "\n",
    "y_train = pd.DataFrame(y_train_ratio)\n",
    "y_val = pd.DataFrame(y_val_ratio)\n",
    "y_test = pd.DataFrame(y_test_ratio)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               6039000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 6,290,001\n",
      "Trainable params: 6,290,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=500, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dropout(0.8),\n",
    "    Dense(units=500, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.02)),\n",
    "    Dropout(0.8),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 20 samples\n",
      "Epoch 1/1000\n",
      "92/92 - 1s - loss: 12.8107 - acc: 0.4674 - val_loss: 12.0549 - val_acc: 0.6000\n",
      "Epoch 2/1000\n",
      "92/92 - 0s - loss: 11.7200 - acc: 0.5326 - val_loss: 11.0226 - val_acc: 0.6500\n",
      "Epoch 3/1000\n",
      "92/92 - 0s - loss: 10.7047 - acc: 0.5326 - val_loss: 10.0744 - val_acc: 0.6000\n",
      "Epoch 4/1000\n",
      "92/92 - 0s - loss: 9.7904 - acc: 0.5326 - val_loss: 9.2069 - val_acc: 0.5000\n",
      "Epoch 5/1000\n",
      "92/92 - 0s - loss: 8.9367 - acc: 0.6087 - val_loss: 8.4156 - val_acc: 0.5000\n",
      "Epoch 6/1000\n",
      "92/92 - 0s - loss: 8.1516 - acc: 0.6196 - val_loss: 7.6954 - val_acc: 0.5000\n",
      "Epoch 7/1000\n",
      "92/92 - 0s - loss: 7.4670 - acc: 0.6087 - val_loss: 7.0414 - val_acc: 0.5000\n",
      "Epoch 8/1000\n",
      "92/92 - 0s - loss: 6.8240 - acc: 0.6196 - val_loss: 6.4485 - val_acc: 0.5000\n",
      "Epoch 9/1000\n",
      "92/92 - 0s - loss: 6.2166 - acc: 0.7500 - val_loss: 5.9116 - val_acc: 0.5000\n",
      "Epoch 10/1000\n",
      "92/92 - 0s - loss: 5.6816 - acc: 0.7609 - val_loss: 5.4259 - val_acc: 0.5000\n",
      "Epoch 11/1000\n",
      "92/92 - 0s - loss: 5.2100 - acc: 0.7935 - val_loss: 4.9871 - val_acc: 0.5000\n",
      "Epoch 12/1000\n",
      "92/92 - 0s - loss: 4.7600 - acc: 0.8587 - val_loss: 4.5911 - val_acc: 0.5000\n",
      "Epoch 13/1000\n",
      "92/92 - 0s - loss: 4.3600 - acc: 0.8261 - val_loss: 4.2334 - val_acc: 0.5000\n",
      "Epoch 14/1000\n",
      "92/92 - 0s - loss: 3.9971 - acc: 0.8370 - val_loss: 3.9101 - val_acc: 0.6500\n",
      "Epoch 15/1000\n",
      "92/92 - 0s - loss: 3.6503 - acc: 0.9130 - val_loss: 3.6184 - val_acc: 0.7000\n",
      "Epoch 16/1000\n",
      "92/92 - 0s - loss: 3.3369 - acc: 0.9348 - val_loss: 3.3560 - val_acc: 0.7500\n",
      "Epoch 17/1000\n",
      "92/92 - 0s - loss: 3.0020 - acc: 0.9674 - val_loss: 3.1194 - val_acc: 0.7500\n",
      "Epoch 18/1000\n",
      "92/92 - 0s - loss: 2.7600 - acc: 0.9565 - val_loss: 2.9059 - val_acc: 0.7000\n",
      "Epoch 19/1000\n",
      "92/92 - 0s - loss: 2.4750 - acc: 1.0000 - val_loss: 2.7135 - val_acc: 0.7500\n",
      "Epoch 20/1000\n",
      "92/92 - 0s - loss: 2.2674 - acc: 0.9891 - val_loss: 2.5402 - val_acc: 0.7500\n",
      "Epoch 21/1000\n",
      "92/92 - 0s - loss: 2.0577 - acc: 0.9891 - val_loss: 2.3830 - val_acc: 0.7500\n",
      "Epoch 22/1000\n",
      "92/92 - 0s - loss: 1.8538 - acc: 1.0000 - val_loss: 2.2380 - val_acc: 0.6500\n",
      "Epoch 23/1000\n",
      "92/92 - 0s - loss: 1.7108 - acc: 1.0000 - val_loss: 2.1077 - val_acc: 0.7000\n",
      "Epoch 24/1000\n",
      "92/92 - 0s - loss: 1.5716 - acc: 1.0000 - val_loss: 1.9881 - val_acc: 0.6500\n",
      "Epoch 25/1000\n",
      "92/92 - 0s - loss: 1.4245 - acc: 1.0000 - val_loss: 1.8796 - val_acc: 0.6500\n",
      "Epoch 26/1000\n",
      "92/92 - 0s - loss: 1.2799 - acc: 1.0000 - val_loss: 1.7796 - val_acc: 0.7000\n",
      "Epoch 27/1000\n",
      "92/92 - 0s - loss: 1.2056 - acc: 0.9783 - val_loss: 1.6861 - val_acc: 0.6500\n",
      "Epoch 28/1000\n",
      "92/92 - 0s - loss: 1.0777 - acc: 1.0000 - val_loss: 1.6003 - val_acc: 0.6500\n",
      "Epoch 29/1000\n",
      "92/92 - 0s - loss: 1.0049 - acc: 1.0000 - val_loss: 1.5230 - val_acc: 0.7500\n",
      "Epoch 30/1000\n",
      "92/92 - 0s - loss: 0.9041 - acc: 1.0000 - val_loss: 1.4507 - val_acc: 0.7500\n",
      "Epoch 31/1000\n",
      "92/92 - 0s - loss: 0.8306 - acc: 1.0000 - val_loss: 1.3813 - val_acc: 0.7500\n",
      "Epoch 32/1000\n",
      "92/92 - 0s - loss: 0.7640 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.6500\n",
      "Epoch 33/1000\n",
      "92/92 - 0s - loss: 0.7135 - acc: 1.0000 - val_loss: 1.2602 - val_acc: 0.7000\n",
      "Epoch 34/1000\n",
      "92/92 - 0s - loss: 0.6518 - acc: 1.0000 - val_loss: 1.2068 - val_acc: 0.7000\n",
      "Epoch 35/1000\n",
      "92/92 - 0s - loss: 0.5977 - acc: 1.0000 - val_loss: 1.1586 - val_acc: 0.6500\n",
      "Epoch 36/1000\n",
      "92/92 - 0s - loss: 0.5506 - acc: 1.0000 - val_loss: 1.1149 - val_acc: 0.6500\n",
      "Epoch 37/1000\n",
      "92/92 - 0s - loss: 0.5080 - acc: 1.0000 - val_loss: 1.0749 - val_acc: 0.6500\n",
      "Epoch 38/1000\n",
      "92/92 - 0s - loss: 0.4690 - acc: 1.0000 - val_loss: 1.0388 - val_acc: 0.6500\n",
      "Epoch 39/1000\n",
      "92/92 - 0s - loss: 0.4385 - acc: 1.0000 - val_loss: 1.0063 - val_acc: 0.7000\n",
      "Epoch 40/1000\n",
      "92/92 - 0s - loss: 0.4024 - acc: 0.9891 - val_loss: 0.9781 - val_acc: 0.7500\n",
      "Epoch 41/1000\n",
      "92/92 - 0s - loss: 0.3678 - acc: 1.0000 - val_loss: 0.9502 - val_acc: 0.7500\n",
      "Epoch 42/1000\n",
      "92/92 - 0s - loss: 0.3319 - acc: 1.0000 - val_loss: 0.9239 - val_acc: 0.7000\n",
      "Epoch 43/1000\n",
      "92/92 - 0s - loss: 0.3140 - acc: 1.0000 - val_loss: 0.9007 - val_acc: 0.6500\n",
      "Epoch 44/1000\n",
      "92/92 - 0s - loss: 0.2974 - acc: 1.0000 - val_loss: 0.8836 - val_acc: 0.7000\n",
      "Epoch 45/1000\n",
      "92/92 - 0s - loss: 0.2733 - acc: 1.0000 - val_loss: 0.8709 - val_acc: 0.7000\n",
      "Epoch 46/1000\n",
      "92/92 - 0s - loss: 0.2520 - acc: 1.0000 - val_loss: 0.8557 - val_acc: 0.6500\n",
      "Epoch 47/1000\n",
      "92/92 - 0s - loss: 0.2409 - acc: 1.0000 - val_loss: 0.8334 - val_acc: 0.7000\n",
      "Epoch 48/1000\n",
      "92/92 - 0s - loss: 0.2183 - acc: 1.0000 - val_loss: 0.8147 - val_acc: 0.6500\n",
      "Epoch 49/1000\n",
      "92/92 - 0s - loss: 0.2102 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.7500\n",
      "Epoch 50/1000\n",
      "92/92 - 0s - loss: 0.1956 - acc: 1.0000 - val_loss: 0.7948 - val_acc: 0.7500\n",
      "Epoch 51/1000\n",
      "92/92 - 0s - loss: 0.1837 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 0.7500\n",
      "Epoch 52/1000\n",
      "92/92 - 0s - loss: 0.1705 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.6500\n",
      "Epoch 53/1000\n",
      "92/92 - 0s - loss: 0.1553 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.6500\n",
      "Epoch 54/1000\n",
      "92/92 - 0s - loss: 0.1504 - acc: 1.0000 - val_loss: 0.7513 - val_acc: 0.6500\n",
      "Epoch 55/1000\n",
      "92/92 - 0s - loss: 0.1395 - acc: 1.0000 - val_loss: 0.7430 - val_acc: 0.6500\n",
      "Epoch 56/1000\n",
      "92/92 - 0s - loss: 0.1312 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.6500\n",
      "Epoch 57/1000\n",
      "92/92 - 0s - loss: 0.1269 - acc: 1.0000 - val_loss: 0.7280 - val_acc: 0.6500\n",
      "Epoch 58/1000\n",
      "92/92 - 0s - loss: 0.1196 - acc: 1.0000 - val_loss: 0.7219 - val_acc: 0.6500\n",
      "Epoch 59/1000\n",
      "92/92 - 0s - loss: 0.1161 - acc: 1.0000 - val_loss: 0.7164 - val_acc: 0.6500\n",
      "Epoch 60/1000\n",
      "92/92 - 0s - loss: 0.1063 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.6500\n",
      "Epoch 61/1000\n",
      "92/92 - 0s - loss: 0.0986 - acc: 1.0000 - val_loss: 0.7066 - val_acc: 0.6500\n",
      "Epoch 62/1000\n",
      "92/92 - 0s - loss: 0.0920 - acc: 1.0000 - val_loss: 0.7025 - val_acc: 0.6500\n",
      "Epoch 63/1000\n",
      "92/92 - 0s - loss: 0.0953 - acc: 1.0000 - val_loss: 0.6986 - val_acc: 0.6500\n",
      "Epoch 64/1000\n",
      "92/92 - 0s - loss: 0.0936 - acc: 1.0000 - val_loss: 0.6959 - val_acc: 0.7000\n",
      "Epoch 65/1000\n",
      "92/92 - 0s - loss: 0.0832 - acc: 1.0000 - val_loss: 0.6948 - val_acc: 0.7000\n",
      "Epoch 66/1000\n",
      "92/92 - 0s - loss: 0.0818 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.6500\n",
      "Epoch 67/1000\n",
      "92/92 - 0s - loss: 0.0787 - acc: 1.0000 - val_loss: 0.6861 - val_acc: 0.6500\n",
      "Epoch 68/1000\n",
      "92/92 - 0s - loss: 0.0727 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 0.6500\n",
      "Epoch 69/1000\n",
      "92/92 - 0s - loss: 0.0734 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.6500\n",
      "Epoch 70/1000\n",
      "92/92 - 0s - loss: 0.0696 - acc: 1.0000 - val_loss: 0.6791 - val_acc: 0.6500\n",
      "Epoch 71/1000\n",
      "92/92 - 0s - loss: 0.0693 - acc: 1.0000 - val_loss: 0.6769 - val_acc: 0.6500\n",
      "Epoch 72/1000\n",
      "92/92 - 0s - loss: 0.0657 - acc: 1.0000 - val_loss: 0.6749 - val_acc: 0.6500\n",
      "Epoch 73/1000\n",
      "92/92 - 0s - loss: 0.0628 - acc: 1.0000 - val_loss: 0.6738 - val_acc: 0.7000\n",
      "Epoch 74/1000\n",
      "92/92 - 0s - loss: 0.0630 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.7500\n",
      "Epoch 75/1000\n",
      "92/92 - 0s - loss: 0.0597 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 0.7500\n",
      "Epoch 76/1000\n",
      "92/92 - 0s - loss: 0.0612 - acc: 1.0000 - val_loss: 0.6695 - val_acc: 0.6500\n",
      "Epoch 77/1000\n",
      "92/92 - 0s - loss: 0.0698 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.6500\n",
      "Epoch 78/1000\n",
      "92/92 - 0s - loss: 0.0588 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 0.6500\n",
      "Epoch 79/1000\n",
      "92/92 - 0s - loss: 0.0535 - acc: 1.0000 - val_loss: 0.6731 - val_acc: 0.6500\n",
      "Epoch 80/1000\n",
      "92/92 - 0s - loss: 0.0519 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 0.6500\n",
      "Epoch 81/1000\n",
      "92/92 - 0s - loss: 0.0539 - acc: 1.0000 - val_loss: 0.6702 - val_acc: 0.6500\n",
      "Epoch 82/1000\n",
      "92/92 - 0s - loss: 0.0548 - acc: 1.0000 - val_loss: 0.6679 - val_acc: 0.7000\n",
      "Epoch 83/1000\n",
      "92/92 - 0s - loss: 0.0542 - acc: 1.0000 - val_loss: 0.6677 - val_acc: 0.7000\n",
      "Epoch 84/1000\n",
      "92/92 - 0s - loss: 0.0497 - acc: 1.0000 - val_loss: 0.6653 - val_acc: 0.6500\n",
      "Epoch 85/1000\n",
      "92/92 - 0s - loss: 0.0502 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.6500\n",
      "Epoch 86/1000\n",
      "92/92 - 0s - loss: 0.0489 - acc: 1.0000 - val_loss: 0.6643 - val_acc: 0.6500\n",
      "Epoch 87/1000\n",
      "92/92 - 0s - loss: 0.0464 - acc: 1.0000 - val_loss: 0.6617 - val_acc: 0.6500\n",
      "Epoch 88/1000\n",
      "92/92 - 0s - loss: 0.0472 - acc: 1.0000 - val_loss: 0.6663 - val_acc: 0.7500\n",
      "Epoch 89/1000\n",
      "92/92 - 0s - loss: 0.0417 - acc: 1.0000 - val_loss: 0.6725 - val_acc: 0.6500\n",
      "Epoch 90/1000\n",
      "92/92 - 0s - loss: 0.0432 - acc: 1.0000 - val_loss: 0.6663 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000\n",
      "92/92 - 0s - loss: 0.0425 - acc: 1.0000 - val_loss: 0.6581 - val_acc: 0.7000\n",
      "Epoch 92/1000\n",
      "92/92 - 0s - loss: 0.0433 - acc: 1.0000 - val_loss: 0.6603 - val_acc: 0.6500\n",
      "Epoch 93/1000\n",
      "92/92 - 0s - loss: 0.0411 - acc: 1.0000 - val_loss: 0.6645 - val_acc: 0.7000\n",
      "Epoch 94/1000\n",
      "92/92 - 0s - loss: 0.0455 - acc: 1.0000 - val_loss: 0.6645 - val_acc: 0.7000\n",
      "Epoch 95/1000\n",
      "92/92 - 0s - loss: 0.0364 - acc: 1.0000 - val_loss: 0.6621 - val_acc: 0.7000\n",
      "Epoch 96/1000\n",
      "92/92 - 0s - loss: 0.0394 - acc: 1.0000 - val_loss: 0.6573 - val_acc: 0.6500\n",
      "Epoch 97/1000\n",
      "92/92 - 0s - loss: 0.0407 - acc: 1.0000 - val_loss: 0.6588 - val_acc: 0.7500\n",
      "Epoch 98/1000\n",
      "92/92 - 0s - loss: 0.0380 - acc: 1.0000 - val_loss: 0.6647 - val_acc: 0.7000\n",
      "Epoch 99/1000\n",
      "92/92 - 0s - loss: 0.0402 - acc: 1.0000 - val_loss: 0.6676 - val_acc: 0.6500\n",
      "Epoch 100/1000\n",
      "92/92 - 0s - loss: 0.0401 - acc: 1.0000 - val_loss: 0.6651 - val_acc: 0.6500\n",
      "Epoch 101/1000\n",
      "92/92 - 0s - loss: 0.0361 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 0.7000\n",
      "Epoch 102/1000\n",
      "92/92 - 0s - loss: 0.0361 - acc: 1.0000 - val_loss: 0.6550 - val_acc: 0.7500\n",
      "Epoch 103/1000\n",
      "92/92 - 0s - loss: 0.0350 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.6500\n",
      "Epoch 104/1000\n",
      "92/92 - 0s - loss: 0.0346 - acc: 1.0000 - val_loss: 0.6518 - val_acc: 0.6500\n",
      "Epoch 105/1000\n",
      "92/92 - 0s - loss: 0.0320 - acc: 1.0000 - val_loss: 0.6510 - val_acc: 0.6500\n",
      "Epoch 106/1000\n",
      "92/92 - 0s - loss: 0.0339 - acc: 1.0000 - val_loss: 0.6505 - val_acc: 0.6500\n",
      "Epoch 107/1000\n",
      "92/92 - 0s - loss: 0.0326 - acc: 1.0000 - val_loss: 0.6505 - val_acc: 0.7000\n",
      "Epoch 108/1000\n",
      "92/92 - 0s - loss: 0.0343 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.7500\n",
      "Epoch 109/1000\n",
      "92/92 - 0s - loss: 0.0336 - acc: 1.0000 - val_loss: 0.6537 - val_acc: 0.7500\n",
      "Epoch 110/1000\n",
      "92/92 - 0s - loss: 0.0319 - acc: 1.0000 - val_loss: 0.6561 - val_acc: 0.7000\n",
      "Epoch 111/1000\n",
      "92/92 - 0s - loss: 0.0345 - acc: 1.0000 - val_loss: 0.6590 - val_acc: 0.6500\n",
      "Epoch 112/1000\n",
      "92/92 - 0s - loss: 0.0312 - acc: 1.0000 - val_loss: 0.6570 - val_acc: 0.7000\n",
      "Epoch 113/1000\n",
      "92/92 - 0s - loss: 0.0323 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.7500\n",
      "Epoch 114/1000\n",
      "92/92 - 0s - loss: 0.0323 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.6500\n",
      "Epoch 115/1000\n",
      "92/92 - 0s - loss: 0.0357 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.6500\n",
      "Epoch 116/1000\n",
      "92/92 - 0s - loss: 0.0323 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.6500\n",
      "Epoch 117/1000\n",
      "92/92 - 0s - loss: 0.0310 - acc: 1.0000 - val_loss: 0.6500 - val_acc: 0.6500\n",
      "Epoch 118/1000\n",
      "92/92 - 0s - loss: 0.0314 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.6500\n",
      "Epoch 119/1000\n",
      "92/92 - 0s - loss: 0.0328 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.6500\n",
      "Epoch 120/1000\n",
      "92/92 - 0s - loss: 0.0305 - acc: 1.0000 - val_loss: 0.6507 - val_acc: 0.6500\n",
      "Epoch 121/1000\n",
      "92/92 - 0s - loss: 0.0325 - acc: 1.0000 - val_loss: 0.6547 - val_acc: 0.7000\n",
      "Epoch 122/1000\n",
      "92/92 - 0s - loss: 0.0326 - acc: 1.0000 - val_loss: 0.6533 - val_acc: 0.7000\n",
      "Epoch 123/1000\n",
      "92/92 - 0s - loss: 0.0306 - acc: 1.0000 - val_loss: 0.6506 - val_acc: 0.6500\n",
      "Epoch 124/1000\n",
      "92/92 - 0s - loss: 0.0341 - acc: 1.0000 - val_loss: 0.6496 - val_acc: 0.6500\n",
      "Epoch 125/1000\n",
      "92/92 - 0s - loss: 0.0299 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 0.6500\n",
      "Epoch 126/1000\n",
      "92/92 - 0s - loss: 0.0299 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.6500\n",
      "Epoch 127/1000\n",
      "92/92 - 0s - loss: 0.0355 - acc: 1.0000 - val_loss: 0.6485 - val_acc: 0.6500\n",
      "Epoch 128/1000\n",
      "92/92 - 0s - loss: 0.0305 - acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.6500\n",
      "Epoch 129/1000\n",
      "92/92 - 0s - loss: 0.0299 - acc: 1.0000 - val_loss: 0.6479 - val_acc: 0.6500\n",
      "Epoch 130/1000\n",
      "92/92 - 0s - loss: 0.0299 - acc: 1.0000 - val_loss: 0.6477 - val_acc: 0.6500\n",
      "Epoch 131/1000\n",
      "92/92 - 0s - loss: 0.0276 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.6500\n",
      "Epoch 132/1000\n",
      "92/92 - 0s - loss: 0.0277 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.7500\n",
      "Epoch 133/1000\n",
      "92/92 - 0s - loss: 0.0287 - acc: 1.0000 - val_loss: 0.6579 - val_acc: 0.6500\n",
      "Epoch 134/1000\n",
      "92/92 - 0s - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6632 - val_acc: 0.6000\n",
      "Epoch 135/1000\n",
      "92/92 - 0s - loss: 0.0276 - acc: 1.0000 - val_loss: 0.6595 - val_acc: 0.6000\n",
      "Epoch 136/1000\n",
      "92/92 - 0s - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6533 - val_acc: 0.6500\n",
      "Epoch 137/1000\n",
      "92/92 - 0s - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6478 - val_acc: 0.7500\n",
      "Epoch 138/1000\n",
      "92/92 - 0s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6452 - val_acc: 0.7500\n",
      "Epoch 139/1000\n",
      "92/92 - 0s - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6439 - val_acc: 0.7000\n",
      "Epoch 140/1000\n",
      "92/92 - 0s - loss: 0.0263 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.6500\n",
      "Epoch 141/1000\n",
      "92/92 - 0s - loss: 0.0245 - acc: 1.0000 - val_loss: 0.6447 - val_acc: 0.6500\n",
      "Epoch 142/1000\n",
      "92/92 - 0s - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.7000\n",
      "Epoch 143/1000\n",
      "92/92 - 0s - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.6500\n",
      "Epoch 144/1000\n",
      "92/92 - 0s - loss: 0.0235 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 0.7000\n",
      "Epoch 145/1000\n",
      "92/92 - 0s - loss: 0.0241 - acc: 1.0000 - val_loss: 0.6473 - val_acc: 0.7000\n",
      "Epoch 146/1000\n",
      "92/92 - 0s - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6473 - val_acc: 0.7000\n",
      "Epoch 147/1000\n",
      "92/92 - 0s - loss: 0.0254 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.7000\n",
      "Epoch 148/1000\n",
      "92/92 - 0s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6448 - val_acc: 0.6500\n",
      "Epoch 149/1000\n",
      "92/92 - 0s - loss: 0.0221 - acc: 1.0000 - val_loss: 0.6502 - val_acc: 0.7000\n",
      "Epoch 150/1000\n",
      "92/92 - 0s - loss: 0.0255 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.7000\n",
      "Epoch 151/1000\n",
      "92/92 - 0s - loss: 0.0263 - acc: 1.0000 - val_loss: 0.6448 - val_acc: 0.6500\n",
      "Epoch 152/1000\n",
      "92/92 - 0s - loss: 0.0251 - acc: 1.0000 - val_loss: 0.6408 - val_acc: 0.6500\n",
      "Epoch 153/1000\n",
      "92/92 - 0s - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.7500\n",
      "Epoch 154/1000\n",
      "92/92 - 0s - loss: 0.0271 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.6500\n",
      "Epoch 155/1000\n",
      "92/92 - 0s - loss: 0.0253 - acc: 1.0000 - val_loss: 0.6439 - val_acc: 0.7500\n",
      "Epoch 156/1000\n",
      "92/92 - 0s - loss: 0.0260 - acc: 1.0000 - val_loss: 0.6432 - val_acc: 0.6500\n",
      "Epoch 157/1000\n",
      "92/92 - 0s - loss: 0.0250 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.7000\n",
      "Epoch 158/1000\n",
      "92/92 - 0s - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.6500\n",
      "Epoch 159/1000\n",
      "92/92 - 0s - loss: 0.0237 - acc: 1.0000 - val_loss: 0.6588 - val_acc: 0.6500\n",
      "Epoch 160/1000\n",
      "92/92 - 0s - loss: 0.0231 - acc: 1.0000 - val_loss: 0.6596 - val_acc: 0.6500\n",
      "Epoch 161/1000\n",
      "92/92 - 0s - loss: 0.0223 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.6500\n",
      "Epoch 162/1000\n",
      "92/92 - 0s - loss: 0.0198 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.6500\n",
      "Epoch 163/1000\n",
      "92/92 - 0s - loss: 0.0220 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 0.6500\n",
      "Epoch 164/1000\n",
      "92/92 - 0s - loss: 0.0220 - acc: 1.0000 - val_loss: 0.6488 - val_acc: 0.6500\n",
      "Epoch 165/1000\n",
      "92/92 - 0s - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.6500\n",
      "Epoch 166/1000\n",
      "92/92 - 0s - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 0.7000\n",
      "Epoch 167/1000\n",
      "92/92 - 0s - loss: 0.0250 - acc: 1.0000 - val_loss: 0.6453 - val_acc: 0.6500\n",
      "Epoch 168/1000\n",
      "92/92 - 0s - loss: 0.0230 - acc: 1.0000 - val_loss: 0.6578 - val_acc: 0.6500\n",
      "Epoch 169/1000\n",
      "92/92 - 0s - loss: 0.0222 - acc: 1.0000 - val_loss: 0.6740 - val_acc: 0.6000\n",
      "Epoch 170/1000\n",
      "92/92 - 0s - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6746 - val_acc: 0.6000\n",
      "Epoch 171/1000\n",
      "92/92 - 0s - loss: 0.0215 - acc: 1.0000 - val_loss: 0.6553 - val_acc: 0.6500\n",
      "Epoch 172/1000\n",
      "92/92 - 0s - loss: 0.0233 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.6500\n",
      "Epoch 173/1000\n",
      "92/92 - 0s - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6495 - val_acc: 0.7000\n",
      "Epoch 174/1000\n",
      "92/92 - 0s - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6516 - val_acc: 0.6500\n",
      "Epoch 175/1000\n",
      "92/92 - 0s - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6496 - val_acc: 0.7000\n",
      "Epoch 176/1000\n",
      "92/92 - 0s - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 0.7500\n",
      "Epoch 177/1000\n",
      "92/92 - 0s - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 0.6500\n",
      "Epoch 178/1000\n",
      "92/92 - 0s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.6428 - val_acc: 0.6500\n",
      "Epoch 179/1000\n",
      "92/92 - 0s - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.7000\n",
      "Epoch 180/1000\n",
      "92/92 - 0s - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "92/92 - 0s - loss: 0.0228 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.6500\n",
      "Epoch 182/1000\n",
      "92/92 - 0s - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6410 - val_acc: 0.6500\n",
      "Epoch 183/1000\n",
      "92/92 - 0s - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6444 - val_acc: 0.7000\n",
      "Epoch 184/1000\n",
      "92/92 - 0s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.7000\n",
      "Epoch 185/1000\n",
      "92/92 - 0s - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6395 - val_acc: 0.6500\n",
      "Epoch 186/1000\n",
      "92/92 - 0s - loss: 0.0219 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.7500\n",
      "Epoch 187/1000\n",
      "92/92 - 0s - loss: 0.0215 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 0.7000\n",
      "Epoch 188/1000\n",
      "92/92 - 0s - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6479 - val_acc: 0.7000\n",
      "Epoch 189/1000\n",
      "92/92 - 0s - loss: 0.0260 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.7000\n",
      "Epoch 190/1000\n",
      "92/92 - 0s - loss: 0.0228 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.7500\n",
      "Epoch 191/1000\n",
      "92/92 - 0s - loss: 0.0226 - acc: 1.0000 - val_loss: 0.6405 - val_acc: 0.6500\n",
      "Epoch 192/1000\n",
      "92/92 - 0s - loss: 0.0220 - acc: 1.0000 - val_loss: 0.6477 - val_acc: 0.7000\n",
      "Epoch 193/1000\n",
      "92/92 - 0s - loss: 0.0225 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.7000\n",
      "Epoch 194/1000\n",
      "92/92 - 0s - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6452 - val_acc: 0.6500\n",
      "Epoch 195/1000\n",
      "92/92 - 0s - loss: 0.0205 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 0.6500\n",
      "Epoch 196/1000\n",
      "92/92 - 0s - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.6500\n",
      "Epoch 197/1000\n",
      "92/92 - 0s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.6500\n",
      "Epoch 198/1000\n",
      "92/92 - 0s - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 0.7500\n",
      "Epoch 199/1000\n",
      "92/92 - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6647 - val_acc: 0.6000\n",
      "Epoch 200/1000\n",
      "92/92 - 0s - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6615 - val_acc: 0.5500\n",
      "Epoch 201/1000\n",
      "92/92 - 0s - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.6500\n",
      "Epoch 202/1000\n",
      "92/92 - 0s - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6530 - val_acc: 0.6500\n",
      "Epoch 203/1000\n",
      "92/92 - 0s - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6724 - val_acc: 0.6000\n",
      "Epoch 204/1000\n",
      "92/92 - 0s - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6671 - val_acc: 0.6500\n",
      "Epoch 205/1000\n",
      "92/92 - 0s - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.6500\n",
      "Epoch 206/1000\n",
      "92/92 - 0s - loss: 0.0201 - acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.6500\n",
      "Epoch 207/1000\n",
      "92/92 - 0s - loss: 0.0179 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.6500\n",
      "Epoch 208/1000\n",
      "92/92 - 0s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.6500\n",
      "Epoch 209/1000\n",
      "92/92 - 0s - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 0.6500\n",
      "Epoch 210/1000\n",
      "92/92 - 0s - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.6500\n",
      "Epoch 211/1000\n",
      "92/92 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.7000\n",
      "Epoch 212/1000\n",
      "92/92 - 0s - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.7500\n",
      "Epoch 213/1000\n",
      "92/92 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.7000\n",
      "Epoch 214/1000\n",
      "92/92 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.6500\n",
      "Epoch 215/1000\n",
      "92/92 - 0s - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6433 - val_acc: 0.6500\n",
      "Epoch 216/1000\n",
      "92/92 - 0s - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.6500\n",
      "Epoch 217/1000\n",
      "92/92 - 0s - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6374 - val_acc: 0.6500\n",
      "Epoch 218/1000\n",
      "92/92 - 0s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 0.7000\n",
      "Epoch 219/1000\n",
      "92/92 - 0s - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6670 - val_acc: 0.6000\n",
      "Epoch 220/1000\n",
      "92/92 - 0s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6866 - val_acc: 0.6000\n",
      "Epoch 221/1000\n",
      "92/92 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6716 - val_acc: 0.6000\n",
      "Epoch 222/1000\n",
      "92/92 - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.7500\n",
      "Epoch 223/1000\n",
      "92/92 - 0s - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.6500\n",
      "Epoch 224/1000\n",
      "92/92 - 0s - loss: 0.0191 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.6500\n",
      "Epoch 225/1000\n",
      "92/92 - 0s - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.7000\n",
      "Epoch 226/1000\n",
      "92/92 - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 0.7000\n",
      "Epoch 227/1000\n",
      "92/92 - 0s - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.6500\n",
      "Epoch 228/1000\n",
      "92/92 - 0s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.6500\n",
      "Epoch 229/1000\n",
      "92/92 - 0s - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.6500\n",
      "Epoch 230/1000\n",
      "92/92 - 0s - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6379 - val_acc: 0.6500\n",
      "Epoch 231/1000\n",
      "92/92 - 0s - loss: 0.0201 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.7500\n",
      "Epoch 232/1000\n",
      "92/92 - 0s - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6577 - val_acc: 0.6000\n",
      "Epoch 233/1000\n",
      "92/92 - 0s - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6444 - val_acc: 0.7500\n",
      "Epoch 234/1000\n",
      "92/92 - 0s - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6362 - val_acc: 0.7000\n",
      "Epoch 235/1000\n",
      "92/92 - 0s - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6354 - val_acc: 0.6500\n",
      "Epoch 236/1000\n",
      "92/92 - 0s - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.6500\n",
      "Epoch 237/1000\n",
      "92/92 - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.7000\n",
      "Epoch 238/1000\n",
      "92/92 - 0s - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.7500\n",
      "Epoch 239/1000\n",
      "92/92 - 0s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6483 - val_acc: 0.6500\n",
      "Epoch 240/1000\n",
      "92/92 - 0s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6533 - val_acc: 0.6500\n",
      "Epoch 241/1000\n",
      "92/92 - 0s - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6551 - val_acc: 0.6500\n",
      "Epoch 242/1000\n",
      "92/92 - 0s - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.7000\n",
      "Epoch 243/1000\n",
      "92/92 - 0s - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.6500\n",
      "Epoch 244/1000\n",
      "92/92 - 0s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.6500\n",
      "Epoch 245/1000\n",
      "92/92 - 0s - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6369 - val_acc: 0.6500\n",
      "Epoch 246/1000\n",
      "92/92 - 0s - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6446 - val_acc: 0.7000\n",
      "Epoch 247/1000\n",
      "92/92 - 0s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6417 - val_acc: 0.6500\n",
      "Epoch 248/1000\n",
      "92/92 - 0s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.6500\n",
      "Epoch 249/1000\n",
      "92/92 - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.6500\n",
      "Epoch 250/1000\n",
      "92/92 - 0s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6347 - val_acc: 0.6500\n",
      "Epoch 251/1000\n",
      "92/92 - 0s - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.6500\n",
      "Epoch 252/1000\n",
      "92/92 - 0s - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6637 - val_acc: 0.6500\n",
      "Epoch 253/1000\n",
      "92/92 - 0s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6843 - val_acc: 0.6000\n",
      "Epoch 254/1000\n",
      "92/92 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6663 - val_acc: 0.6500\n",
      "Epoch 255/1000\n",
      "92/92 - 0s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.6500\n",
      "Epoch 256/1000\n",
      "92/92 - 0s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.6500\n",
      "Epoch 257/1000\n",
      "92/92 - 0s - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6616 - val_acc: 0.5500\n",
      "Epoch 258/1000\n",
      "92/92 - 0s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6711 - val_acc: 0.6000\n",
      "Epoch 259/1000\n",
      "92/92 - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6387 - val_acc: 0.7500\n",
      "Epoch 260/1000\n",
      "92/92 - 0s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6369 - val_acc: 0.6500\n",
      "Epoch 261/1000\n",
      "92/92 - 0s - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6464 - val_acc: 0.6500\n",
      "Epoch 262/1000\n",
      "92/92 - 0s - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.6500\n",
      "Epoch 263/1000\n",
      "92/92 - 0s - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.6500\n",
      "Epoch 264/1000\n",
      "92/92 - 0s - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6437 - val_acc: 0.7000\n",
      "Epoch 265/1000\n",
      "92/92 - 0s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6592 - val_acc: 0.6000\n",
      "Epoch 266/1000\n",
      "92/92 - 0s - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6505 - val_acc: 0.6500\n",
      "Epoch 267/1000\n",
      "92/92 - 0s - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.7500\n",
      "Epoch 268/1000\n",
      "92/92 - 0s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.6500\n",
      "Epoch 269/1000\n",
      "92/92 - 0s - loss: 0.0143 - acc: 1.0000 - val_loss: 0.6468 - val_acc: 0.6500\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 - 0s - loss: 0.0148 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 0.6500\n",
      "Epoch 271/1000\n",
      "92/92 - 0s - loss: 0.0179 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.7000\n",
      "Epoch 272/1000\n",
      "92/92 - 0s - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6659 - val_acc: 0.6500\n",
      "Epoch 273/1000\n",
      "92/92 - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 0.6000\n",
      "Epoch 274/1000\n",
      "92/92 - 0s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6609 - val_acc: 0.6500\n",
      "Epoch 275/1000\n",
      "92/92 - 0s - loss: 0.0179 - acc: 1.0000 - val_loss: 0.6443 - val_acc: 0.7000\n",
      "Epoch 276/1000\n",
      "92/92 - 0s - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.6500\n",
      "Epoch 277/1000\n",
      "92/92 - 0s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.6500\n",
      "Epoch 278/1000\n",
      "92/92 - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 0.7500\n",
      "Epoch 279/1000\n",
      "92/92 - 0s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6387 - val_acc: 0.7500\n",
      "Epoch 280/1000\n",
      "92/92 - 0s - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6333 - val_acc: 0.6500\n",
      "Epoch 281/1000\n",
      "92/92 - 0s - loss: 0.0141 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 0.6500\n",
      "Epoch 282/1000\n",
      "92/92 - 0s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.6500\n",
      "Epoch 283/1000\n",
      "92/92 - 0s - loss: 0.0134 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.6500\n",
      "Epoch 284/1000\n",
      "92/92 - 0s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6437 - val_acc: 0.7000\n",
      "Epoch 285/1000\n",
      "92/92 - 0s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.6500\n",
      "Epoch 286/1000\n",
      "92/92 - 0s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.6359 - val_acc: 0.6500\n",
      "Epoch 287/1000\n",
      "92/92 - 0s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 0.6500\n",
      "Epoch 288/1000\n",
      "92/92 - 0s - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6408 - val_acc: 0.6500\n",
      "Epoch 289/1000\n",
      "92/92 - 0s - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6605 - val_acc: 0.6500\n",
      "Epoch 290/1000\n",
      "92/92 - 0s - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6586 - val_acc: 0.6500\n",
      "Epoch 291/1000\n",
      "92/92 - 0s - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6507 - val_acc: 0.7000\n",
      "Epoch 292/1000\n",
      "92/92 - 0s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6484 - val_acc: 0.7000\n",
      "Epoch 293/1000\n",
      "92/92 - 0s - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6365 - val_acc: 0.6500\n",
      "Epoch 294/1000\n",
      "92/92 - 0s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6341 - val_acc: 0.7000\n",
      "Epoch 295/1000\n",
      "92/92 - 0s - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6703 - val_acc: 0.6000\n",
      "Epoch 296/1000\n",
      "92/92 - 0s - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6876 - val_acc: 0.6000\n",
      "Epoch 297/1000\n",
      "92/92 - 0s - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.6000\n",
      "Epoch 298/1000\n",
      "92/92 - 0s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.7000\n",
      "Epoch 299/1000\n",
      "92/92 - 0s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6362 - val_acc: 0.6500\n",
      "Epoch 300/1000\n",
      "92/92 - 0s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6459 - val_acc: 0.6500\n",
      "Epoch 301/1000\n",
      "92/92 - 0s - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.7000\n",
      "Epoch 302/1000\n",
      "92/92 - 0s - loss: 0.0148 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.6500\n",
      "Epoch 303/1000\n",
      "92/92 - 0s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 0.7000\n",
      "Epoch 304/1000\n",
      "92/92 - 0s - loss: 0.0133 - acc: 1.0000 - val_loss: 0.6347 - val_acc: 0.7000\n",
      "Epoch 305/1000\n",
      "92/92 - 0s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.6331 - val_acc: 0.7000\n",
      "Epoch 306/1000\n",
      "92/92 - 0s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.6313 - val_acc: 0.6500\n",
      "Epoch 307/1000\n",
      "92/92 - 0s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.7500\n",
      "Epoch 308/1000\n",
      "92/92 - 0s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6397 - val_acc: 0.7000\n",
      "Epoch 309/1000\n",
      "92/92 - 0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 0.7500\n",
      "Epoch 310/1000\n",
      "92/92 - 0s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.6500\n",
      "Epoch 311/1000\n",
      "92/92 - 0s - loss: 0.0130 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 0.6500\n",
      "Epoch 312/1000\n",
      "92/92 - 0s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.6500\n",
      "Epoch 313/1000\n",
      "92/92 - 0s - loss: 0.0119 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.6500\n",
      "Epoch 314/1000\n",
      "92/92 - 0s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 0.6500\n",
      "Epoch 315/1000\n",
      "92/92 - 0s - loss: 0.0114 - acc: 1.0000 - val_loss: 0.6303 - val_acc: 0.6500\n",
      "Epoch 316/1000\n",
      "92/92 - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.6500\n",
      "Epoch 317/1000\n",
      "92/92 - 0s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6359 - val_acc: 0.7500\n",
      "Epoch 318/1000\n",
      "92/92 - 0s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.6381 - val_acc: 0.7500\n",
      "Epoch 319/1000\n",
      "92/92 - 0s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 0.7000\n",
      "Epoch 320/1000\n",
      "92/92 - 0s - loss: 0.0141 - acc: 1.0000 - val_loss: 0.6334 - val_acc: 0.6500\n",
      "Epoch 321/1000\n",
      "92/92 - 0s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 0.6500\n",
      "Epoch 322/1000\n",
      "92/92 - 0s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.6331 - val_acc: 0.6500\n",
      "Epoch 323/1000\n",
      "92/92 - 0s - loss: 0.0127 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.7500\n",
      "Epoch 324/1000\n",
      "92/92 - 0s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6397 - val_acc: 0.7500\n",
      "Epoch 325/1000\n",
      "92/92 - 0s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6341 - val_acc: 0.7000\n",
      "Epoch 326/1000\n",
      "92/92 - 0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.6500\n",
      "Epoch 327/1000\n",
      "92/92 - 0s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 0.7000\n",
      "Epoch 328/1000\n",
      "92/92 - 0s - loss: 0.0115 - acc: 1.0000 - val_loss: 0.6479 - val_acc: 0.6500\n",
      "Epoch 329/1000\n",
      "92/92 - 0s - loss: 0.0124 - acc: 1.0000 - val_loss: 0.6527 - val_acc: 0.6500\n",
      "Epoch 330/1000\n",
      "92/92 - 0s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.6500\n",
      "Epoch 331/1000\n",
      "92/92 - 0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.7500\n",
      "Epoch 332/1000\n",
      "92/92 - 0s - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6545 - val_acc: 0.6500\n",
      "Epoch 333/1000\n",
      "92/92 - 0s - loss: 0.0135 - acc: 1.0000 - val_loss: 0.6566 - val_acc: 0.6500\n",
      "Epoch 334/1000\n",
      "92/92 - 0s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.7000\n",
      "Epoch 335/1000\n",
      "92/92 - 0s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.6365 - val_acc: 0.6500\n",
      "Epoch 336/1000\n",
      "92/92 - 0s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 0.6500\n",
      "Epoch 337/1000\n",
      "92/92 - 0s - loss: 0.0119 - acc: 1.0000 - val_loss: 0.6404 - val_acc: 0.6500\n",
      "Epoch 338/1000\n",
      "92/92 - 0s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.6500\n",
      "Epoch 339/1000\n",
      "92/92 - 0s - loss: 0.0119 - acc: 1.0000 - val_loss: 0.6395 - val_acc: 0.7000\n",
      "Epoch 340/1000\n",
      "92/92 - 0s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6332 - val_acc: 0.6500\n",
      "Epoch 00340: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2072a65fa20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val) , epochs=1000, verbose=2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT THE LOSS\n",
    "\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()\n",
    "plt.title('Model loss and accuracy during training') \n",
    "plt.ylabel('Loss or Accuracy') \n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        12\n",
      "           1       0.64      0.69      0.67        13\n",
      "\n",
      "    accuracy                           0.64        25\n",
      "   macro avg       0.64      0.64      0.64        25\n",
      "weighted avg       0.64      0.64      0.64        25\n",
      "\n",
      "\n",
      " CONFUSION MATRIX:\n",
      " [[7 5]\n",
      " [4 9]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.64\n"
     ]
    }
   ],
   "source": [
    "# PERFORMANCE EVALUATION\n",
    "\n",
    "pred_NN = []\n",
    "\n",
    "for predictions in model.predict(X_test):\n",
    "    if predictions < 0.5:\n",
    "        predictions = 0\n",
    "    else:\n",
    "        predictions=1\n",
    "    pred_NN.append(predictions)\n",
    "    \n",
    "pred = np.array(pred_NN)\n",
    "true = np.array(y_test)\n",
    "\n",
    "# print(\"PREDICTED CLASS: \", pred)\n",
    "# print(\"ACTUAL CLASS: \", true, '\\n')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(true, pred))\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[11  1]\n",
      " [ 4  9]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Random Forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=600)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_rfc))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[9 3]\n",
      " [5 8]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Decision Tree)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "pred_tree = dtree.predict(X_test)\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_tree))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[9 3]\n",
      " [7 6]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Classifier (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "pred_svm = svm_model.predict(np.array(X_test))\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_svm))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classifier(K-Nearest Neighbors)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "pred_knn = knn.predict(X_test)\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_knn))\n",
    "\n",
    "# BEST VALUE OF K (Will take some time)\n",
    "error_rate = []\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    pred_i = pred_i.reshape(25, 1)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 40), error_rate, color='blue', linestyle='dashed', marker='o',\n",
    "          markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[11  1]\n",
      " [ 4  9]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.8\n"
     ]
    }
   ],
   "source": [
    "# KNN with best K\n",
    "knn = KNeighborsClassifier(n_neighbors=18)\n",
    "knn.fit(X_train, y_train)\n",
    "pred_knn = knn.predict(X_test)\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_knn))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[10  2]\n",
      " [ 7  6]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "pred_log = logmodel.predict(X_test)\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_log))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:573: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  \"pandas.DataFrame with sparse columns found.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CONFUSION MATRIX:\n",
      " [[ 1 11]\n",
      " [ 0 13]]\n",
      "\n",
      "\n",
      " ACCURACY SCORE IS: 0.56 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier (Naive Bayes)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "pred_naive = nb.predict(X_test)\n",
    "print('\\n CONFUSION MATRIX:\\n', confusion_matrix(true, pred_naive))\n",
    "print('\\n\\n ACCURACY SCORE IS:', accuracy_score(true, pred_naive), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY SCORE OF EACH CLASSIFIER:\n",
      "\n",
      "NEURAL NETWORK: 0.64\n",
      "RANDOM FOREST: 0.8\n",
      "DECISION TREE: 0.68\n",
      "SVM: 0.6\n",
      "K NEAREST NEIGHBORS: 0.8\n",
      "LOGISTIC REGRESSION: 0.64\n",
      "NAIVE BAYES: 0.56\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY SCORE OF EACH CLASSIFIER:\\n')\n",
    "print('NEURAL NETWORK:', accuracy_score(true, pred))\n",
    "print('RANDOM FOREST:', accuracy_score(true, pred_rfc))\n",
    "print('DECISION TREE:', accuracy_score(true, pred_tree))\n",
    "print('SVM:', accuracy_score(true, pred_svm))\n",
    "print('K NEAREST NEIGHBORS:', accuracy_score(true, pred_knn))\n",
    "print('LOGISTIC REGRESSION:', accuracy_score(true, pred_log))\n",
    "print('NAIVE BAYES:', accuracy_score(true, pred_naive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "WARNING:tensorflow:From C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\onjad\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Loaded model from disk\n",
      "acc: 64.00%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_K.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_K.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
